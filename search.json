[{"path":"https://hassanpazira.github.io/BFI/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 BFI authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"An Introduction to BFI","text":"R package BFI (Bayesian Federated Inference) provides several functions carry Bayesian Federated Inference method two kinds models (GLM Survival) multicenteral data without combining/sharing . tutorial focus GLM , version package available two commonly used families: \"binomial\" \"gaussian\". mostly using functions include bfi(), MAP.estimation(), inv.prior.cov(). following, see BFI package can applied real datasets included package.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"how-to-use-it","dir":"Articles","previous_headings":"","what":"How to use it?","title":"An Introduction to BFI","text":"go , first install load package: following code can see two available datasets package: trauma Nurses. trauma data can utilized \"binomial\" family Nurses data can used \"gaussian\". avoid repetition, use trauma data set. Load inspect trauma data follows: data set consists data 371 trauma patients three hospitals (peripheral hospital without neuro-surgical unit, status=1, peripheral hospital neuro-surgical unit, status=2, academic medical center, status=3). can see 6 columns: covariates sex (dichotomous), age (continuous), ISS (Injury Severity Score, continuous), GCS (Glasgow Coma Scale, continuous) predictors, mortality response variable. hospital categorical variable indicates hospitals involved study. information dataset use","code":"# install BFI from GitHub devtools::install_github(\"hassanpazira/BFI\") ##  ## ── R CMD build ───────────────────────────────────────────────────────────────── ## * checking for file ‘/tmp/RtmpBzzOXZ/remotes19cc49d115e3/hassanpazira-BFI-4d1fde1/DESCRIPTION’ ... OK ## * preparing ‘BFI’: ## * checking DESCRIPTION meta-information ... OK ## * checking for LF line-endings in source and make files and shell scripts ## * checking for empty or unneeded directories ## * building ‘BFI_1.0.0.tar.gz’ # load BFI library(BFI) data(package = \"BFI\") # Load 'trauma' in the R workspace data(\"trauma\")  # Get the number of rows and columns dim(trauma) ## [1] 371   6 # To get an idea of the dataset, print the first 7 rows head(trauma, 7) ##   sex age hospital ISS GCS mortality ## 1   1  20        3  24  15         0 ## 2   0  38        3  34  13         0 ## 3   0  37        3  50  15         0 ## 4   0  17        3  43   4         1 ## 5   0  49        3  29  15         0 ## 6   0  30        3  22  15         0 ## 7   1  84        2  66   3         1 (col_name <- colnames(trauma)) ## [1] \"sex\"       \"age\"       \"hospital\"  \"ISS\"       \"GCS\"       \"mortality\" # Get some info about the dataset from the help file ?trauma"},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Calling BFI from Python","text":"BFI R package performs Bayesian Federated Inference (BFI) linear, logistic, Cox regression models. Since Python package carrying BFI method far, vignette describes usage R package BFI Python environment. move Python environment, need prepare operating system. Although, explain following prepare different systems (‘MacOS’, ‘Ubuntu’ ‘Windows’), recommend use ‘Google Colab’ write execute (following) Python codes can done system browser without preparations.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"google-colab","dir":"Articles","previous_headings":"","what":"Google Colab","title":"Calling BFI from Python","text":"First go Google Colab https://colab.google https://colab.research.google.com, click New Notebook. Now, skip two following sections jump third section Python script.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"python-installation","dir":"Articles","previous_headings":"","what":"Python Installation","title":"Calling BFI from Python","text":"steps install latest version Python ‘MacOS’, ‘Ubuntu’ ‘Windows’ follows:","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-macos","dir":"Articles","previous_headings":"Python Installation","what":"On MacOS","title":"Calling BFI from Python","text":"Open terminal window (cmd + space search ‘Terminal’) install package manager ‘Homebrew’ executing following command: Install latest version Python (Python 3) following command: Verify installation checking Python version: ’s assumed R also installed configured system. , following can :","code":"/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\" brew install python@3 python3 --version # Install XCode command-line tools xcode-select --install  # Install R brew install --cask r"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-ubuntu","dir":"Articles","previous_headings":"Python Installation","what":"On Ubuntu","title":"Calling BFI from Python","text":"Update package repositories get latest package information running following command terminal window: Verify Python indeed installed system following command: already Python (Python 3) installed system, need upgrade latest version follows: case Python installed first place, latest version Python can installed using following command: Verify installation checking Python version: don’t R installed configured, just run following:","code":"sudo apt-get update -y python3 --version sudo apt-get upgrade python3 sudo apt-get install python3 python3 --version # Install R sudo apt-get install r-base"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-windows","dir":"Articles","previous_headings":"Python Installation","what":"On Windows","title":"Calling BFI from Python","text":"default, Python usually installed Windows. However, can check exists system running one line command command prompt. Go Start enter cmd search bar, click Command Prompt. Enter command python --version python3 --version command prompt. download Python, go official Python download website Windows: https://www.python.org. Find stable Python 3 release, download executable file system appropriate link. installer downloaded, open/run Python installer install Python. Select Add Python 3.x PATH checkbox, enables users launch Python command line, select Install Now. installation complete, can verify whether Python installation successful command line. Enter command python --version python3 --version command prompt. ’s assumed R also installed system. don’t R installed, just visit CRAN downloads (https://cran.r-project.org) get last version.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"installation-of-required-modules","dir":"Articles","previous_headings":"","what":"Installation of required modules","title":"Calling BFI from Python","text":"required modules installed PIP. PIP (Python package manager) helps us install use various packages/modules Python programming. Install latest version PIP required modules running following commands different systems.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-macos-1","dir":"Articles","previous_headings":"Installation of required modules","what":"On MacOS","title":"Calling BFI from Python","text":"Install/Upgrade latest version PIP running Install required modules running following commands","code":"# Installing PIP python3 -m pip install --user --upgrade pip # Installing the 'pandas' module pip3 install pandas  # Installing the 'numpy' module pip3 install numpy  # Installing the 'rpy2' module pip3 install rpy2"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-ubuntu-1","dir":"Articles","previous_headings":"Installation of required modules","what":"On Ubuntu","title":"Calling BFI from Python","text":"install PIP use code Verify successfully installed PIP running Now, install required modules typing following commands lines installation modules install , use following: Finally, use show command verify whether module now part Python packages:","code":"# Installing PIP sudo apt-get install python3-pip pip3 -V # Installing the 'pandas' module sudo pip3 install pandas  # Installing the 'numpy' module sudo pip3 install numpy  # Installing the 'rpy2' module sudo pip3 install rpy2 # Installing the 'pandas' module sudo apt-get install python3-pandas  # Installing the 'numpy' module sudo apt-get install python3-numpy  # Installing the 'rpy2' module sudo apt-get install python3-rpy2 pip3 show pandas pip3 show numpy pip3 show rpy2"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-windows-1","dir":"Articles","previous_headings":"Installation of required modules","what":"On Windows","title":"Calling BFI from Python","text":"Usually, PIP automatically installed using Python downloaded https://www.python.org. followed previous steps provided vignette, PIP installed system. check PIP already installed Windows, open command line , type pip -V, press Enter. PIP installed: First download get-pip.py folder computer. , open command prompt navigate folder containing get-pip.py installer. Finally, run following command: PIP now installed successfully. receive ‘file found’ error, double check directory path file. can use dir command view entire contents directory. information can found : https://pip.pypa.io/en/stable/installation. Now, install required modules running following commands: Now, can start coding Python using Python’s command-line interpreter IDLE application. Go Start enter python search bar. can see Python 3.x IDLE can used coding. Open one follow following steps.","code":"python get-pip.py # Installing the 'pandas' module pip3 install pandas  # Installing the 'numpy' module pip3 install numpy  # Installing the 'rpy2' module pip3 install rpy2"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"Python","dir":"Articles","previous_headings":"","what":"Python script","title":"Calling BFI from Python","text":"assumed required packages properly installed, case Google Colab. Now move work rpy2 package inside Python script! Python script, first go Python Environment typing following command terminal window (skip line already Google Colab): now, following codes run Python environment. want copy codes go last section.","code":"python3"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"importing-python-modules-and-functions","dir":"Articles","previous_headings":"Python script","what":"Importing Python modules and functions","title":"Calling BFI from Python","text":"Use following codes import required Python modules: using following codes imports required functions importr() data():","code":"# import 'pandas' package import pandas as pd  # import 'numpy' package import numpy as np                  # import 'rpy2' package import rpy2 from rpy2.robjects.packages import importr, data from rpy2.robjects.vectors import StrVector from rpy2.robjects import numpy2ri, pandas2ri # activation of the automatic conversion of 'numpy' and 'pandas' objects into rpy2 objects numpy2ri.activate()    pandas2ri.activate()"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"installing-r-packages-from-cran-and-github","dir":"Articles","previous_headings":"Python script","what":"Installing R packages from CRAN and GitHub:","title":"Calling BFI from Python","text":"First load packages preinstalled R using importr() follows: install R packages stats devtools CRAN typing Now load installed packages using","code":"# import R's \"utils\" package utils = importr('utils')  # import R's \"base\" package base = importr('base') utils.chooseCRANmirror(ind=1)  # which selects the first mirror in the list package_names = ('stats', 'devtools') utils.install_packages(StrVector(package_names)) stats = importr('stats') devtools = importr('devtools')"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"installing-the-bfi-package-from-github","dir":"Articles","previous_headings":"Python script","what":"Installing the BFI package from GitHub","title":"Calling BFI from Python","text":"BFI package can installed loaded using following lines:","code":"# Installing the 'BFI' package devtools.install_github(\"hassanpazira/BFI\", force = True)  # Loading the package BFI = importr('BFI')"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"Calling BFI from Python","text":"Now generate two datasets independently Gaussian distribution, apply main functions BFI package datasets:","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"data-simulation-for-two-local-centers","dir":"Articles","previous_headings":"Examples","what":"Data Simulation for two local centers","title":"Calling BFI from Python","text":"First generate 30 samples randomly Gaussian distribution 3 covariates: generate randomly 50 samples Gaussian distribution 3 covariates:","code":"# model parameters: 'theta' and 'p' are assumed to be the same for both centers: theta = np.array([1, 2, 3, 4, 0.75])   # intercept is theta[0], sigma2 is theta[4] p = 3     # number of regression parameters without intercept  # Center 1: n1 = 30   # sample size of center 1 X1 = np.random.normal(size=(n1, p))  X1.shape   # dimension of X1 X1 = pd.DataFrame(X1, columns=['X1', 'X2', 'X3']) mu1 = theta[0] + np.dot(X1, np.delete(theta, [0, 4]))  # for gaussian: \\eta = \\mu  X1 = pandas2ri.py2rpy(X1)   # == base.as_data_frame(X1) y1 = np.random.normal(loc=mu1, scale=np.sqrt(theta[4])) # Center 2: n2 = 50   # sample size of center 2 X2 = np.random.normal(size=(n2, p)) X2 = pd.DataFrame(X2, columns=['X1', 'X2', 'X3']) mu2 = theta[0] + np.dot(X2, np.delete(theta, [0, 4])) X2 = pandas2ri.py2rpy(X2) y2 = np.random.normal(loc=mu2, scale=np.sqrt(theta[4]))"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"map-estimates-at-the-local-centers","dir":"Articles","previous_headings":"Examples","what":"MAP estimates at the local centers","title":"Calling BFI from Python","text":"following compute Maximum Posterior (MAP) estimators parameters center 1: Obtaining MAP estimators parameters center 2 using following:","code":"# Creating an inverse covariance matrix for a Gaussian prior for center 1 Lambda1 = BFI.inv_prior_cov(X1, 0.01, 'gaussian') fit1 = BFI.MAP_estimation(y1, X1, 'gaussian', Lambda1) print(fit1) theta_hat1 = fit1.rx2(\"theta_hat\") # MAP estimates of the intercept and coefficients A_hat1 = fit1.rx2(\"A_hat\")         # minus the curvature matrix summary_1 = BFI.summary_bfi(fit1, cur_mat = True) # Creating an inverse covariance matrix for Gaussian prior for center 2 Lambda2 = BFI.inv_prior_cov(X2, 0.01, 'gaussian') # MAP estimates fit2 = BFI.MAP_estimation(y2, X2, 'gaussian', Lambda2) theta_hat2 = fit2.rx2(\"theta_hat\") # MAP estimates of the parameters A_hat2 = fit2.rx2(\"A_hat\")         # minus the curvature matrix around 'theta_hat2' summary_2 = BFI.summary_bfi(fit2, cur_mat = True)"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"bfi-at-central-center","dir":"Articles","previous_headings":"Examples","what":"BFI at central center","title":"Calling BFI from Python","text":"","code":"theta_hats = base.list(theta_hat1, theta_hat2) A_hats = base.list(A_hat1, A_hat2) Lambda1 = pd.DataFrame(Lambda1, index=fit1.rx2(\"names\"), columns=fit1.rx2(\"names\")) Lambda2 = pd.DataFrame(Lambda2, index=fit2.rx2(\"names\"), columns=fit2.rx2(\"names\")) Lambdas = base.list(Lambda1, Lambda2) fit_bfi = BFI.bfi(theta_hats, A_hats, Lambdas) print(fit_bfi) summary_bfi = BFI.summary_bfi(fit_bfi, cur_mat = True)"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"datasets-included-in-the-bfi-package","dir":"Articles","previous_headings":"Examples","what":"Datasets included in the BFI package","title":"Calling BFI from Python","text":"find list datasets included package run: order use datasets available BFI package, use following codes: end, use following deactivate automatic conversion:","code":"print(utils.data(package = \"BFI\")) Nurses = data(BFI).fetch('Nurses')['Nurses']  # is equivalent to BFI::Nurses in R print(\"Dimension of the 'Nurses' data: \\n\", base.dim(Nurses)) print(\"Colnames of the 'Nurses' data: \\n\", base.colnames(Nurses))  trauma = data(BFI).fetch('trauma')['trauma']  # is equivalent to BFI::trauma in R print(\"Dimension of the 'trauma' data: \\n\", base.dim(trauma)) print(\"Colnames of the 'trauma' data: \\n\", base.colnames(trauma)) numpy2ri.deactivate() pandas2ri.deactivate()"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"allcodes","dir":"Articles","previous_headings":"","what":"All codes together","title":"Calling BFI from Python","text":"need codes copy paste example Google Colab, codes:","code":"# import 'pandas' package import pandas as pd  # import 'numpy' package import numpy as np                  # import 'rpy2' package import rpy2                    from rpy2.robjects.packages import importr, data from rpy2.robjects.vectors import StrVector from rpy2.robjects import numpy2ri, pandas2ri # activation of the automatic conversion of 'numpy' and 'pandas' objects into rpy2 objects numpy2ri.activate()    pandas2ri.activate()  # import R's \"utils\" package utils = importr('utils')  # import R's \"base\" package base = importr('base')  utils.chooseCRANmirror(ind=1)  # which selects the first mirror in the list package_names = ('stats', 'devtools') utils.install_packages(StrVector(package_names))  # loading the installed packages stats = importr('stats') devtools = importr('devtools')  # Installing the 'BFI' package devtools.install_github(\"hassanpazira/BFI\", force = True)  # Loading the package BFI = importr('BFI')  # Examples  # model parameters: 'theta' and 'p' are assumed to be the same for both centers: theta = np.array([1, 2, 3, 4, 0.75])   # intercept is theta[0], sigma2 is theta[4] p = 3     # number of regression parameters without intercept  # Data Simulation for center 1 n1 = 30   # sample size of center 1 X1 = np.random.normal(size=(n1, p))  X1.shape   # dimension of X1 X1 = pd.DataFrame(X1, columns=['X1', 'X2', 'X3']) mu1 = theta[0] + np.dot(X1, np.delete(theta, [0, 4]))  # for gaussian: \\eta = \\mu  X1 = pandas2ri.py2rpy(X1)   # == base.as_data_frame(X1) y1 = np.random.normal(loc=mu1, scale=np.sqrt(theta[4]))  # Data Simulation for center 2 n2 = 50   # sample size of center 2 X2 = np.random.normal(size=(n2, p)) X2 = pd.DataFrame(X2, columns=['X1', 'X2', 'X3']) mu2 = theta[0] + np.dot(X2, np.delete(theta, [0, 4])) X2 = pandas2ri.py2rpy(X2) y2 = np.random.normal(loc=mu2, scale=np.sqrt(theta[4]))  # MAP estimates at center 1 # Creating an inverse covariance matrix for a Gaussian prior for center 1 Lambda1 = BFI.inv_prior_cov(X1, 0.01, 'gaussian') fit1 = BFI.MAP_estimation(y1, X1, 'gaussian', Lambda1) print(fit1) theta_hat1 = fit1.rx2(\"theta_hat\") # MAP estimates of the intercept and coefficients A_hat1 = fit1.rx2(\"A_hat\")         # minus the curvature matrix summary_1 = BFI.summary_bfi(fit1, cur_mat = True)  # MAP estimates at center 2 # Creating an inverse covariance matrix for Gaussian prior for center 2 Lambda2 = BFI.inv_prior_cov(X2, 0.01, 'gaussian') # MAP estimates fit2 = BFI.MAP_estimation(y2, X2, 'gaussian', Lambda2) theta_hat2 = fit2.rx2(\"theta_hat\") # MAP estimates of the parameters A_hat2 = fit2.rx2(\"A_hat\")         # minus the curvature matrix around 'theta_hat2' summary_2 = BFI.summary_bfi(fit2, cur_mat = True)  # BFI at central center theta_hats = base.list(theta_hat1, theta_hat2) A_hats = base.list(A_hat1, A_hat2) Lambda1 = pd.DataFrame(Lambda1, index=fit1.rx2(\"names\"), columns=fit1.rx2(\"names\")) Lambda2 = pd.DataFrame(Lambda2, index=fit2.rx2(\"names\"), columns=fit2.rx2(\"names\")) Lambdas = base.list(Lambda1, Lambda2) fit_bfi = BFI.bfi(theta_hats, A_hats, Lambdas) print(fit_bfi) summary_bfi = BFI.summary_bfi(fit_bfi, cur_mat = True)  # To find a list of all datasets included in the package: print(utils.data(package = \"BFI\"))  Nurses = data(BFI).fetch('Nurses')['Nurses'] print(\"Dimension of the 'Nurses' data: \\n\", base.dim(Nurses)) print(\"Colnames of the 'Nurses' data: \\n\", base.colnames(Nurses))  trauma = data(BFI).fetch('trauma')['trauma'] print(\"Dimension of the 'trauma' data: \\n\", base.dim(trauma)) print(\"Colnames of the 'trauma' data: \\n\", base.colnames(trauma))"},{"path":"https://hassanpazira.github.io/BFI/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Hassan Pazira. Author, maintainer. Marianne . Jonker. Author. Anthony C.C. Coolen. Author.","code":""},{"path":"https://hassanpazira.github.io/BFI/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pazira H, Jonker MA, Coolen AC (2023). “BFI: Bayesian Federated Inference.” Journal Statistical Software, 0(0), 0. https://hassanpazira.github.io/BFI.","code":"@Article{,   title = {{BFI}: Bayesian Federated Inference},   author = {Hassan Pazira and Marianne A. Jonker and Anthony C.C. Coolen},   journal = {Journal of Statistical Software},   year = {2023},   volume = {0},   number = {0},   pages = {0},   url = {https://hassanpazira.github.io/BFI}, }"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"bfi-","dir":"","previous_headings":"","what":"Bayesian Federated Inference","title":"Bayesian Federated Inference","text":"Bayesian Federated Inference","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Bayesian Federated Inference","text":"Due limited size available data sets especially rare diseases, sometimes challenging identify relevant predictive features using multivariable statistical analysis. issue may resolved combining data multiple centers one centralized location without sharing data , difficult reality privacy security concerns. address challenges, developed implemented Bayesian Federated Inference (BFI) framework multicenter data. aims leverage statistical power larger (combined) data sets without requiring data aggregated one location. BFI framework allows center using local data infer optimal parameter values well additional features posterior parameter distribution able gather information captured alternative techniques. One benefit BFI alternative approaches , one inference cycle across centers required BFI. R package called BFI created perform Bayesian Federated Inference. following instructions install development version BFI package computer.","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"install-r-and-rstudio","dir":"","previous_headings":"","what":"Install R and RStudio","title":"Bayesian Federated Inference","text":"First, need install R RStudio: Install R Install RStudio Desktop (R installed) details installing R RStudio, see page. need help learning R, see RStudio Education.","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"install-bfi-package","dir":"","previous_headings":"","what":"Install BFI package","title":"Bayesian Federated Inference","text":"order install BFI package directly Github, need devtools package. Invoke R RStudio type (Console) load typing: Next, install BFI follows: package can now loaded R used :","code":"if(!require(devtools)) {install.packages(\"devtools\")} library(devtools) devtools::install_github(\"hassanpazira/BFI\", force = TRUE) library(BFI)"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"update","dir":"","previous_headings":"","what":"Update","title":"Bayesian Federated Inference","text":"latest version BFIpackage 1.0.0. check current version BFI installed R library, use:","code":"packageVersion(\"BFI\")"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"details","dir":"","previous_headings":"","what":"Details","title":"Bayesian Federated Inference","text":"BFI package provides several functions, important following two main functions: MAP.estimation(): used centers, result sent central server. bfi(): used central server. access R documentation functions, example bfi(), enter following command:","code":"help(bfi, package = \"BFI\")    # or, equivalently, after loading the BFI package  ?bfi"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Bayesian Federated Inference","text":"Let’s look following example see BFI package can used. examples details look BFI vignette typing use vignette(\"BFI\") see BFI vignette Help tab RStudio. Now, generate two independent (local) data sets Gaussian distribution, apply package see works. First apply function MAP.estimation() local data, apply bfi() function aggregated results.","code":"devtools::install_github(\"hassanpazira/BFI\", dependencies = TRUE, build_vignettes = TRUE, force = TRUE) browseVignettes(\"BFI\")  # to see all vignettes from the BFI package in an HTML browser. #------------- # y ~ Gaussian #------------- # model assumptions: p     <- 3                     # number of coefficients without intercept theta <- c(1, rep(2, p), 1.5)  # regression coefficients (theta[1] is the intercept) and sigma2 = 1.5  #----------------------------------- # Data simulation for local center 1 #----------------------------------- n1   <- 30                                       # sample size of center 1 X1   <- data.frame(matrix(rnorm(n1 * p), n1, p)) # continuous variables # linear predictor: eta1 <- theta[1] + as.matrix(X1) \\%*\\% theta[2:4] # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu1  <- gaussian()$linkinv(eta1) y1   <- rnorm(n1, mu1, sd = sqrt(theta[5]))  #----------------------------------- # Data simulation for local center 2 #----------------------------------- n2   <- 50                                       # sample size of center 2 X2   <- data.frame(matrix(rnorm(n2 * p), n2, p)) # continuous variables # linear predictor: eta2 <- theta[1] + as.matrix(X2) \\%*\\% theta[2:4] # inverse of the link function: mu2  <- gaussian()$linkinv(eta2) y2   <- rnorm(n2, mu2, sd = sqrt(theta[5]))  #--------------------- # Load the BFI package #--------------------- library(BFI)  #--------------------------- # Inverse Covariance Matrix #--------------------------- # Creating the inverse covariance matrix for the Gaussian prior distribution: Lambda <- inv.prior.cov(X1, lambda=0.05, family=gaussian) # the same for both centers  #-------------------------- # MAP estimates at center 1 #-------------------------- fit1       <- MAP.estimation(y1, X1, family=gaussian, Lambda) theta_hat1 <- fit1$theta_hat # intercept and coefficient estimates A_hat1     <- fit1$A_hat     # minus the curvature matrix  #-------------------------- # MAP estimates at center 2 #-------------------------- fit2       <- MAP.estimation(y2, X2, family=gaussian, Lambda) theta_hat2 <- fit2$theta_hat A_hat2     <- fit2$A_hat  #---------------------- # BFI at central center #---------------------- A_hats     <- list(A_hat1, A_hat2) theta_hats <- list(theta_hat1, theta_hat2) bfi        <- bfi(theta_hats, A_hats, Lambda) summary(bfi, cur_mat=TRUE)  #-------------------- # Stratified analysis #-------------------- # Stratified analysis when 'intercept' varies across two centers: newLambda1 <- inv.prior.cov(X1, lambda=c(0.1, 0.3), family=gaussian, stratified=TRUE, strat_par = 1) # 'newLambda1' is used the prior for combined data and 'Lambda' is used the prior for locals bfi(theta_hats, A_hats, list(Lambda, newLambda1), stratified=TRUE, strat_par=1)  # Stratified analysis when 'sigma2' varies across two centers: newLambda2 <- inv.prior.cov(X1, lambda=c(0.1, 0.3), family=gaussian, stratified=TRUE, strat_par = 2) # 'newLambda2' is used the prior for combined data and 'Lambda' is used the prior for locals bfi(theta_hats, A_hats, list(Lambda, newLambda2), stratified=TRUE, strat_par=2)  # Stratified analysis when 'intercept' and 'sigma2' vary across 2 centers: newLambda3 <- inv.prior.cov(X1, lambda=c(0.1, 0.2, 0.3), family=gaussian, stratified=TRUE, strat_par = c(1, 2)) # 'newLambda3' is used the prior for combined data and 'Lambda' is used the prior for locals bfi(theta_hats, A_hats, list(Lambda, newLambda3), stratified=TRUE, strat_par=1:2)"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Bayesian Federated Inference","text":"cite BFI publications, please use:","code":"citation(\"BFI\")"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Bayesian Federated Inference","text":"technical papers package: Generalized Linear Models (GLMs) Survival Models","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"contact","dir":"","previous_headings":"","what":"Contact","title":"Bayesian Federated Inference","text":"find errors, suggestions, like request something added, please file issue issue report send email : hassan.pazira@radboudumc.nl.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal BFI Functions — BFI-internal","title":"Internal BFI Functions — BFI-internal","text":"Internal BFI functions.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-internal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Internal BFI Functions — BFI-internal","text":"Hassan Pazira","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-internal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal BFI Functions — BFI-internal","text":"functions intended use users.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Federated Inference — BFI-package","title":"Bayesian Federated Inference — BFI-package","text":"Bayesian Federated Inference method combines inference results different (medical) centers without sharing data. version package, user can fit models specifying Gaussian Binomial (Logistic) families. package updated models soon.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Federated Inference — BFI-package","text":"MAP.estimation bfi main functions. functions utility functions. examples provided vignettes accompanying package order show package can applied real data. vignettes can found package website https://hassanpazira.github.io/BFI/ within R package installed, e.g. via vignette(\"BFI\", package = \"BFI\").","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian Federated Inference — BFI-package","text":"Hassan Pazira, Marianne . Jonker, Anthony C.C. Coolen Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Federated Inference — BFI-package","text":"Jonker M.., Pazira H. Coolen .C.C. (2023). Bayesian Federated Inference Statistical Models, Statistics Medicine, Vol. 0(0), 0-0. <https://doi.org/10.48550/arXiv.2302.07677>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Federated Inference — bfi","title":"Bayesian Federated Inference — bfi","text":"bfi function can used (central server) combine inference results separate data sets (without combining data) approximate inferred data sets merged. now function can handle linear logistic regression models, code models available near future. bfi command","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Federated Inference — bfi","text":"","code":"bfi(theta_hats = NULL, A_hats, Lambda, stratified = FALSE,     strat_par = NULL, center_spec = NULL)"},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Federated Inference — bfi","text":"theta_hats list \\(L\\) vectors maximum posteriori (MAP) estimates model parameters \\(L\\) centers. vectors must equal dimensions. See ‘Details’. A_hats list \\(L\\) (minus) curvature matrices \\(L\\) centers. matrices must equal dimensions. See ‘Details’. Lambda list \\(L+1\\) matrices. \\(k^{\\th}\\) matrix chosen inverse variance-covariance matrix Gaussian distribution used prior distribution center \\(k\\), \\(k=1,2,\\ldots,L\\). last matrix chosen variance-covariance matrix Gaussian prior (fictive) combined data set. stratified = FALSE, \\(L+1\\) matrices must equal dimensions. , stratified = TRUE, first \\(L\\) matrices must equal dimensions last matrix different (greater) dimention others. See ‘Details’. stratified logical flag performing stratified analysis. stratified = TRUE, parameter(s) selected strat_par argument allowed different across centers, except argument center_spec NULL. Default stratified = FALSE. See ‘Details’ ‘Examples’. strat_par one- two-element integer vector indicating stratification parameter(s). values \\(1\\) /\\(2\\) /used indicate ``intercept'' /``sigma2'' allowed vary, respectively. argument used stratified = TRUE center_spec = NULL. Default strat_par = NULL, stratified = TRUE, strat_par can NULL unless center specific variable. binomial family length vector one refers ``intercept'', value element \\(1\\). gaussian family vector can \\(1\\) indicating ``intercept'' , \\(2\\) indicating ``sigma2'' , c(\\(1\\), \\(2\\)) ``intercept'' ``sigma2''. See ‘Details’ ‘Examples’. center_spec vector \\(L\\) elements representing center specific variable. argument used stratified = TRUE strat_par = NULL. element represents specific feature corresponding center. must one specific value attribute center. vector numeric, characteristic factor vector. Note , order centers vector center_spec must list argument theta_hats. used data type argument center_spec must categorical. Default center_spec = NULL. See also ‘Details’ ‘Examples’.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Federated Inference — bfi","text":"bfi returns list containing following components: theta_hat vector estimates obtained combining inference results \\(L\\) centers 'BFI' methodology. intercept fitted every center stratified = FALSE, one general ``intercept'' vector, stratified = TRUE strat_par = 1, \\(L\\) different intercepts model, center one; A_hat minus curvature (Hessian) matrix obtained 'BFI' method combined model. stratified = TRUE, dimension matrix always greater stratified = FALSE. stratified = TRUE, elements -diagonal matrix can determined therefore NA; sd vector standard deviation estimates theta_hat obtained matrix A_hat, .e., vector equals sqrt(diag(solve(A_hat))) equals square root elements diagonal inverse A_hat matrix. stratified = TRUE, sd NULL matrix A_hat non-invertible due NA's.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Federated Inference — bfi","text":"bfi function implements BFI approach described paper Jonker et. al. (2023) given references. inference results gathered different (\\(L\\)) centers combined, BFI estimates model parameters curvature matrix evaluated point returned. inference result center must obtained using MAP.estimation function separately, results (coming different centers) compiled list used input bfi(). models different centers defined exactly way; among others, exactly covariates included models. parameter vectors defined exactly , \\(L\\) vectors matrices input lists theta_hat's A_hat's defined way (e.g., covariates need included models order). Note order elements lists theta_hats, A_hats Lambda, must respect centers, every list element \\(\\ell^{\\th}\\) position center \\(\\ell\\). also case vector center_spec. locations intercept = FALSE, stratified analysis possible anymore binomial family. stratified = FALSE, strat_par center_spec must NULL (defaults), stratified = TRUE one two must NULL. stratified = FALSE \\(L+1\\) matrices equal, sufficient give (list ) one matrix . cases stratified argument (TRUE FALSE), first \\(L\\) matrices equal, argument Lambda can list two matrices, fist matrix represents chosen variance-covariance matrix local centers second one chosen matrix combined data set. last matrix list argument Lambda can built function inv.prior.cov(). data type used argument center_spec continuous, one can use stratified = TRUE center_spec = NULL, set strat_par NULL (.e., \\(1\\), \\(2\\) \\((1, 2)\\)). Indeed, case, stratification parameter(s) given argument strat_par assumed different across centers.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Federated Inference — bfi","text":"Jonker M.., Pazira H. Coolen .C.C. (2023). Bayesian Federated Inference Statistical Models. Statistics Medicine, Vol. 0(0), 0-0. <https://doi.org/10.48550/arXiv.2302.07677>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian Federated Inference — bfi","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian Federated Inference — bfi","text":"","code":"############################################### ##  Example 1:  y ~ Binomial  (L=2 centers)  ## ###############################################  #------------------ # Model Assumption: #------------------ beta <- 1:4  # regression coefficients (beta[1] is the intercept)  #----------------------------------- # Data Simulation for Local Center 1 #----------------------------------- n1 <- 30                                           # sample size of center 1 X1 <- data.frame(x1=rnorm(n1),                     # continuous variable                  x2=sample(0:2, n1, replace=TRUE)) # categorical variable # make dummy variables X1x2_1 <- ifelse(X1$x2 == '1', 1, 0) X1x2_2 <- ifelse(X1$x2 == '2', 1, 0) X1$x2  <- as.factor(X1$x2) # linear predictor: eta1   <- beta[1] + X1$x1 * beta[2] + X1x2_1 * beta[3] + X1x2_2 * beta[4] # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu1    <- binomial()$linkinv(eta1) y1     <- rbinom(n1, 1, mu1)  #----------------------------------- # Data Simulation for Local Center 2 #----------------------------------- n2 <- 50                                           # sample size of center 2 X2 <- data.frame(x1=rnorm(n2),                     # continuous variable                  x2=sample(0:2, n2, replace=TRUE)) # categorical variable # make dummy variables: X2x2_1 <- ifelse(X2$x2 == '1', 1, 0) X2x2_2 <- ifelse(X2$x2 == '2', 1, 0) X2$x2  <- as.factor(X2$x2) # linear predictor: eta2   <- beta[1] + X2$x1 * beta[2] + X2x2_1 * beta[3] + X2x2_2 * beta[4] # inverse of the link function: mu2    <- binomial()$linkinv(eta2) y2     <- rbinom(n2, 1, mu2)  #--------------------- # Load the BFI package #--------------------- library(BFI)  #-------------------------- # MAP Estimates at Center 1 #-------------------------- # assume the same inverse covariance matrix (Lambda) for both centers: Lambda     <- inv.prior.cov(X1, lambda=0.01, family=binomial) fit1       <- MAP.estimation(y1, X1, family=binomial, Lambda) theta_hat1 <- fit1$theta_hat # intercept and coefficient estimates A_hat1     <- fit1$A_hat     # minus the curvature matrix  #-------------------------- # MAP Estimates at Center 2 #-------------------------- fit2       <- MAP.estimation(y2, X2, family=binomial, Lambda) theta_hat2 <- fit2$theta_hat A_hat2     <- fit2$A_hat  #---------------------- # BFI at Central Center #---------------------- A_hats     <- list(A_hat1, A_hat2) theta_hats <- list(theta_hat1, theta_hat2) bfi        <- bfi(theta_hats, A_hats, Lambda) class(bfi) #> [1] \"bfi\" summary(bfi, cur_mat=TRUE) #>  #> Summary of the model: #>  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.5619  0.4803 -0.3795   1.5032 #> x1            1.7501  0.5893  0.5951   2.9051 #> x21           2.3790  1.0047  0.4098   4.3482 #> x22           6.5729  2.7611  1.1612  11.9847 #>  #> Dispersion parameter (sigma2):  1  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      x1     x21     x22 #> (Intercept)      6.0830 -1.6618  1.6048  0.1364 #> x1              -1.6618  4.0760 -1.2093 -0.2001 #> x21              1.6048 -1.2093  1.6148  0.0000 #> x22              0.1364 -0.2001  0.0000  0.1464  #-------------------- # Stratified Analysis #-------------------- # By running the following line an error appears because when stratified = TRUE, # both 'strat_par' and 'center_spec' can not be NULL: # bfi(theta_hats, A_hats, Lambda, stratified=TRUE)  # By running the following line an error appears because when stratified = TRUE, # last matrix in 'Lambda' should not have the same dim. as the other local matrices: # bfi(theta_hats, A_hats, Lambda, stratified=TRUE, strat_par=1)  # Stratified analysis when 'intercept' varies across two centers: newLam <- inv.prior.cov(X1, lambda=c(0.1, 0.3), family=binomial, stratified=TRUE,                            strat_par = 1) bfi(theta_hats, A_hats, list(Lambda, newLam), stratified=TRUE, strat_par=1) #> $theta_hat #> (Intercept)_loc1 (Intercept)_loc2               x1              x21  #>       0.08796527       1.06508656       1.39971571       1.77619671  #>              x22  #>       2.05023884  #>  #> $A_hat #>                  (Intercept)_loc1 (Intercept)_loc2         x1        x21 #> (Intercept)_loc1       2.31443212               NA -0.2295431  0.7910415 #> (Intercept)_loc2               NA       3.95861670 -1.4322757  0.8137157 #> x1                    -0.22954306      -1.43227569  4.3660029 -1.2092994 #> x21                    0.79104151       0.81371565 -1.2092994  1.9047572 #> x22                    0.07284536       0.06356279 -0.2001401  0.0000000 #>                          x22 #> (Intercept)_loc1  0.07284536 #> (Intercept)_loc2  0.06356279 #> x1               -0.20014009 #> x21               0.00000000 #> x22               0.43640814 #>  #> $sd #> NULL #>  #> $family #> [1] \"binomial\" #>  #> $stratified #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"bfi\" # summary() does not work for the stratified analysis!   ############################################### ##  Example 2:  y ~ Gaussian  (L=3 centers)  ## ###############################################  #------------------- # Model Assumptions: #------------------- p     <- 3                     # number of coefficients without 'intercept' theta <- c(1, rep(2, p), 1.5)  # reg. coefficients (theta[1] is 'intercept') & 'sigma2' = 1.5  #----------------------------------- # Data Simulation for Local Center 1 #----------------------------------- n1   <- 30                                       # sample size of center 1 X1   <- data.frame(matrix(rnorm(n1 * p), n1, p)) # continuous variables # linear predictor: eta1 <- theta[1] + as.matrix(X1) %*% theta[2:4] # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu1  <- gaussian()$linkinv(eta1) y1   <- rnorm(n1, mu1, sd = sqrt(theta[5]))  #----------------------------------- # Data Simulation for Local Center 2 #----------------------------------- n2   <- 40                                       # sample size of center 2 X2   <- data.frame(matrix(rnorm(n2 * p), n2, p)) # continuous variables # linear predictor: eta2 <- theta[1] + as.matrix(X2) %*% theta[2:4] # inverse of the link function: mu2  <- gaussian()$linkinv(eta2) y2   <- rnorm(n2, mu2, sd = sqrt(theta[5]))  #----------------------------------- # Data Simulation for Local Center 3 #----------------------------------- n3   <- 50                                       # sample size of center 3 X3   <- data.frame(matrix(rnorm(n3 * p), n3, p)) # continuous variables # linear predictor: eta3 <- theta[1] + as.matrix(X3) %*% theta[2:4] # inverse of the link function: mu3  <- gaussian()$linkinv(eta3) y3   <- rnorm(n3, mu3, sd = sqrt(theta[5]))  #--------------------------- # Inverse Covariance Matrix #--------------------------- # Creating the inverse covariance matrix for the Gaussian prior distribution: Lambda <- inv.prior.cov(X1, lambda=0.05, family=gaussian) # the same for both centers  #-------------------------- # MAP Estimates at Center 1 #-------------------------- fit1       <- MAP.estimation(y1, X1, family=gaussian, Lambda) theta_hat1 <- fit1$theta_hat # intercept and coefficient estimates A_hat1     <- fit1$A_hat     # minus the curvature matrix  #-------------------------- # MAP Estimates at Center 2 #-------------------------- fit2       <- MAP.estimation(y2, X2, family=gaussian, Lambda) theta_hat2 <- fit2$theta_hat A_hat2     <- fit2$A_hat  #-------------------------- # MAP Estimates at Center 3 #-------------------------- fit3       <- MAP.estimation(y3, X3, family=gaussian, Lambda) theta_hat3 <- fit3$theta_hat A_hat3     <- fit3$A_hat  #---------------------- # BFI at Central Center #---------------------- A_hats     <- list(A_hat1, A_hat2, A_hat3) theta_hats <- list(theta_hat1, theta_hat2, theta_hat3) bfi        <- bfi(theta_hats, A_hats, Lambda) summary(bfi, cur_mat=TRUE) #>  #> Summary of the model: #>  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.9899  0.1087  0.7768   1.2030 #> X1            1.8996  0.1130  1.6780   2.1211 #> X2            2.1686  0.0970  1.9784   2.3589 #> X3            1.9879  0.1080  1.7762   2.1996 #>  #> Dispersion parameter (sigma2):  1.421  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      X1       X2      X3   sigma2 #> (Intercept)     84.8339 -3.6192   0.6598 -2.0589  -0.2855 #> X1              -3.6192 79.2750   5.0909 -7.4089  -0.5807 #> X2               0.6598  5.0909 106.9661 -6.7144  -0.6537 #> X3              -2.0589 -7.4089  -6.7144 86.8449  -0.5975 #> sigma2          -0.2855 -0.5807  -0.6537 -0.5975 240.7433  #-------------------- # Stratified Analysis #-------------------- # Stratified analysis when 'intercept' varies across two centers: newLam1 <- inv.prior.cov(X1, lambda=c(0.1,0.3), family=gaussian, stratified=TRUE,                          strat_par = 1, L=3) # 'newLam1' is used the prior for combined data and 'Lambda' is used the prior for locals bfi(theta_hats, A_hats, list(Lambda, newLam1), stratified=TRUE, strat_par=1) #> $theta_hat #> (Intercept)_loc1 (Intercept)_loc2 (Intercept)_loc3               X1  #>        1.0226053        0.8713524        1.0548295        1.9110883  #>               X2               X3           sigma2  #>        2.1679403        1.9727926        1.4191773  #>  #> $A_hat #>                  (Intercept)_loc1 (Intercept)_loc2 (Intercept)_loc3         X1 #> (Intercept)_loc1       23.5526833               NA               NA -1.8888921 #> (Intercept)_loc2               NA      27.27674262               NA  5.1438273 #> (Intercept)_loc3               NA               NA       34.2544325 -6.8741614 #> X1                     -1.8888921       5.14382734       -6.8741614 79.3250395 #> X2                      2.1038306       0.92062827       -2.3646713  5.0908951 #> X3                     -1.3830337      -7.54515847        6.8692758 -7.4088504 #> sigma2                 -0.1014047      -0.08751509       -0.0965792 -0.5806566 #>                           X2         X3       sigma2 #> (Intercept)_loc1   2.1038306 -1.3830337  -0.10140473 #> (Intercept)_loc2   0.9206283 -7.5451585  -0.08751509 #> (Intercept)_loc3  -2.3646713  6.8692758  -0.09657920 #> X1                 5.0908951 -7.4088504  -0.58065658 #> X2               107.0161295 -6.7143863  -0.65373046 #> X3                -6.7143863 86.8948954  -0.59748716 #> sigma2            -0.6537305 -0.5974872 240.99327085 #>  #> $sd #> NULL #>  #> $family #> [1] \"gaussian\" #>  #> $stratified #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"bfi\"  # Stratified analysis when 'sigma2' varies across two centers: newLam2 <- inv.prior.cov(X1, lambda=c(0.1,0.3), family=gaussian, stratified=TRUE,                          strat_par = 2, L=3) # 'newLam2' is used the prior for combined data and 'Lambda' is used the prior for locals bfi(theta_hats, A_hats, list(Lambda, newLam2), stratified=TRUE, strat_par=2) #> $theta_hat #> (Intercept)          X1          X2          X3 sigma2_loc1 sigma2_loc2  #>   0.9891168   1.8980866   2.1674635   1.9864492   1.2730337   1.4664521  #> sigma2_loc3  #>   1.4607929  #>  #> $A_hat #>             (Intercept)         X1          X2         X3 sigma2_loc1 #> (Intercept) 84.88385838 -3.6192261   0.6597875 -2.0589164  -0.1014047 #> X1          -3.61922613 79.3250395   5.0908951 -7.4088504  -0.2112137 #> X2           0.65978751  5.0908951 107.0161295 -6.7143863  -0.2337677 #> X3          -2.05891637 -7.4088504  -6.7143863 86.8948954  -0.1784639 #> sigma2_loc1 -0.10140473 -0.2112137  -0.2337677 -0.1784639  60.5057862 #> sigma2_loc2 -0.08751509 -0.2221618  -0.1992739 -0.2169459          NA #> sigma2_loc3 -0.09657920 -0.1472811  -0.2206889 -0.2020773          NA #>             sigma2_loc2 sigma2_loc3 #> (Intercept) -0.08751509  -0.0965792 #> X1          -0.22216179  -0.1472811 #> X2          -0.19927386  -0.2206889 #> X3          -0.21694587  -0.2020773 #> sigma2_loc1          NA          NA #> sigma2_loc2 80.54424266          NA #> sigma2_loc3          NA 100.5432420 #>  #> $sd #> NULL #>  #> $family #> [1] \"gaussian\" #>  #> $stratified #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"bfi\"  # Stratified analysis when 'intercept' and 'sigma2' vary across 2 centers: newLam3 <- inv.prior.cov(X1, lambda=c(0.1,0.2,0.3), family=gaussian, stratified=TRUE,                          strat_par = c(1, 2), L=3) # 'newLam3' is used the prior for combined data and 'Lambda' is used the prior for locals bfi(theta_hats, A_hats, list(Lambda, newLam3), stratified=TRUE, strat_par=1:2) #> $theta_hat #> (Intercept)_loc1 (Intercept)_loc2 (Intercept)_loc3               X1  #>        1.0217916        0.8713256        1.0548039        1.9083655  #>               X2               X3      sigma2_loc1      sigma2_loc2  #>        2.1657426        1.9700247        1.2730693        1.4663040  #>      sigma2_loc3  #>        1.4608343  #>  #> $A_hat #>                  (Intercept)_loc1 (Intercept)_loc2 (Intercept)_loc3         X1 #> (Intercept)_loc1       23.5526833               NA               NA -1.8888921 #> (Intercept)_loc2               NA      27.27674262               NA  5.1438273 #> (Intercept)_loc3               NA               NA       34.2544325 -6.8741614 #> X1                     -1.8888921       5.14382734       -6.8741614 79.4250395 #> X2                      2.1038306       0.92062827       -2.3646713  5.0908951 #> X3                     -1.3830337      -7.54515847        6.8692758 -7.4088504 #> sigma2_loc1            -0.1014047               NA               NA  2.1038306 #> sigma2_loc2                    NA      -0.08751509               NA  0.9206283 #> sigma2_loc3                    NA               NA       -0.0965792 -2.3646713 #>                           X2         X3 sigma2_loc1 sigma2_loc2 sigma2_loc3 #> (Intercept)_loc1  -1.3830337 -0.2337677  -0.1014047          NA          NA #> (Intercept)_loc2  -7.5451585 -0.1992739          NA -0.08751509          NA #> (Intercept)_loc3   6.8692758 -0.2206889          NA          NA  -0.0965792 #> X1                 5.0908951 -7.4088504  -0.2112137 -0.22216179  -0.1472811 #> X2               107.1161295 -6.7143863  -0.2337677 -0.19927386  -0.2206889 #> X3                -6.7143863 86.9948954  -0.1784639 -0.21694587  -0.2020773 #> sigma2_loc1       -0.2112137 -0.1784639  60.5057862          NA          NA #> sigma2_loc2       -0.2221618 -0.2169459          NA 80.54424266          NA #> sigma2_loc3       -0.1472811 -0.2020773          NA          NA 100.5432420 #>  #> $sd #> NULL #>  #> $family #> [1] \"gaussian\" #>  #> $stratified #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"bfi\"  #--------------------------- # Center Specific Covariates #--------------------------- newLam4 <- inv.prior.cov(X1, lambda=c(0.1, 0.2, 0.3), family=gaussian, stratified=TRUE,                          center_spec = c(3,1,3), L=3) bfi(theta_hats, A_hats, list(Lambda, newLam4), stratified=TRUE, center_spec = c(3,1,3)) #> $theta_hat #> (Intercept)_1 (Intercept)_3            X1            X2            X3  #>     0.8715877     1.0431902     1.9081828     2.1653001     1.9713403  #>        sigma2  #>     1.4191636  #>  #> $A_hat #>               (Intercept)_1 (Intercept)_3         X1          X2         X3 #> (Intercept)_1    0.87158767            NA  5.1438273   0.9206283 -7.5451585 #> (Intercept)_3            NA     1.0431902 -8.7630535  -0.2608408  5.4862421 #> X1               5.14382734    -8.7630535 79.4250395   5.0908951 -7.4088504 #> X2               0.92062827    -0.2608408  5.0908951 107.1161295 -6.7143863 #> X3              -7.54515847     5.4862421 -7.4088504  -6.7143863 86.9948954 #> sigma2          -0.08751509    -0.1979839 -0.5806566  -0.6537305 -0.5974872 #>                     sigma2 #> (Intercept)_1  -0.08751509 #> (Intercept)_3  -0.19798392 #> X1             -0.58065658 #> X2             -0.65373046 #> X3             -0.59748716 #> sigma2        240.99327085 #>  #> $sd #> NULL #>  #> $family #> [1] \"gaussian\" #>  #> $stratified #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"bfi\""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum A Posteriori estimation — MAP.estimation","title":"Maximum A Posteriori estimation — MAP.estimation","text":"MAP.estimation function used (local centers) compute Maximum Posterior (MAP) estimators parameters GLM soon Survival models.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum A Posteriori estimation — MAP.estimation","text":"","code":"MAP.estimation(y, X, family = gaussian, Lambda, intercept = TRUE,                initial = NULL, control = list())"},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum A Posteriori estimation — MAP.estimation","text":"y response vector. binomial family used, argument vector entries 0 (failure) 1 (success). Alternatively, response can matrix first column number “successes” second column number “failures”. X design matrix dimension \\(n \\times p\\), \\(p\\) number covariables predictors. family description error distribution link function used specify model. can character string naming family function result call family function (see family details). current version package, family model can gaussian (identity link function) binomial (logit link function). default gaussian family used. case linear regression model, family = gaussian, extra model parameter variance measurement error. Lambda inverse variance-covariance matrix Gaussian distribution used prior distribution model parameters. dimension matrix depends number columns X, type covariates (continuous / dichotomous categorical), family, intercept. However, Lambda can easily created inv.prior.cov(). intercept logical flag fitting intercept. intercept=TRUE (default), intercept fitted, .e., included model, intercept=FALSE set zero, .e., model. initial vector specifying initial values parameters optimized . length initial equal number model parameters thus, equal number rows columns Lambda. Since 'L-BFGS-B' method used algorithm, values always finite. Default vector zeros. control list control parameters. See ‘Details’.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum A Posteriori estimation — MAP.estimation","text":"MAP.estimation returns list containing following components: theta_hat vector corresponding maximum posteriori (MAP) estimates parameters; A_hat minus curvature (Hessian) matrix around point theta_hat. dimension matrix argument Lambda; sd vector standard deviation MAP estimates theta_hat, sqrt(diag(solve(A_hat))); Lambda inverse variance-covariance matrix Gaussian distribution used prior distribution parameters. exactly argument Lambda; formula formula applied; names names model parameters; n sample size; np number coefficients; value value minus log-likelihood posterior density evaluated theta_hat; family family object used.; intercept logical flag used fit intercept TRUE, set zero FALSE; convergence integer value used encode warnings errors related algorithm used fit model. values returned : 0 algorithm converged; 1 maximum number iterations ('maxit') reached; 2 Warning 'L-BFGS-B' method. See message value; control list control parameters used compute MAP estimates.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maximum A Posteriori estimation — MAP.estimation","text":"MAP.estimation function finds Maximum Posteriori (MAP) estimates model parameters maximizing log-posterior density respect parameters, .e., estimates equal values log-posterior density maximal (posterior mode). words, MAP.estimation() optimizes log-posterior density respect parameter vector obtain MAP estimates. addition model parameters, .e., coefficients (\\({\\beta}\\)'s) variance error (\\(\\sigma^2_e\\)), curvature matrix (Hessian log-posterior) estimated around mode. MAP.estimation function returns object class `bfi`. Therefore, summary() can used object returned MAP.estimation(). solve unconstrained bound-constrained optimization problems, MAP.estimation function utilizes optimization algorithm called Limited-memory Broyden-Fletcher-Goldfarb-Shanno Bound Constraints (L-BFGS-B), Byrd et. al. (1995). L-BFGS-B algorithm limited-memory “quasi-Newton” method iteratively updates parameter estimates approximating inverse Hessian matrix using gradient information history previous iterations. approach allows algorithm approximate curvature posterior distribution efficiently search optimal solution, makes computationally efficient problems large number variables. default, algorithm uses relative change objective function convergence criterion. change objective function iterations falls certain threshold (`factr`) algorithm considered converged. convergence can checked argument convergence output. See ‘Value’. case convergence issue, may necessary investigate adjust optimization parameters facilitate convergence. can done using initial control arguments. argument initial initial points interative optimization algorithm can changed, argument control list can supply following components: maxit: maximum number iterations. Default 100; factr: controls convergence 'L-BFGS-B' method. Convergence occurs reduction objective within factor machine tolerance. Default factr 1e7, gives tolerance 1e-9. exact tolerance can checked multiplying value .Machine$double.eps; pgtol: helps control convergence 'L-BFGS-B' method. tolerance projected gradient current search direction, .e., iteration stop maximum component projected gradient less equal pgtol, pgtol\\(\\geq 0\\). Default zero, check suppressed; trace: non-negative integer. positive, tracing information progress optimization produced. Higher values may produce tracing information: method 'L-BFGS-B' six levels tracing. understand exactly see source code optim function stats package; REPORT: frequency reports 'L-BFGS-B' method 'control$trace' positive. Default every 10 iterations; lmm: integer giving number BFGS updates retained 'L-BFGS-B' method. Default 5.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Maximum A Posteriori estimation — MAP.estimation","text":"Jonker M.., Pazira H. Coolen .C.C. (2023). Bayesian Federated Inference Statistical Models. Statistics Medicine, Vol. 0(0), 0-0. <https://doi.org/10.48550/arXiv.2302.07677> Byrd R.H., Lu P., Nocedal J. Zhu C. (1995). limited memory algorithm bound constrained optimization. SIAM Journal Scientific Computing, 16, 1190-1208. <https://doi.org/10.1137/0916069>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Maximum A Posteriori estimation — MAP.estimation","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum A Posteriori estimation — MAP.estimation","text":"","code":"#------------- # y ~ Gaussian #------------- # model assumption: theta <- c(1, 2, 2, 2, 1.5)  # model parameters: coefficients and sigma2 = 1.5  #---------------- # Data Simulation #---------------- n   <- 30   # sample size p   <- 3    # number of coefficients without intercept X   <- data.frame(matrix(rnorm(n * p), n, p)) # continuous variables # linear predictor: eta <- theta[1] + theta[2] * X$X1 + theta[3] * X$X2 + theta[4] * X$X3 # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu  <- gaussian()$linkinv(eta) y   <- rnorm(n, mu, sd = sqrt(theta[5]))  #--------------------- # Load the BFI package #--------------------- library(BFI)  #----------------------------------------------- # MAP estimations for theta and curvature matrix #----------------------------------------------- # MAP estimates with 'intercept' Lambda <- inv.prior.cov(X, lambda = c(0.1, 1), family = gaussian) (fit <- MAP.estimation(y, X, family = gaussian, Lambda)) #> $theta_hat #> (Intercept)          X1          X2          X3      sigma2  #>   1.3798270   1.5123814   1.9267104   2.0441168   0.9506079  #>  #> $A_hat #>             (Intercept)         X1         X2         X3     sigma2 #> (Intercept)  31.6587531 12.5517280 -4.1755719 -8.4683063 -0.2759874 #> X1           12.5517280 28.7161348 -5.8177797 -7.5384962 -0.3022097 #> X2           -4.1755719 -5.8177797 27.4951582 -2.3953327 -0.3851296 #> X3           -8.4683063 -7.5384962 -2.3953327 38.0031710 -0.4094611 #> sigma2       -0.2759874 -0.3022097 -0.3851296 -0.4094611 63.8019041 #>  #> $sd #> (Intercept)          X1          X2          X3      sigma2  #>   0.1990380   0.2109938   0.1972746   0.1707254   0.1252156  #>  #> $Lambda #>             (Intercept)  X1  X2  X3 sigma2 #> (Intercept)         0.1 0.0 0.0 0.0      0 #> X1                  0.0 0.1 0.0 0.0      0 #> X2                  0.0 0.0 0.1 0.0      0 #> X3                  0.0 0.0 0.0 0.1      0 #> sigma2              0.0 0.0 0.0 0.0      1 #>  #> $formula #> [1] y ~ X1 + X2 + X3 #>  #> $names #> [1] \"(Intercept)\" \"X1\"          \"X2\"          \"X3\"          \"sigma2\"      #>  #> $n #> [1] 30 #>  #> $np #> [1] 4 #>  #> $value #> [1] 31.58953 #>  #> $family #> [1] \"gaussian\" #>  #> $intercept #> [1] TRUE #>  #> $convergence #> [1] 0 #>  #> $control #> list() #>  #> attr(,\"class\") #> [1] \"bfi\" class(fit) #> [1] \"bfi\" summary(fit, cur_mat = TRUE) #>  #> Summary of the model: #>  #>    Formula: y ~ X1 + X2 + X3  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   1.3798  0.1990  0.9897   1.7699 #> X1            1.5124  0.2110  1.0988   1.9259 #> X2            1.9267  0.1973  1.5401   2.3134 #> X3            2.0441  0.1707  1.7095   2.3787 #>  #> Dispersion parameter (sigma2):  0.9506  #>                  log Lik Post:  -31.59  #>                   Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      X1      X2      X3  sigma2 #> (Intercept)     31.6588 12.5517 -4.1756 -8.4683 -0.2760 #> X1              12.5517 28.7161 -5.8178 -7.5385 -0.3022 #> X2              -4.1756 -5.8178 27.4952 -2.3953 -0.3851 #> X3              -8.4683 -7.5385 -2.3953 38.0032 -0.4095 #> sigma2          -0.2760 -0.3022 -0.3851 -0.4095 63.8019  # MAP estimates without 'intercept' Lambda <- inv.prior.cov(X, lambda = c(0.1, 1), family = gaussian, intercept = FALSE) (fit1 <- MAP.estimation(y, X, family = gaussian, Lambda, intercept = FALSE)) #> $theta_hat #>       X1       X2       X3   sigma2  #> 2.020553 1.795887 1.822268 2.327938  #>  #> $A_hat #>                X1         X2         X3     sigma2 #> X1     11.7853316 -2.3756767 -3.0783272 -0.4041856 #> X2     -2.3756767 11.2867487 -0.9781285 -0.3593104 #> X3     -3.0783272 -0.9781285 15.5776711 -0.3643882 #> sigma2 -0.4041856 -0.3593104 -0.3643882 69.3122642 #>  #> $sd #>        X1        X2        X3    sigma2  #> 0.3073722 0.3066939 0.2623144 0.1201590  #>  #> $Lambda #>         X1  X2  X3 sigma2 #> X1     0.1 0.0 0.0      0 #> X2     0.0 0.1 0.0      0 #> X3     0.0 0.0 0.1      0 #> sigma2 0.0 0.0 0.0      1 #>  #> $formula #> [1] y ~ X1 + X2 + X3 #>  #> $names #> [1] \"X1\"     \"X2\"     \"X3\"     \"sigma2\" #>  #> $n #> [1] 30 #>  #> $np #> [1] 3 #>  #> $value #> [1] 61.06847 #>  #> $family #> [1] \"gaussian\" #>  #> $intercept #> [1] FALSE #>  #> $convergence #> [1] 0 #>  #> $control #> list() #>  #> attr(,\"class\") #> [1] \"bfi\" summary(fit1, cur_mat = TRUE) #>  #> Summary of the model: #>  #>    Formula: y ~ X1 + X2 + X3  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>    Estimate Std.Dev CI 2.5% CI 97.5% #> X1   2.0206  0.3074  1.4181   2.6230 #> X2   1.7959  0.3067  1.1948   2.3970 #> X3   1.8223  0.2623  1.3081   2.3364 #>  #> Dispersion parameter (sigma2):  2.328  #>                  log Lik Post:  -61.07  #>                   Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>             X1      X2      X3  sigma2 #> X1     11.7853 -2.3757 -3.0783 -0.4042 #> X2     -2.3757 11.2867 -0.9781 -0.3593 #> X3     -3.0783 -0.9781 15.5777 -0.3644 #> sigma2 -0.4042 -0.3593 -0.3644 69.3123"},{"path":"https://hassanpazira.github.io/BFI/reference/Nurses.html","id":null,"dir":"Reference","previous_headings":"","what":"Nurses' stress in different hospitals — Nurses","title":"Nurses' stress in different hospitals — Nurses","text":"dataset comprises three-level simulated data extracted hypothetical study investigating stress levels within hospital settings. dataset focuses nurses working specific wards within various hospitals. includes several variables, nurse age (measured years), nurse experience (measured years), nurse gender (0 male, 1 female), ward type (0 general care, 1 special care), hospital size (0 small, 1 medium, 2 large). dataset package obtained original dataset leaving unused columns.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/Nurses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nurses' stress in different hospitals — Nurses","text":"","code":"data(Nurses)"},{"path":"https://hassanpazira.github.io/BFI/reference/Nurses.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Nurses' stress in different hospitals — Nurses","text":"https://multilevel-analysis.sites.uu.nl/datasets/","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/Nurses.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Nurses' stress in different hospitals — Nurses","text":"Hox, J., Moerbeek, M., van de Schoot, R. (2010). Multilevel Analysis: Techniques Applications, Second Edition (2nd ed.). Routledge. <https://doi.org/10.4324/9780203852279>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"inv.prior.cov builds diagonal inverse covariance matrix Gaussian prior distribution based design matrix covariates, takes account number regression parameters case categorical covariates.  case linear model, also includes row column variance measurement errors.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"","code":"inv.prior.cov(X, lambda = 1, L = 2, family = gaussian, intercept = TRUE,               stratified = FALSE, strat_par = NULL, center_spec = NULL)"},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"X design matrix dimension \\(n \\times p\\), \\(n\\) number samples observed, \\(p\\) number predictors/variables excluding intercept. lambda vector used diagonal (inverse covariance) matrix created inv.prior.cov(). length vector depends number columns X, type covariates (continuous/dichotomous categorical), family, whether intercept included model, whether stratified analysis desired. stratified = FALSE, lambda single positive number (values vector equal), vector two elements (first used regression parameters including ``intercept'' second ``sigma2''), vector length equal number model parameters. However, length lambda different stratified = TRUE, see ‘Details’ information. Default lambda = 1. L number centers. argument used stratified = TRUE. Default L = 2. See ‘Details’ ‘Examples’. family description error distribution link function used specify model. can character string naming family function result call family function (see family details). current version, family model can gaussian (identity link function) binomial (logit link function). default gaussian family used. case linear regression model, family = gaussian, extra model parameter variance measurement error. intercept logical flag intercept. changing intercept dimension inverse covariance matrix changes. intercept = TRUE (default), output matrix created inv.prior.cov() one row one column related intercept, intercept = FALSE, resulting matrix row column called intercept. stratified logical flag performing stratified analysis. stratified = TRUE, parameter(s) selected strat_par argument allowed different across centers. argument used designing inverse covariance matrix (fictive) combined data, .e., last matrix Lambda argument bfi(). inv.prior.cov() used analysis local centers (built \\(L\\) first matrices Lambda argument bfi()), argument FALSE, even BFI analysis stratified. Default stratified = FALSE. See ‘Details’ ‘Examples’. strat_par one- two-element integer vector indicating stratification parameter(s). values \\(1\\) /\\(2\\) /used indicate ``intercept'' /``sigma2'' allowed vary, respectively. argument used stratified = TRUE. Default strat_par = NULL, stratified = TRUE, strat_par can NULL. binomial family length vector one refers ``intercept'', value element \\(1\\). gaussian vector can \\(1\\) indicating ``intercept'' , \\(2\\) indicating ``sigma2'' , c(\\(1\\), \\(2\\)) ``intercept'' ``sigma2''. See ‘Examples’. center_spec vector \\(L\\) elements representing center specific variable. argument used stratified = TRUE strat_par = NULL. element represents specific feature corresponding center. must one specific value attribute center. vector numeric, characteristic factor vector. Note , order centers vector center_spec must list argument theta_hats function bfi(). used data type argument center_spec must categorical. Default center_spec = NULL. See also ‘Details’ ‘Examples’.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"inv.prior.cov creates diagonal matrix vector lambda diagonal. argument stratified = TRUE used construct matrix prior density case stratification fictive combined data. Never used construction matrix analysis centers. stratified = FALSE, length vector lambda depends covariate matrix X, family, whether ``intercept'' included model. example, design matrix X p columns continuous dichotomous covariates, family = gaussian, intercept = TRUE, lambda \\(p+2\\) elements. case, X categorical covariate \\(q>2\\) categories, length lambda increases \\(q-2\\). values lambda non-negative represent inverse variance Gaussian prior. Note , values vector lambda equal, one value enough given entry. lambda scalar, function inv.prior.cov sets value diagonal equal lambda. linear regression model last parameter assumed inverse variance prior distribution measurement error. lambda two dimensional, first value used prior regression parameters second inverse variance prior distribution measurement error. stratified = TRUE length vector lambda equal number parameters combined model. intercept = FALSE, binomial family stratified analysis possible therefore stratified can TRUE. stratified = FALSE, strat_par center_spec must NULL (defaults), stratified = TRUE one two must NULL. output inv.prior.cov() can used main functions MAP.estimation() bfi().","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"inv.prior.cov returns diagonal matrix. dimension matrix depends number columns X, type covariates (continuous/dichotomous categorical), family, intercept.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"Jonker M.., Pazira H. Coolen .C.C. (2023). Bayesian Federated Inference Statistical Models, Statistics Medicine, Vol. 0(0), 0-0. <https://doi.org/10.48550/arXiv.2302.07677>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"","code":"#---------------- # Data Simulation #---------------- X <- data.frame(x1=rnorm(50),                     # standard normal variable                 x2=sample(0:2, 50, replace=TRUE), # categorical variable                 x3=sample(0:1, 50, replace=TRUE)) # dichotomous variable X$x2 <- as.factor(X$x2) X$x3 <- as.factor(X$x3)  #--------------------- # Load the BFI package #--------------------- library(BFI)  # The (inverse) variance value (lambda=0.05) is assumed to be # the same for Gaussian prior of all parameters (for non-stratified)  #------------------------------------------------- # Inverse Covariance Matrix for the Gaussian prior #------------------------------------------------- # y ~ Binomial with 'intercept' inv.prior.cov(X, lambda=0.05, family=binomial) # returns a 5-by-5 matrix #>             (Intercept)   x1  x21  x22  x31 #> (Intercept)        0.05 0.00 0.00 0.00 0.00 #> x1                 0.00 0.05 0.00 0.00 0.00 #> x21                0.00 0.00 0.05 0.00 0.00 #> x22                0.00 0.00 0.00 0.05 0.00 #> x31                0.00 0.00 0.00 0.00 0.05  # y ~ Binomial without 'intercept' inv.prior.cov(X, lambda=0.05, family=\"binomial\", intercept = FALSE) # a 4-by-4 matrix #>       x1  x21  x22  x31 #> x1  0.05 0.00 0.00 0.00 #> x21 0.00 0.05 0.00 0.00 #> x22 0.00 0.00 0.05 0.00 #> x31 0.00 0.00 0.00 0.05  # y ~ Gaussian with 'intercept' inv.prior.cov(X, lambda=0.05, family=gaussian) # returns a 6-by-6 matrix #>             (Intercept)   x1  x21  x22  x31 sigma2 #> (Intercept)        0.05 0.00 0.00 0.00 0.00   0.00 #> x1                 0.00 0.05 0.00 0.00 0.00   0.00 #> x21                0.00 0.00 0.05 0.00 0.00   0.00 #> x22                0.00 0.00 0.00 0.05 0.00   0.00 #> x31                0.00 0.00 0.00 0.00 0.05   0.00 #> sigma2             0.00 0.00 0.00 0.00 0.00   0.05  #-------------------- # Stratified analysis #-------------------- # y ~ Binomial when 'intercept' varies across 3 centers: inv.prior.cov(X, lambda=c(.2, 1), family=binomial, stratified=TRUE, strat_par = 1, L = 3) #>                  (Intercept)_loc1 (Intercept)_loc2 (Intercept)_loc3 x1 x21 x22 #> (Intercept)_loc1              0.2              0.0              0.0  0   0   0 #> (Intercept)_loc2              0.0              0.2              0.0  0   0   0 #> (Intercept)_loc3              0.0              0.0              0.2  0   0   0 #> x1                            0.0              0.0              0.0  1   0   0 #> x21                           0.0              0.0              0.0  0   1   0 #> x22                           0.0              0.0              0.0  0   0   1 #> x31                           0.0              0.0              0.0  0   0   0 #>                  x31 #> (Intercept)_loc1   0 #> (Intercept)_loc2   0 #> (Intercept)_loc3   0 #> x1                 0 #> x21                0 #> x22                0 #> x31                1  # y ~ Gaussian when 'intercept' and 'sigma2' vary across 2 centers; y ~ Gaussian inv.prior.cov(X, lambda=c(1, 2, 3), family=gaussian, stratified=TRUE, strat_par = c(1, 2)) #>                  (Intercept)_loc1 (Intercept)_loc2 x1 x21 x22 x31 sigma2_loc1 #> (Intercept)_loc1                1                0  0   0   0   0           0 #> (Intercept)_loc2                0                1  0   0   0   0           0 #> x1                              0                0  2   0   0   0           0 #> x21                             0                0  0   2   0   0           0 #> x22                             0                0  0   0   2   0           0 #> x31                             0                0  0   0   0   2           0 #> sigma2_loc1                     0                0  0   0   0   0           3 #> sigma2_loc2                     0                0  0   0   0   0           0 #>                  sigma2_loc2 #> (Intercept)_loc1           0 #> (Intercept)_loc2           0 #> x1                         0 #> x21                        0 #> x22                        0 #> x31                        0 #> sigma2_loc1                0 #> sigma2_loc2                3  # y ~ Gaussian when 'sigma2' varies across 2 centers (with 'intercept') inv.prior.cov(X, lambda=c(1, 2, 3), family=gaussian, stratified=TRUE, strat_par = 2) #>             (Intercept) x1 x21 x22 x31 sigma2_loc1 sigma2_loc2 #> (Intercept)           1  0   0   0   0           0           0 #> x1                    0  2   0   0   0           0           0 #> x21                   0  0   2   0   0           0           0 #> x22                   0  0   0   2   0           0           0 #> x31                   0  0   0   0   2           0           0 #> sigma2_loc1           0  0   0   0   0           3           0 #> sigma2_loc2           0  0   0   0   0           0           3  # y ~ Gaussian when 'sigma2' varies across 2 centers (without 'intercept') inv.prior.cov(X, lambda=c(2, 3), family=gaussian, intercept = FALSE, stratified=TRUE,               strat_par = 2) #>             x1 x21 x22 x31 sigma2_loc1 sigma2_loc2 #> x1           2   0   0   0           0           0 #> x21          0   2   0   0           0           0 #> x22          0   0   2   0           0           0 #> x31          0   0   0   2           0           0 #> sigma2_loc1  0   0   0   0           3           0 #> sigma2_loc2  0   0   0   0           0           3  #-------------------------- # Center specific covariate #-------------------------- # center specific covariate has K=2 categories across 4 centers; y ~ Binomial inv.prior.cov(X, lambda=c(0.1:2), family=binomial, stratified=TRUE,               center_spec = c(\"Iran\",\"Netherlands\",\"Netherlands\",\"Iran\"), L=4) #>                         (Intercept)_Iran (Intercept)_Netherlands  x1 x21 x22 #> (Intercept)_Iran                     0.1                     0.0 0.0 0.0 0.0 #> (Intercept)_Netherlands              0.0                     0.1 0.0 0.0 0.0 #> x1                                   0.0                     0.0 1.1 0.0 0.0 #> x21                                  0.0                     0.0 0.0 1.1 0.0 #> x22                                  0.0                     0.0 0.0 0.0 1.1 #> x31                                  0.0                     0.0 0.0 0.0 0.0 #>                         x31 #> (Intercept)_Iran        0.0 #> (Intercept)_Netherlands 0.0 #> x1                      0.0 #> x21                     0.0 #> x22                     0.0 #> x31                     1.1  # center specific covariate has K=3 categories across 5 centers; y ~ Gaussian inv.prior.cov(X, lambda=c(0.5:3), family=gaussian, stratified=TRUE,               center_spec = c(\"Medium\",\"Big\",\"Small\",\"Big\",\"Small\"), L=5) #>                    (Intercept)_Big (Intercept)_Medium (Intercept)_Small  x1 x21 #> (Intercept)_Big                0.5                0.0               0.0 0.0 0.0 #> (Intercept)_Medium             0.0                0.5               0.0 0.0 0.0 #> (Intercept)_Small              0.0                0.0               0.5 0.0 0.0 #> x1                             0.0                0.0               0.0 1.5 0.0 #> x21                            0.0                0.0               0.0 0.0 1.5 #> x22                            0.0                0.0               0.0 0.0 0.0 #> x31                            0.0                0.0               0.0 0.0 0.0 #> sigma2                         0.0                0.0               0.0 0.0 0.0 #>                    x22 x31 sigma2 #> (Intercept)_Big    0.0 0.0    0.0 #> (Intercept)_Medium 0.0 0.0    0.0 #> (Intercept)_Small  0.0 0.0    0.0 #> x1                 0.0 0.0    0.0 #> x21                0.0 0.0    0.0 #> x22                1.5 0.0    0.0 #> x31                0.0 1.5    0.0 #> sigma2             0.0 0.0    2.5  # center specific covariate has K=4 categories across 5 centers; y ~ Gaussian inv.prior.cov(X, lambda=1, family=gaussian, stratified=TRUE, center_spec = c(3,1:4), L=5) #>               (Intercept)_1 (Intercept)_2 (Intercept)_3 (Intercept)_4 x1 x21 #> (Intercept)_1             1             0             0             0  0   0 #> (Intercept)_2             0             1             0             0  0   0 #> (Intercept)_3             0             0             1             0  0   0 #> (Intercept)_4             0             0             0             1  0   0 #> x1                        0             0             0             0  1   0 #> x21                       0             0             0             0  0   1 #> x22                       0             0             0             0  0   0 #> x31                       0             0             0             0  0   0 #> sigma2                    0             0             0             0  0   0 #>               x22 x31 sigma2 #> (Intercept)_1   0   0      0 #> (Intercept)_2   0   0      0 #> (Intercept)_3   0   0      0 #> (Intercept)_4   0   0      0 #> x1              0   0      0 #> x21             0   0      0 #> x22             1   0      0 #> x31             0   1      0 #> sigma2          0   0      1"},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing BFI Fits — summary.bfi","title":"Summarizing BFI Fits — summary.bfi","text":"Summary method object class 'bfi' created MAP.estimation function.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing BFI Fits — summary.bfi","text":"","code":"# S3 method for bfi summary(object, cur_mat = FALSE,         digits = max(3, getOption(\"digits\") - 3), ...)"},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing BFI Fits — summary.bfi","text":"object fitted bfi object. cur_mat logical; TRUE, minus curvature matrix around estimated parameters returned printed. Default FALSE. digits significant digits printout. ... additional arguments affecting summary produced.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarizing BFI Fits — summary.bfi","text":"summary.bfi() gives information MAP estimates parameters model. can used bfi objects built MAP.estimation function. output summary method shows details model, .e. formula, family link function used specify generalized linear model, followed information estimates, standard deviations credible intervals. Information log-likelihood posterior convergence status also provided. default, summary.bfi function return (minus) curvature matrix, user can use cur_mat = TRUE print .","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing BFI Fits — summary.bfi","text":"summary.bfi returns object class summary.bfi, list following components: theta_hat component object. last element vector estimate dispersion parameter (sigma2) family = gaussian. See MAP.estimation function. A_hat component object. See MAP.estimation function. sd component object. family = gaussian, last element vector square root estimated dispersion. See MAP.estimation function. Lambda component object. See MAP.estimation function. formula component object. See MAP.estimation function. n component object. See MAP.estimation function. np component object. See MAP.estimation function. family component object. See MAP.estimation function. intercept component object. See MAP.estimation function. convergence component object. See MAP.estimation function. control component object. See MAP.estimation function. estimate estimated regression coefficients, .e., without estimate sigma2. logLikPost value log-likelihood posterior density evaluated estimates (theta_hat). link link function. default gaussian family identity link function binomial family logit link function used. dispersion estimated variance random error, .e., sigma2. dispersion taken 1 binomial family. CI 95% credible interval MAP estimates parameters.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarizing BFI Fits — summary.bfi","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing BFI Fits — summary.bfi","text":"","code":"#------------- # y ~ Gaussian #------------- # model assumption: theta <- c(1, 2, 3, 4, 1.5)  # coefficients and sigma2 = 1.5  #---------------- # Data Simulation #---------------- n      <- 40 X      <- data.frame(x1=rnorm(n),                     # continuous variable                      x2=sample(1:3, n, replace=TRUE)) # categorical variable Xx2_1  <- ifelse(X$x2 == '2', 1, 0) Xx2_2  <- ifelse(X$x2 == '3', 1, 0) X$x2   <- as.factor(X$x2) eta    <- theta[1] + theta[2] * X$x1 + theta[3] * Xx2_1 + theta[4] * Xx2_2 mu     <- gaussian()$linkinv(eta) y      <- rnorm(n, mu, sd = sqrt(theta[5]))  #---------------- # MAP estimations #---------------- Lambda <- inv.prior.cov(X, lambda = c(0.1, 0.5), family = gaussian) fit    <- MAP.estimation(y, X, family = gaussian, Lambda) class(fit) #> [1] \"bfi\"  #------------------------- # Summary of MAP estimates #------------------------- summary(fit) #>  #> Summary of the model: #>  #>    Formula: y ~ x1 + x2  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.7868  0.2892  0.2199   1.3537 #> x1            1.6937  0.3040  1.0979   2.2895 #> x22           3.1173  0.5040  2.1296   4.1051 #> x23           4.2339  0.5192  3.2162   5.2515 #>  #> Dispersion parameter (sigma2):  1.705  #>                  log Lik Post:  -66.15  #>                   Convergence:  0  sumfit <- summary(fit, cur_mat = TRUE) #>  #> Summary of the model: #>  #>    Formula: y ~ x1 + x2  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.7868  0.2892  0.2199   1.3537 #> x1            1.6937  0.3040  1.0979   2.2895 #> x22           3.1173  0.5040  2.1296   4.1051 #> x23           4.2339  0.5192  3.2162   5.2515 #>  #> Dispersion parameter (sigma2):  1.705  #>                  log Lik Post:  -66.15  #>                   Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      x1     x22     x23  sigma2 #> (Intercept)     23.5671  4.6227  5.8668  5.2801 -0.1573 #> x1               4.6227 12.7022 -0.6243  2.5738 -0.3382 #> x22              5.8668 -0.6243  5.9668  0.0000 -0.6238 #> x23              5.2801  2.5738  0.0000  5.3801 -0.8468 #> sigma2          -0.1573 -0.3382 -0.6238 -0.8468 83.4099 sumfit$estimate #> [1] 0.7867788 1.6936919 3.1173346 4.2338751 sumfit$logLikPost #> [1] -66.14934 sumfit$dispersion #>   sigma2  #> 1.704517  sumfit$CI #>                2.5 %   97.5 % #> (Intercept) 0.219865 1.353693 #> x1          1.097910 2.289474 #> x22         2.129573 4.105097 #> x23         3.216236 5.251514 class(sumfit) #> [1] \"summary.bfi\""},{"path":"https://hassanpazira.github.io/BFI/reference/trauma.html","id":null,"dir":"Reference","previous_headings":"","what":"Trauma patients from different hospitals — trauma","title":"Trauma patients from different hospitals — trauma","text":"data set consists data 371 trauma patients three hospitals. binary variable mortality used outcome, variables age, sex, Injury Severity Score (ISS, ranging 1 (low) 75 (high)) Glasgow Coma Scale (GCS, expresses level consciousness, ranging 3 (low) 15 (high)) used covariates. three types hospitals: peripheral hospital without neuro-surgical unit (Status = 1), peripheral hospital neuro-surgical unit (Status = 2), academic medical center (Status = 3). Originally, data come multi center study collected different aim. educational purposes minor changes made, see references .","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/trauma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trauma patients from different hospitals — trauma","text":"","code":"data(trauma)"},{"path":"https://hassanpazira.github.io/BFI/reference/trauma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Trauma patients from different hospitals — trauma","text":"Jonker M.., Pazira H. Coolen .C.C. (2023). Bayesian Federated Inference Statistical Models, Statistics Medicine, Vol. 0(0), 0-0. <https://doi.org/10.48550/arXiv.2302.07677> Draaisma J.M.Th, de Haan .F.J., Goris R.J.. (1989). Preventable Trauma Deaths Netherlands - prospective Multicentre Study, journal Trauma, Vol. 29(11), 1552-1557.","code":""}]
