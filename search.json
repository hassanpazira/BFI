[{"path":"https://hassanpazira.github.io/BFI/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 BFI authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"An Introduction to BFI in R","text":"R package BFI (Bayesian Federated Inference) provides several functions carry Bayesian Federated Inference method two types models (GLM Survival) using multicenter data without need combine share . tutorial focuses GLM models. Two commonly used families GLM models, \"binomial\" \"gaussian\", available version package. mostly using functions include bfi(), MAP.estimation(), inv.prior.cov(). following, see BFI package can applied real datasets included package.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"how-to-use-it","dir":"Articles","previous_headings":"","what":"How to use it?","title":"An Introduction to BFI in R","text":"go , first install load BFI package: using following code, can see two available datasets package: trauma Nurses. trauma dataset can utilized \"binomial\" family Nurses dataset can used \"gaussian\" family. avoid repetition, use trauma dataset. loading package, datasets included loaded can inspected follows: dataset consists data 371 trauma patients three hospitals (peripheral hospital without neuro-surgical unit, 'status=1', peripheral hospital neuro-surgical unit, status=2, academic medical center, status=3). can see, dataset six columns. covariates sex (dichotomous), age (continuous), ISS (Injury Severity Score, continuous), GCS (Glasgow Coma Scale, continuous), serve predictors. mortality response variable, hospital categorical variable indicates hospitals involved study. information dataset use analyze data logistic regression model. First standardize covariates. necessary analysis, done interpretability accuracy estimates. using following code can see three hospitals involved study:","code":"# Install and load the BFI package from CRAN: install.packages(\"BFI\") library(BFI) data(package = \"BFI\") # Get the number of rows and columns dim(trauma) ## [1] 371   6 # To get an idea of the dataset, print the first 7 rows head(trauma, 7) ##   sex age hospital ISS GCS mortality ## 1   1  20        3  24  15         0 ## 2   0  38        3  34  13         0 ## 3   0  37        3  50  15         0 ## 4   0  17        3  43   4         1 ## 5   0  49        3  29  15         0 ## 6   0  30        3  22  15         0 ## 7   1  84        2  66   3         1 # Get some info about the dataset from the help file ?trauma trauma$age <- scale(trauma$age) trauma$ISS <- scale(trauma$ISS)  trauma$GCS <- scale(trauma$GCS)  trauma$hospital <- as.factor(trauma$hospital) length(levels(trauma$hospital)) ## [1] 3"},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"map-estimations","dir":"Articles","previous_headings":"How to use it?","what":"MAP estimations","title":"An Introduction to BFI in R","text":"Therefore, MAP.estimation function applied 3 local datasets separately obtain MAP estimations. Note , practice, access combined data, center perform analysis independently send output central server, follows: can seen algorithms converged (Convergence: 0). Convergence: 1 occurs, can increase number iteration optimization process optim() adding control = list(maxit=500) function MAP.estimation, shown : see information dataset, number observations parameters, can use output MAP.estimation function follows: Additionally, conducting analysis, can use n.par function retrieve information. outputs fit1,fit2, fit3 local centers sent central server analysis. send lists R central server (also uses R), can save format R can easily read, RDS file.","code":"# Center 1: # X1 <- data.frame(sex=trauma$sex[trauma$hospital==1], #                  age=trauma$age[trauma$hospital==1], #                  ISS=trauma$ISS[trauma$hospital==1], #                  GCS=trauma$GCS[trauma$hospital==1]) X1 <- subset(trauma, hospital == 1, select = c(sex, age, ISS, GCS)) Lambda1 <- inv.prior.cov(X1, lambda=0.01, L=3, family=\"binomial\") fit1 <- MAP.estimation(y=trauma$mortality[trauma$hospital==1], X=X1, family=\"binomial\", Lambda=Lambda1) summary(fit1) ##  ## Summary of the local model: ##  ##    Formula: y ~ sex + age + ISS + GCS  ##     Family: 'binomial'  ##       Link: 'Logit' ##  ## Coefficients: ##  ##             Estimate Std.Dev  CI 2.5% CI 97.5% ## (Intercept)  -2.1226  0.8074  -3.7050  -0.5402 ## sex          -5.2795  2.6305 -10.4351  -0.1239 ## age           1.8864  0.7210   0.4732   3.2996 ## ISS           2.3741  0.9250   0.5611   4.1872 ## GCS          -2.4522  0.8295  -4.0781  -0.8264 ##  ## Dispersion parameter (sigma2):  1  ##             log Lik Posterior:  -10.74  ##                   Convergence:  0 # Center 2: # X2 <- data.frame(sex=trauma$sex[trauma$hospital==2], #                  age=trauma$age[trauma$hospital==2], #                  ISS=trauma$ISS[trauma$hospital==2], #                  GCS=trauma$GCS[trauma$hospital==2]) X2 <- subset(trauma, hospital == 2, select = c(sex, age, ISS, GCS)) Lambda2 <- inv.prior.cov(X2, lambda=0.01, L=3, family=\"binomial\") fit2 <- MAP.estimation(y=trauma$mortality[trauma$hospital==2], X=X2, family=\"binomial\", Lambda=Lambda2) summary(fit2) ##  ## Summary of the local model: ##  ##    Formula: y ~ sex + age + ISS + GCS  ##     Family: 'binomial'  ##       Link: 'Logit' ##  ## Coefficients: ##  ##             Estimate Std.Dev CI 2.5% CI 97.5% ## (Intercept)  -0.7854  0.3789 -1.5280  -0.0427 ## sex          -0.7850  0.6999 -2.1568   0.5868 ## age           1.9601  0.4662  1.0465   2.8738 ## ISS           0.5216  0.3673 -0.1983   1.2415 ## GCS          -1.8737  0.4115 -2.6803  -1.0672 ##  ## Dispersion parameter (sigma2):  1  ##             log Lik Posterior:  -36.87  ##                   Convergence:  0 # Center 3: # X3 <- data.frame(sex=trauma$sex[trauma$hospital==3], #                  age=trauma$age[trauma$hospital==3], #                  ISS=trauma$ISS[trauma$hospital==3], #                  GCS=trauma$GCS[trauma$hospital==3]) X3 <- subset(trauma, hospital == 3, select = c(sex, age, ISS, GCS)) Lambda3 <- inv.prior.cov(X3, lambda=0.01, L=3, family=\"binomial\") fit3 <- MAP.estimation(y=trauma$mortality[trauma$hospital==3], X=X3, family=\"binomial\", Lambda=Lambda3) summary(fit3) ##  ## Summary of the local model: ##  ##    Formula: y ~ sex + age + ISS + GCS  ##     Family: 'binomial'  ##       Link: 'Logit' ##  ## Coefficients: ##  ##             Estimate Std.Dev CI 2.5% CI 97.5% ## (Intercept)  -2.3144  0.4020 -3.1024  -1.5264 ## sex           0.1580  0.5714 -0.9619   1.2780 ## age           1.3031  0.2955  0.7239   1.8824 ## ISS           0.2967  0.2638 -0.2203   0.8138 ## GCS          -2.4221  0.4130 -3.2316  -1.6125 ##  ## Dispersion parameter (sigma2):  1  ##             log Lik Posterior:  -50.63  ##                   Convergence:  0 # Example for Center 3: fit3 <- MAP.estimation(y=trauma$mortality[trauma$hospital==3], X=X3, family=\"binomial\", Lambda=Lambda3, control = list(maxit=500)) # number of samples in center 1 fit1$n ## [1] 49 # number of parameters in center 1 fit1$np ## [1] 5 # number of samples in center 2 fit2$n ## [1] 106 # number of samples in center 3 fit3$n ## [1] 216 # Save fit1 as an RDS file saveRDS(fit1, file=\"fit1.rds\")  # Save fit2 as an RDS file saveRDS(fit2, file=\"fit2.rds\")  # Save fit3 as an RDS file saveRDS(fit3, file=\"fit3.rds\")"},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"bfi-estimations","dir":"Articles","previous_headings":"How to use it?","what":"BFI estimations","title":"An Introduction to BFI in R","text":"Now, received files can loaded R using following lines: central server, bfi() function can used obtain BFI estimations:","code":"# Load the RDS files fit1 <- readRDS(\"fit1.rds\") # use the relative path to the file fit2 <- readRDS(\"fit2.rds\") # use the relative path to the file fit3 <- readRDS(\"fit3.rds\") # use the relative path to the file theta_hats <- list(fit1$theta_hat, fit2$theta_hat, fit3$theta_hat) A_hats     <- list(fit1$A_hat, fit2$A_hat, fit3$A_hat) Lambda_com <- inv.prior.cov(X1, lambda=0.01, L=3, family=\"binomial\") Lambdas    <- list(Lambda1, Lambda2, Lambda3, Lambda_com) BFI_fits   <- bfi(theta_hats, A_hats, Lambdas, family=\"binomial\") summary(BFI_fits, cur_mat=TRUE) ##  ## Summary of the BFI model: ##  ##     Family: 'binomial'  ##       Link: 'Logit' ##  ## Coefficients: ##  ##             Estimate Std.Dev CI 2.5% CI 97.5% ## (Intercept)  -1.4434  0.2465 -1.9265  -0.9602 ## sex          -0.2473  0.4187 -1.0680   0.5733 ## age           1.2189  0.2190  0.7897   1.6481 ## ISS           0.4939  0.1945  0.1127   0.8751 ## GCS          -1.7375  0.2491 -2.2258  -1.2492 ##  ## Dispersion parameter (sigma2):  1  ##  ## Minus the Curvature Matrix:  ##  ##             (Intercept)     sex     age      ISS      GCS ## (Intercept)     30.4330  7.7926  0.7578   8.3797 -16.6608 ## sex              7.7926  7.8026  1.3061   1.8414  -4.6925 ## age              0.7578  1.3061 31.5230  -4.8356  15.7494 ## ISS              8.3797  1.8414 -4.8356  30.7881 -11.7189 ## GCS            -16.6608 -4.6925 15.7494 -11.7189  34.4508"},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"comparison","dir":"Articles","previous_headings":"How to use it?","what":"Comparison","title":"An Introduction to BFI in R","text":"compare performance BFI methodology, can combine datasets obtain MAP estimations based combined data: Now, can see difference BFI combined estimates: close zero, expected! details see following references.","code":"# MAP estimates of the combined data: X_combined  <- data.frame(sex=trauma$sex,                           age=trauma$age,                           ISS=trauma$ISS,                           GCS=trauma$GCS) Lambda   <- inv.prior.cov(X=X_combined, lambda=0.01, L=3, family=\"binomial\") fit_comb  <- MAP.estimation(y=trauma$mortality, X=X_combined, family=\"binomial\", Lambda=Lambda)  summary(fit_comb, cur_mat=TRUE) ##  ## Summary of the local model: ##  ##    Formula: y ~ sex + age + ISS + GCS  ##     Family: 'binomial'  ##       Link: 'Logit' ##  ## Coefficients: ##  ##             Estimate Std.Dev CI 2.5% CI 97.5% ## (Intercept)  -1.6255  0.2398 -2.0955  -1.1556 ## sex          -0.3357  0.3990 -1.1178   0.4463 ## age           1.3703  0.2056  0.9673   1.7733 ## ISS           0.5498  0.1862  0.1848   0.9149 ## GCS          -1.9981  0.2379 -2.4645  -1.5318 ##  ## Dispersion parameter (sigma2):  1  ##             log Lik Posterior:  -109.4  ##                   Convergence:  0  ##  ## Minus the Curvature Matrix:  ##  ##             (Intercept)     sex     age      ISS      GCS ## (Intercept)     33.5675  8.4942  2.3840   8.3535 -18.2832 ## sex              8.4942  8.5042  1.8643   1.4055  -4.5326 ## age              2.3840  1.8643 37.1516  -6.1748  18.0223 ## ISS              8.3535  1.4055 -6.1748  33.4408 -12.8543 ## GCS            -18.2832 -4.5326 18.0223 -12.8543  38.5342 # Squared Errors: (fit_comb$theta_hat - BFI_fits$theta_hat)^2 ##      (Intercept)        sex        age         ISS        GCS ## [1,]  0.03319286 0.00781985 0.02292217 0.003132086 0.06791077"},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"An Introduction to BFI in R","text":"Jonker M.., Pazira H. Coolen .C.C. (2024). Bayesian federated inference estimating statistical models based non-shared multicenter data sets, Statistics Medicine, 43(12): 2421-2438. https://doi.org/10.1002/sim.10072 Pazira H., Massa E., Weijers J..M., Coolen .C.C. Jonker M.. (2025b). Bayesian Federated Inference Survival Models, Journal Applied Statistics (Accepted). https://arxiv.org/abs/2404.17464 Jonker M.., Pazira H. Coolen .C.C. (2025a). Bayesian Federated Inference regression models based non-shared medical center data, Research Synthesis Methods, 1-41. https://doi.org/10.1017/rsm.2025.6 van den Heuvel Z.D., Pazira H. Jonker M.. (2025c). Bayesian Federated Causal Inference observational data, arXiv. https://arxiv.org/abs/???","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/BFI.html","id":"contact","dir":"Articles","previous_headings":"","what":"Contact","title":"An Introduction to BFI in R","text":"find errors, suggestions, like request something added, please file issue issue report send email : hassan.pazira@radboudumc.nl Marianne.Jonker@radboudumc.nl.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Calling BFI from Python","text":"BFI R package performs Bayesian Federated Inference (BFI) linear, logistic, survival regression models. Since Python package carrying BFI method far, vignette describes usage R package BFI Python environment. move Python environment, need prepare operating system. Although, explain following prepare different systems (‘MacOS’, ‘Ubuntu’ ‘Windows’), recommend use ‘Google Colab’ write execute (following) Python codes can done system browser without preparations.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"google-colab","dir":"Articles","previous_headings":"","what":"Google Colab","title":"Calling BFI from Python","text":"First go Google Colab https://colab.google https://colab.research.google.com, click New Notebook. Now, skip two following sections jump section Python Script.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"python-installation","dir":"Articles","previous_headings":"","what":"Python Installation","title":"Calling BFI from Python","text":"steps install latest version Python ‘MacOS’, ‘Ubuntu’ ‘Windows’ follows:","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-macos","dir":"Articles","previous_headings":"Python Installation","what":"On MacOS","title":"Calling BFI from Python","text":"Open terminal window (cmd + space search ‘Terminal’) install package manager ‘Homebrew’ executing following command: Install latest version Python (Python 3) following command: Verify installation checking Python version: ’s assumed R also installed configured system. , following can :","code":"/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\" brew install python@3 python3 --version # Install XCode command-line tools xcode-select --install  # Install R brew install --cask r"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-ubuntu","dir":"Articles","previous_headings":"Python Installation","what":"On Ubuntu","title":"Calling BFI from Python","text":"Update package repositories get latest package information running following command terminal window: Verify Python indeed installed system following command: already Python (Python 3) installed system, need upgrade latest version follows: case Python installed first place, latest version Python can installed using following command: Verify installation checking Python version: don’t R installed configured, just run following:","code":"sudo apt-get update -y python3 --version sudo apt-get upgrade python3 sudo apt-get install python3 python3 --version # Install R sudo apt-get install r-base"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-windows","dir":"Articles","previous_headings":"Python Installation","what":"On Windows","title":"Calling BFI from Python","text":"default, Python usually installed Windows. However, can check exists system running one line command command prompt. Go Start enter cmd search bar, click Command Prompt. Enter command python --version python3 --version command prompt. download Python, go official Python download website Windows: https://www.python.org. Find stable Python 3 release, download executable file system appropriate link. installer downloaded, open/run Python installer install Python. Select Add Python 3.x PATH checkbox, enables users launch Python command line, select Install Now. installation complete, can verify whether Python installation successful command line. Enter command python --version python3 --version command prompt. ’s assumed R also installed system. don’t R installed, just visit CRAN downloads (https://cran.r-project.org) get last version.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"installation-of-required-modules","dir":"Articles","previous_headings":"","what":"Installation of Required Modules","title":"Calling BFI from Python","text":"required modules installed PIP. PIP (Python package manager) helps us install use various packages/modules Python programming. Install latest version PIP required modules running following commands different systems.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-macos-1","dir":"Articles","previous_headings":"Installation of Required Modules","what":"On MacOS","title":"Calling BFI from Python","text":"Install/Upgrade latest version PIP running Install required modules running following commands","code":"# Installing PIP python3 -m pip install --user --upgrade pip # Installing the 'pandas' module pip3 install pandas  # Installing the 'numpy' module pip3 install numpy  # Installing the 'pickle' module pip3 install pickle  # Installing the 'rpy2' module pip3 install rpy2"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-ubuntu-1","dir":"Articles","previous_headings":"Installation of Required Modules","what":"On Ubuntu","title":"Calling BFI from Python","text":"install PIP use code Verify successfully installed PIP running Now, install required modules typing following commands lines installation modules install , use following: Finally, use show command verify whether module now part Python packages:","code":"# Installing PIP sudo apt-get install python3-pip pip3 -V # Installing the 'pandas' module sudo pip3 install pandas  # Installing the 'numpy' module sudo pip3 install numpy  # Installing the 'pickle' module sudo pip3 install pickle  # Installing the 'rpy2' module sudo pip3 install rpy2 # Installing the 'pandas' module sudo apt-get install python3-pandas  # Installing the 'numpy' module sudo apt-get install python3-numpy  # Installing the 'pickle' module sudo apt-get install python3-pickle  # Installing the 'rpy2' module sudo apt-get install python3-rpy2 pip3 show pandas pip3 show numpy pip3 show pickle pip3 show rpy2"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"on-windows-1","dir":"Articles","previous_headings":"Installation of Required Modules","what":"On Windows","title":"Calling BFI from Python","text":"Usually, PIP automatically installed using Python downloaded https://www.python.org. followed previous steps provided vignette, PIP installed system. check PIP already installed Windows, open command line , type pip -V, press Enter. PIP installed: First download get-pip.py folder computer. , open command prompt navigate folder containing get-pip.py installer. Finally, run following command: PIP now installed successfully. receive ‘file found’ error, double check directory path file. can use dir command view entire contents directory. information can found : https://pip.pypa.io/en/stable/installation. Now, install required modules running following commands: Now, can start coding Python using Python’s command-line interpreter IDLE application. Go Start enter python search bar. can see Python 3.x IDLE can used coding. Open one follow following steps.","code":"python get-pip.py # Installing the 'pandas' module pip3 install pandas  # Installing the 'numpy' module pip3 install numpy  # Installing the 'pickle' module pip3 install pickle  # Installing the 'rpy2' module pip3 install rpy2"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"Python","dir":"Articles","previous_headings":"","what":"Python Script","title":"Calling BFI from Python","text":"assumed required packages properly installed, case Google Colab. Now move work rpy2 package inside Python script! Python script, first go Python Environment typing following command terminal window (skip line already Google Colab): now, following codes run Python environment. want copy codes go last section.","code":"python3"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"importing-python-modules-and-functions","dir":"Articles","previous_headings":"Python Script","what":"Importing Python modules and functions","title":"Calling BFI from Python","text":"Use following codes import required Python modules: using following codes imports required functions importr() data():","code":"# import 'pandas' package import pandas as pd  # import 'numpy' package import numpy as np                  # import 'pickle' package import pickle  # import 'rpy2' package import rpy2 from rpy2.robjects.packages import importr, data from rpy2.robjects.vectors import StrVector from rpy2.robjects import numpy2ri, pandas2ri # activation of the automatic conversion of 'numpy' and 'pandas' objects into rpy2 objects numpy2ri.activate()    pandas2ri.activate()"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"installing-r-packages-from-cran-and-github","dir":"Articles","previous_headings":"Python Script","what":"Installing R packages from CRAN and GitHub","title":"Calling BFI from Python","text":"First load packages preinstalled R using importr() follows: install R packages stats BFI CRAN typing Now load installed packages using","code":"# import R's \"utils\" package utils = importr('utils')  # import R's \"base\" package base = importr('base') utils.chooseCRANmirror(ind=1)  # which selects the first mirror in the list package_names = ('stats', 'BFI') utils.install_packages(StrVector(package_names)) stats = importr('stats') BFI = importr('BFI')"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"installing-the-bfi-package-from-github-if-necessary","dir":"Articles","previous_headings":"Python Script > Installing R packages from CRAN and GitHub","what":"Installing the BFI package from GitHub (if necessary)","title":"Calling BFI from Python","text":"want install BFI package GitHub (instead CRAN), can installed loaded using following lines:","code":"utils.chooseCRANmirror(ind=1) utils.install_packages('devtools') devtools = importr('devtools')  # Installing the 'BFI' package devtools.install_github(\"hassanpazira/BFI\", force = True)  # Loading the package BFI = importr('BFI')"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"applying-bfi-method-to-the-simulated-data","dir":"Articles","previous_headings":"","what":"Applying BFI method to the simulated data","title":"Calling BFI from Python","text":"Now generate two datasets independently Gaussian distribution, apply main functions BFI package datasets:","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"data-simulation-for-two-local-centers","dir":"Articles","previous_headings":"Applying BFI method to the simulated data","what":"Data Simulation for two Local Centers","title":"Calling BFI from Python","text":"First generate 30 samples randomly Gaussian distribution 3 covariates: generate randomly 50 samples Gaussian distribution 3 covariates:","code":"# model parameters: 'theta' and 'p' are assumed to be the same for both centers: theta = np.array([1, 2, 3, 4, 0.75])   # intercept is theta[0], sigma2 is theta[4] p = 3     # number of regression parameters without intercept  # Center 1: n1 = 30   # sample size of center 1 X1 = np.random.normal(size=(n1, p))  X1.shape   # dimension of X1 X1 = pd.DataFrame(X1, columns=['X1', 'X2', 'X3']) mu1 = theta[0] + np.dot(X1, np.delete(theta, [0, 4]))  # for gaussian: \\eta = \\mu  X1 = pandas2ri.py2rpy(X1)   # == base.as_data_frame(X1) y1 = np.random.normal(loc=mu1, scale=np.sqrt(theta[4])) # Center 2: n2 = 50   # sample size of center 2 X2 = np.random.normal(size=(n2, p)) X2 = pd.DataFrame(X2, columns=['X1', 'X2', 'X3']) mu2 = theta[0] + np.dot(X2, np.delete(theta, [0, 4])) X2 = pandas2ri.py2rpy(X2) y2 = np.random.normal(loc=mu2, scale=np.sqrt(theta[4]))"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"map-estimates-at-the-local-centers","dir":"Articles","previous_headings":"Applying BFI method to the simulated data","what":"MAP Estimates at the Local Centers","title":"Calling BFI from Python","text":"following compute Maximum Posterior (MAP) estimators parameters center 1: Obtaining MAP estimators parameters center 2 using following:","code":"# Creating an inverse covariance matrix for a Gaussian prior for center 1 Lambda1 = BFI.inv_prior_cov(X1, 0.01, 'gaussian') fit1 = BFI.MAP_estimation(y1, X1, 'gaussian', Lambda1) print(fit1) theta_hat1 = fit1.rx2(\"theta_hat\") # MAP estimates of the intercept and coefficients A_hat1 = fit1.rx2(\"A_hat\")         # minus the curvature matrix summary_1 = BFI.summary_bfi(fit1, cur_mat = True) # Creating an inverse covariance matrix for Gaussian prior for center 2 Lambda2 = BFI.inv_prior_cov(X2, 0.01, 'gaussian') # MAP estimates fit2 = BFI.MAP_estimation(y2, X2, 'gaussian', Lambda2) theta_hat2 = fit2.rx2(\"theta_hat\") # MAP estimates of the parameters A_hat2 = fit2.rx2(\"A_hat\")         # minus the curvature matrix around 'theta_hat2' summary_2 = BFI.summary_bfi(fit2, cur_mat = True)"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"sending-the-required-files-to-central-server","dir":"Articles","previous_headings":"Applying BFI method to the simulated data","what":"Sending the Required Files to Central Server","title":"Calling BFI from Python","text":"required outputs using central server fit1 center 1 fit2 center 2. send outputs central server, can save list file common format (RDS, JSON, CSV). allow central server open file either R Python environments.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"central-server-with-r","dir":"Articles","previous_headings":"Applying BFI method to the simulated data > Sending the Required Files to Central Server","what":"Central server with R","title":"Calling BFI from Python","text":"central server using R, follow instructions . using Python, go next subsection: Central server Python. show fit1 center 1. process center 2. Since fit1 R object central server using R, can save RDS file, file format native R single R objects. file, fit1.rds sent central server, can loaded follows: Now, variable fit1 list R containing information needed analysis: see proceed use bfi() R, see, example, .","code":"import rpy2.robjects as ro  # Save fit1 as an RDS file ro.r('saveRDS(fit1, file=\"fit1.rds\")') # Load the saved RDS file fit1 <- readRDS(\"fit1.rds\") # use the relative path to the file theta_hat1 <- fit1$theta_hat A_hat1 <- fit1$A_hat"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"server_python","dir":"Articles","previous_headings":"Applying BFI method to the simulated data > Sending the Required Files to Central Server","what":"Central server with Python","title":"Calling BFI from Python","text":"central server using Python, follow instructions . show fit1 center 1. process center 2. Since fit1 needs shared central server using Python, can serialize using pickle module, common way save Python objects. center 1, use following create fit1.pkl: Now, file fit1.pkl sent central server, can loaded follows: variable fit1 contains information needed analysis central server. see proceed obtain BFI estimates central server, follow next section.","code":"# Save fit1 as a pickle file with open('fit1.pkl', 'wb') as f:     pickle.dump(fit1, f) # Load the pickle file with open('fit1.pkl', 'rb') as f:  # use the relative path to the file     fit1 = pickle.load(f)"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"bfi-at-central-server-using-python","dir":"Articles","previous_headings":"Applying BFI method to the simulated data","what":"BFI at Central Server (using Python)","title":"Calling BFI from Python","text":"central server, first load files saved proper address: Now, main function bfi() can used obtain BFI estimates:","code":"# Load the file form center 1 with open('fit1.pkl', 'rb') as f: # use the relative path to the file     fit1 = pickle.load(f)  # Load the file form center 2, using the relative path to the file with open('fit2.pkl', 'rb') as f:     fit2 = pickle.load(f) theta_hat1 = fit1.rx2(\"theta_hat\") A_hat1 = fit1.rx2(\"A_hat\") theta_hat2 = fit2.rx2(\"theta_hat\") A_hat2 = fit2.rx2(\"A_hat\") theta_hats = base.list(theta_hat1, theta_hat2) A_hats = base.list(A_hat1, A_hat2) Lambda1 = pd.DataFrame(Lambda1, index=fit1.rx2(\"names\"), columns=fit1.rx2(\"names\")) Lambda2 = pd.DataFrame(Lambda2, index=fit2.rx2(\"names\"), columns=fit2.rx2(\"names\")) Lambdas = base.list(Lambda1, Lambda2) fit_bfi = BFI.bfi(theta_hats, A_hats, Lambdas) print(fit_bfi) summary_bfi = BFI.summary_bfi(fit_bfi, cur_mat = True)"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"datasets-included-in-the-bfi-package","dir":"Articles","previous_headings":"","what":"Datasets included in the BFI package","title":"Calling BFI from Python","text":"find list datasets included package run: order use datasets available BFI package, use following codes: end, use following deactivate automatic conversion:","code":"print(utils.data(package = \"BFI\")) Nurses = data(BFI).fetch('Nurses')['Nurses']  # is equivalent to BFI::Nurses in R print(\"Dimension of the 'Nurses' data: \\n\", base.dim(Nurses)) print(\"Colnames of the 'Nurses' data: \\n\", base.colnames(Nurses))  trauma = data(BFI).fetch('trauma')['trauma']  # is equivalent to BFI::trauma in R print(\"Dimension of the 'trauma' data: \\n\", base.dim(trauma)) print(\"Colnames of the 'trauma' data: \\n\", base.colnames(trauma)) numpy2ri.deactivate() pandas2ri.deactivate()"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"allcodes","dir":"Articles","previous_headings":"","what":"All codes together","title":"Calling BFI from Python","text":"need codes copy paste example Google Colab, ’s complete codes:","code":"# import 'pandas' package import pandas as pd  # import 'numpy' package import numpy as np                  # import 'pickle' package import pickle  # import 'rpy2' package import rpy2                    from rpy2.robjects.packages import importr, data from rpy2.robjects.vectors import StrVector from rpy2.robjects import numpy2ri, pandas2ri # activation of the automatic conversion of 'numpy' and 'pandas' objects into rpy2 objects numpy2ri.activate()    pandas2ri.activate()  # import R's \"utils\" package utils = importr('utils')  # import R's \"base\" package base = importr('base')  utils.chooseCRANmirror(ind=1)  # which selects the first mirror in the list package_names = ('stats', 'BFI') utils.install_packages(StrVector(package_names))  # loading the installed packages stats = importr('stats') BFI = importr('BFI')  ## Examples  # model parameters: 'theta' and 'p' are assumed to be the same for both centers: theta = np.array([1, 2, 3, 4, 0.75])   # intercept is theta[0], sigma2 is theta[4] p = 3     # number of regression parameters without intercept  # Data Simulation for center 1 n1 = 30   # sample size of center 1 X1 = np.random.normal(size=(n1, p))  X1.shape   # dimension of X1 X1 = pd.DataFrame(X1, columns=['X1', 'X2', 'X3']) mu1 = theta[0] + np.dot(X1, np.delete(theta, [0, 4]))  # for gaussian: \\eta = \\mu  X1 = pandas2ri.py2rpy(X1)   # == base.as_data_frame(X1) y1 = np.random.normal(loc=mu1, scale=np.sqrt(theta[4]))  # Data Simulation for center 2 n2 = 50   # sample size of center 2 X2 = np.random.normal(size=(n2, p)) X2 = pd.DataFrame(X2, columns=['X1', 'X2', 'X3']) mu2 = theta[0] + np.dot(X2, np.delete(theta, [0, 4])) X2 = pandas2ri.py2rpy(X2) y2 = np.random.normal(loc=mu2, scale=np.sqrt(theta[4]))  ## MAP estimates at center 1 # Creating an inverse covariance matrix for a Gaussian prior for center 1 Lambda1 = BFI.inv_prior_cov(X1, 0.01, 'gaussian') fit1 = BFI.MAP_estimation(y1, X1, 'gaussian', Lambda1) print(fit1) theta_hat1 = fit1.rx2(\"theta_hat\") # MAP estimates of the intercept and coefficients A_hat1 = fit1.rx2(\"A_hat\")         # minus the curvature matrix summary_1 = BFI.summary_bfi(fit1, cur_mat = True) # Save fit1 as a pickle file for sending to the central server with open('fit1.pkl', 'wb') as f:     pickle.dump(fit1, f)  ## MAP estimates at center 2 # Creating an inverse covariance matrix for Gaussian prior for center 2 Lambda2 = BFI.inv_prior_cov(X2, 0.01, 'gaussian') # MAP estimates fit2 = BFI.MAP_estimation(y2, X2, 'gaussian', Lambda2) theta_hat2 = fit2.rx2(\"theta_hat\") # MAP estimates of the parameters A_hat2 = fit2.rx2(\"A_hat\")         # minus the curvature matrix around 'theta_hat2' summary_2 = BFI.summary_bfi(fit2, cur_mat = True) # Save fit2 as a pickle file for sending to the central server with open('fit2.pkl', 'wb') as f:     pickle.dump(fit2, f)  ## BFI at central server # Load the pickle file using the relative path to the file with open('fit1.pkl', 'rb') as f:  # use the relative path to the file     fit1 = pickle.load(f) theta_hat1 = fit1.rx2(\"theta_hat\") A_hat1 = fit1.rx2(\"A_hat\") # Load the pickle file using the relative path to the file with open('fit2.pkl', 'rb') as f:     fit2 = pickle.load(f) theta_hat2 = fit2.rx2(\"theta_hat\") A_hat2 = fit2.rx2(\"A_hat\") theta_hats = base.list(theta_hat1, theta_hat2) A_hats = base.list(A_hat1, A_hat2) Lambda1 = pd.DataFrame(Lambda1, index=fit1.rx2(\"names\"), columns=fit1.rx2(\"names\")) Lambda2 = pd.DataFrame(Lambda2, index=fit2.rx2(\"names\"), columns=fit2.rx2(\"names\")) Lambdas = base.list(Lambda1, Lambda2) fit_bfi = BFI.bfi(theta_hats, A_hats, Lambdas) print(fit_bfi) summary_bfi = BFI.summary_bfi(fit_bfi, cur_mat = True)  # To find a list of all datasets included in the package: print(utils.data(package = \"BFI\"))  Nurses = data(BFI).fetch('Nurses')['Nurses'] print(\"Dimension of the 'Nurses' data: \\n\", base.dim(Nurses)) print(\"Colnames of the 'Nurses' data: \\n\", base.colnames(Nurses))  trauma = data(BFI).fetch('trauma')['trauma'] print(\"Dimension of the 'trauma' data: \\n\", base.dim(trauma)) print(\"Colnames of the 'trauma' data: \\n\", base.colnames(trauma))"},{"path":"https://hassanpazira.github.io/BFI/articles/Python.html","id":"contact","dir":"Articles","previous_headings":"","what":"Contact","title":"Calling BFI from Python","text":"find errors, suggestions, like request something added, please file issue issue report send email : hassan.pazira@radboudumc.nl.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using BFI in SAS","text":"BFI package powerful tool R designed execute Bayesian Federated Inference (BFI) methodology. supports wide range regression models, including linear, logistic, survival regression. SAS offers robust statistical capabilities, currently lacks dedicated package implementing BFI method. Consequently, vignette aims bridge gap illustrating utilize R package BFI within SAS environment. seamlessly integrating R’s BFI package analytical prower SAS, users gain access comprehensive suite statistical techniques, enhancing ability perform sophisticated data analyses, particularly working small datasets. guide, ’ll explore can leverage SAS effectively utilize BFI package data analysis needs. utilize R within SAS, ’s assumed access SAS server. access allows establish connection SAS session providing necessary connection parameters, SAS server hostname, port number, authentication credentials. information configuring SAS system call functions R language documented SAS Online Help.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"accessing-sas-services","dir":"Articles","previous_headings":"","what":"Accessing SAS Services","title":"Using BFI in SAS","text":"access SAS services, typically need connect SAS server. ’s can using SAS Studio, web-based interface SAS: Open web browser navigate URL provided SAS administrator accessing SAS Studio. Enter credentials log . logged , can access SAS services analysis reporting SAS Studio interface.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"install-r-and-configuring-it-with-sas","dir":"Articles","previous_headings":"","what":"Install R and Configuring It with SAS","title":"Using BFI in SAS","text":"SAS requires two configuration options order communicate R. First RLANG option must set SAS started. may set either custom configuration file SAS command line. Second, SAS needs R_HOME environment variable pointing correct, available version R.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"the-rlang-system-option","dir":"Articles","previous_headings":"Install R and Configuring It with SAS","what":"The RLANG System Option","title":"Using BFI in SAS","text":"RLANG system option determines whether permission call R SAS system. can check value RLANG option submitting following SAS statements: result one following statements SAS log: NORLANG: support access R language interfaces SAS log contains statement, means R integration disabled, permission call R SAS system :( may need consult SAS administrator department enable . RLANG: Support access R language interfaces SAS log contains statement, means R integration enabled, can call R SAS system :)","code":"proc options option=RLANG; run;"},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"install-r","dir":"Articles","previous_headings":"Install R and Configuring It with SAS","what":"Install R","title":"Using BFI in SAS","text":"Download install R official R website (https://www.r-project.org/). Follow installation instructions provided operating system.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"install-sasiml-interface-to-r","dir":"Articles","previous_headings":"Install R and Configuring It with SAS","what":"Install SAS/IML Interface to R","title":"Using BFI in SAS","text":"SAS/IML Interface R allows call R functions within PROC IML (Interactive Matrix Language). Check interface installed running following code within SAS: path R installation directory displayed, SAS/IML Interface R installed. , may need install reinstall .","code":"proc options option=R_HOME; run;"},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"using-proc-iml-and-rsubmit","dir":"Articles","previous_headings":"","what":"Using PROC IML and Rsubmit","title":"Using BFI in SAS","text":"can use R inside SAS use PROC IML procedure. PROC IML allows execute R code within SAS session, enabling integration SAS R data analysis statistical modeling.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"installing-r-packages-from-cran-and-github-in-sas","dir":"Articles","previous_headings":"Using PROC IML and Rsubmit","what":"Installing R packages from CRAN and GitHub in SAS:","title":"Using BFI in SAS","text":"install R package CRAN GitHub, can use base, stats remotes packages, respectively. can done R SAS. ’s can within SAS: Now BFI package installed configured, let’s explore functionality following example.","code":"proc iml;    rsubmit;      /* First install and load 'base', 'stats' and 'BFI'from CRAN */     install.packages(\"base\")     install.packages(\"stats\")     install.packages(\"BFI\")  /* To install BFI from CRAN */     library(base)     library(stats)     library(BFI)        /* To install BFI from GitHub (if nessecary) */     /* install.packages(\"remotes\") */     /* library(remotes) */     /* remotes::install_github(\"hassanpazira/BFI\", force = TRUE) */    endrsubmit;  quit;"},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Using BFI in SAS","text":"Now generate two datasets independently Gaussian distribution, apply main functions BFI package datasets:","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"simulate-data-for-two-local-centers","dir":"Articles","previous_headings":"Example","what":"Simulate data for two local centers","title":"Using BFI in SAS","text":"First generate 30 samples randomly Gaussian distribution N(0, 1) p=3 covariates: Now generate 50 samples randomly N(0, 1) 3 covariates: transferred SAS data R session currently initiating analysis using BFI method R. communications R facilitated SAS’s PROC IML. ’s important note capitalization matters R, character variables automatically converted factors.","code":"proc iml;      /****************************************************************/     /* Center 1: Data simulation for local center 1 with 30 samples */     /****************************************************************/      p     = 3;   /* Number of variables */     n1    = 30;  /* Number of samples for center 1 */     theta = {1, 2, 2, 2, 1.5}; /* Define theta values directly */      X1  = j(n1, p); /* Initialize matrix X1 */     mu1 = j(n1, 1); /* Initialize vector mu1 */     y1  = j(n1, 1); /* Initialize vector y1 */      /* Generate data for center 1 */     call randseed(1123);     X1  = randfun(n1 || p, \"Normal\", 0, 1);     mu1 = theta[1] + X1 * theta[2:4];     y1  = randfun(n1 || 1, \"Normal\", mu1, sqrt(theta[5]));      /* Create dataset for center 1 */     create y1 var {\"y1\"};     append;     close y1;      create X1 from X1[colname={\"X1_1\" \"X1_2\" \"X1_3\"}];     append from X1;     close X1;      /* Transfer SAS data to the R session */     call ExportMatrixToR(X1, \"X1\");     call ExportMatrixToR(y1, \"y1\");  quit; proc iml;      /****************************************************************/     /* Center 2: Data simulation for local center 2 with 50 samples */     /****************************************************************/     p     = 3;   /* Number of variables */     n2    = 50;   /* Number of samples for center 2 */     theta = {1, 2, 2, 2, 1.5}; /* Define theta values directly */        X2  = j(n2, p);     mu2 = j(n2, 1);     y2  = j(n2, 1);      /* Generate data for center 2 */     call randseed(1123);     X2  = randfun(n2 || p, \"Normal\", 0, 1);     mu2 = theta[1] + X2 * theta[2:4];     y2  = randfun(n2 || 1, \"Normal\", mu2, sqrt(theta[5]));      /* Create dataset for center 1 */     create y2 var {\"y2\"};     append;     close y2;      create X2 from X2[colname={\"X2_1\" \"X2_2\" \"X2_3\"}];     append from X2;     close X2;      /* Transfer SAS data to the R session */     call ExportMatrixToR(X2, \"X2\");     call ExportMatrixToR(y2, \"y2\");  quit;"},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"map-estimates-at-the-local-centers","dir":"Articles","previous_headings":"Example","what":"MAP estimates at the local centers","title":"Using BFI in SAS","text":"following compute Maximum Posterior (MAP) estimators parameters center 1: Obtaining MAP estimators parameters center 2 using following:","code":"proc iml;      rsubmit;      #---------------------------     # Inverse Covariance Matrix     #---------------------------     # Creating the inverse covariance matrix for the Gaussian prior distribution:     Lambda <- inv.prior.cov(X1, lambda=0.05, family='gaussian')      #--------------------------     # MAP estimates at center 1     #--------------------------     fit1       <- MAP.estimation(y1, X1, family='gaussian', Lambda)     theta_hat1 <- fit1$theta_hat # intercept and coefficient estimates     A_hat1     <- fit1$A_hat     # minus the curvature matrix     summary(fit1, cur_mat=TRUE)    endrsubmit;  quit; proc iml;    rsubmit;          # Creating the inverse covariance matrix for the Gaussian prior distribution:     Lambda <- inv.prior.cov(X2, lambda=0.05, family='gaussian')      #--------------------------     # MAP estimates at center 2     #--------------------------     fit2       <- MAP.estimation(y2, X2, family='gaussian', Lambda)     theta_hat2 <- fit2$theta_hat     A_hat2     <- fit2$A_hat     summary(fit2, cur_mat=TRUE)    endrsubmit;  quit;"},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"bfi-at-central-center","dir":"Articles","previous_headings":"Example","what":"BFI at central center","title":"Using BFI in SAS","text":"Now, can utilize primary function bfi() acquire BFI estimates:","code":"proc iml;    rsubmit;        # Creating the inverse covariance matrix for central server:     Lambda <- inv.prior.cov(X1, lambda=0.05, family='gaussian') # the same as other centers        #----------------------     # BFI at central center     #----------------------     A_hats     <- list(A_hat1, A_hat2)     theta_hats <- list(theta_hat1, theta_hat2)     bfi        <- bfi(theta_hats, A_hats, Lambda)     summary(bfi, cur_mat=TRUE)    endrsubmit;    /* Transfer the outputs from R to SAS */   call ImportMatrixFromR(bfi, \"bfi\");    quit;"},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"datasets-included-in-the-bfi-package","dir":"Articles","previous_headings":"","what":"Datasets included in the BFI package","title":"Using BFI in SAS","text":"find use datasets available BFI package, use following codes:","code":"proc iml;    rsubmit;        # To find a list of all datasets included in the package     print(data(package = \"BFI\"))          # To use the 'Nurses' data     BFI::Nurses     cat(\"Dimension of the 'Nurses' data: \\n\", dim(Nurses))     cat(\"Colnames of the 'Nurses' data: \\n\", colnames(Nurses))      # To use the 'trauma' data     BFI::trauma     cat(\"Dimension of the 'trauma' data: \\n\", dim(trauma))     cat(\"Colnames of the 'trauma' data: \\n\", colnames(trauma))    endrsubmit;  quit;"},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"importing-the-data-from-r","dir":"Articles","previous_headings":"","what":"Importing the data from R","title":"Using BFI in SAS","text":"R objects data may brought back SAS well, manipulation might want SAS. , just grab bfi object Nurses data R print data SAS.","code":"proc iml;   submit / R;  * 'rsubmit' is equivalent to 'submit / R' ;     # Export 'bfi' object    ExportDataSetToSAS(bfi)     # Export dataset 'Nurses'    ExportDataSetToSAS(Nurses)       endsubmit; run;    proc print data=Nurses; run;"},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"bfi-as-a-sas-package","dir":"Articles","previous_headings":"","what":"BFI as a SAS Package","title":"Using BFI in SAS","text":"near future, releasing SAS/IML package BFI, can installed PACKAGE INSTALL statement SAS environment.","code":""},{"path":"https://hassanpazira.github.io/BFI/articles/SAS.html","id":"contact","dir":"Articles","previous_headings":"","what":"Contact","title":"Using BFI in SAS","text":"find errors, suggestions, like request something added, please file issue issue report send email : hassan.pazira@radboudumc.nl.","code":""},{"path":"https://hassanpazira.github.io/BFI/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Hassan Pazira. Author, maintainer. Emanuele Massa. Author. Marianne . Jonker. Author.","code":""},{"path":"https://hassanpazira.github.io/BFI/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pazira H, Massa E, Jonker MA (2024). BFI: Bayesian Federated Inference. R package version 2.0.1, https://CRAN.R-project.org/package=BFI.","code":"@Manual{,   title = {BFI: Bayesian Federated Inference},   author = {Hassan Pazira and Emanuele Massa and Marianne A. Jonker},   year = {2024},   note = {R package version 2.0.1},   url = {https://CRAN.R-project.org/package=BFI}, }"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"bfi-","dir":"","previous_headings":"","what":"Bayesian Federated Inference","title":"Bayesian Federated Inference","text":"Bayesian Federated Inference","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"description","dir":"","previous_headings":"","what":"Description","title":"Bayesian Federated Inference","text":"Due limited size available data sets especially rare diseases, sometimes challenging identify relevant predictive features using multivariable statistical analysis. issue may resolved combining data multiple centers one centralized location without sharing data , difficult reality privacy security concerns. address challenges, developed implemented Bayesian Federated Inference (BFI) framework multicenter data. aims leverage statistical power larger (combined) data sets without requiring data aggregated one location. BFI framework allows center use local data infer optimal parameter values well additional features posterior parameter distribution able gather information captured alternative techniques. One benefits BFI alternative approaches one inference cycle across centers required BFI. R package called BFI created perform Bayesian Federated Inference. following instructions install development version BFI package computer. Python SAS users can also apply BFI methodology respective environments. instructions, see Python SAS.","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"install-r-and-rstudio","dir":"","previous_headings":"","what":"Install R and RStudio","title":"Bayesian Federated Inference","text":"First, need install R RStudio: Install R Install RStudio Desktop (R installed) details installing R RStudio, see page. need help learning R, see RStudio Education.","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"install-bfi-package","dir":"","previous_headings":"","what":"Install BFI package","title":"Bayesian Federated Inference","text":"order install BFI package, invoke R RStudio follow one following steps:","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"installing-from-r","dir":"","previous_headings":"Install BFI package","what":"Installing from R","title":"Bayesian Federated Inference","text":"install load BFI package directly R, type following (Console)","code":"install.packages(\"BFI\") library(BFI)"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"installing-from-github","dir":"","previous_headings":"Install BFI package","what":"Installing from Github","title":"Bayesian Federated Inference","text":"install BFI package directly Github, need devtools package. type following install load : Next, install BFI follows: package can now loaded R used :","code":"install.packages(\"devtools\") library(devtools) devtools::install_github(\"hassanpazira/BFI\", dependencies = TRUE, build_vignettes = TRUE, force = TRUE) library(BFI)"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"update","dir":"","previous_headings":"","what":"Update","title":"Bayesian Federated Inference","text":"latest version BFIpackage 2.0.1. check current version BFI installed R library, use:","code":"packageVersion(\"BFI\")"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"details","dir":"","previous_headings":"","what":"Details","title":"Bayesian Federated Inference","text":"BFI package provides several functions, important following two main functions: MAP.estimation(): used centers, result sent central server. bfi(): used central server. access R documentation functions, example bfi(), enter following command:","code":"help(bfi, package = \"BFI\")  # without loading the BFI package # or, equivalently, after loading the BFI package  ?bfi"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Bayesian Federated Inference","text":"Let’s look following example see BFI package can used. examples details look BFI vignette typing use vignette(\"BFI\"), vignette(\"SAS\") vignette(\"Python\") see BFI, SAS Python vignettes separately Help tab RStudio. Now, generate two independent (local) data sets Gaussian distribution, apply package see works. First apply function MAP.estimation() local data, apply bfi() function aggregated results.","code":"browseVignettes(\"BFI\")  # to see all vignettes from the BFI package in an HTML browser. #------------- # y ~ Gaussian #------------- # model assumptions: p     <- 3                     # number of coefficients without intercept theta <- c(1, rep(2, p), 1.5)  # regression coefficients (theta[1] is the intercept) and sigma2 = 1.5  #----------------------------------- # Data simulation for local center 1 #----------------------------------- n1   <- 30                                       # sample size of center 1 X1   <- data.frame(matrix(rnorm(n1 * p), n1, p)) # continuous variables # linear predictor: eta1 <- theta[1] + as.matrix(X1) %*% theta[2:4] # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu1  <- gaussian()$linkinv(eta1) y1   <- rnorm(n1, mu1, sd = sqrt(theta[5]))  #----------------------------------- # Data simulation for local center 2 #----------------------------------- n2   <- 50                                       # sample size of center 2 X2   <- data.frame(matrix(rnorm(n2 * p), n2, p)) # continuous variables # linear predictor: eta2 <- theta[1] + as.matrix(X2) %*% theta[2:4] # inverse of the link function: mu2  <- gaussian()$linkinv(eta2) y2   <- rnorm(n2, mu2, sd = sqrt(theta[5]))  #--------------------- # Load the BFI package #--------------------- library(BFI)  #--------------------------- # Inverse Covariance Matrix #--------------------------- # Creating the inverse covariance matrix for the Gaussian prior distribution: Lambda <- inv.prior.cov(X1, lambda=0.05, family='gaussian') # the same for both centers  #-------------------------- # MAP estimates at center 1 #-------------------------- fit1       <- MAP.estimation(y1, X1, family='gaussian', Lambda) theta_hat1 <- fit1$theta_hat # intercept and coefficient estimates A_hat1     <- fit1$A_hat     # minus the curvature matrix  #-------------------------- # MAP estimates at center 2 #-------------------------- fit2       <- MAP.estimation(y2, X2, family='gaussian', Lambda) theta_hat2 <- fit2$theta_hat A_hat2     <- fit2$A_hat  #---------------------- # BFI at central center #---------------------- A_hats     <- list(A_hat1, A_hat2) theta_hats <- list(theta_hat1, theta_hat2) bfi        <- bfi(theta_hats, A_hats, Lambda) summary(bfi, cur_mat=TRUE)  #-------------------- # Stratified analysis #-------------------- # Stratified analysis when 'intercept' varies across two centers: newLambda1 <- inv.prior.cov(X1, lambda=c(0.1, 0.3), family='gaussian', stratified=TRUE, strat_par = 1) # 'newLambda1' is used the prior for combined data and 'Lambda' is used the prior for locals bfi1 <- bfi(theta_hats, A_hats, list(Lambda, newLambda1), stratified=TRUE, strat_par=1) summary(bfi1, cur_mat=TRUE)  # Stratified analysis when 'sigma2' varies across two centers: newLambda2 <- inv.prior.cov(X1, lambda=c(0.1, 0.3), family='gaussian', stratified=TRUE, strat_par = 2) # 'newLambda2' is used the prior for combined data and 'Lambda' is used the prior for locals bfi2 <- bfi(theta_hats, A_hats, list(Lambda, newLambda2), stratified=TRUE, strat_par=2) summary(bfi2, cur_mat=TRUE)  # Stratified analysis when 'intercept' and 'sigma2' vary across 2 centers: newLambda3 <- inv.prior.cov(X1, lambda=c(0.1, 0.2, 0.3), family='gaussian', stratified=TRUE, strat_par = c(1, 2)) # 'newLambda3' is used the prior for combined data and 'Lambda' is used the prior for locals bfi3 <- bfi(theta_hats, A_hats, list(Lambda, newLambda3), stratified=TRUE, strat_par=1:2) summary(bfi3, cur_mat=TRUE)"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Bayesian Federated Inference","text":"cite BFI publications, please use:","code":"citation(\"BFI\")"},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Bayesian Federated Inference","text":"technical papers package: BFI Generalized Linear Models (GLMs) BFI Survival Models BFI Heterogeneous Populations","code":""},{"path":"https://hassanpazira.github.io/BFI/index.html","id":"contact","dir":"","previous_headings":"","what":"Contact","title":"Bayesian Federated Inference","text":"find errors, suggestions, like request something added, please file issue issue report send email : hassan.pazira@radboudumc.nl.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal BFI Functions — BFI-internal","title":"Internal BFI Functions — BFI-internal","text":"Internal BFI functions.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-internal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal BFI Functions — BFI-internal","text":".l.maker() returns curvature matrix local. negloglik.theta() returns negative log-likelihood regression coefficients error variance, can utilized optimization purposes. model.maker() returns outcome design matrix, incorporating dummy variables categorical covariates present, e.g., expanding factors set dummy variables expanding interactions similarly. optim.survival() general-purpose optimization algorithm based “L-BFGS-B” method, returns vector estimates coefficients baseline hazard parameters. ql.LRT() returns optimal order/degree exponentiated polynomial model, obtained likelihood ratio test, 'cox' family. lambda.poly() returns baseline hazard function exponentiated polynomial form. .basis() creates integral output basis ibasis = TRUE. also indicator function \\(k^{th}\\) \\((k+1)^{th}\\) time points ibasis = FALSE.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-internal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal BFI Functions — BFI-internal","text":"functions intended use users.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-internal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Internal BFI Functions — BFI-internal","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Federated Inference — BFI-package","title":"Bayesian Federated Inference — BFI-package","text":"Bayesian Federated Inference method combines inference results different (medical) centers without sharing data. version package, user can fit models specifying Gaussian, Binomial (Logistic) Survival families.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Federated Inference — BFI-package","text":"MAP.estimation bfi main functions. functions utility functions. examples provided vignettes accompanying package order show package can applied real data. vignettes can found package website https://hassanpazira.github.io/BFI/ within R package installed, e.g., via vignette(\"BFI\", package = \"BFI\").","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian Federated Inference — BFI-package","text":"Hassan Pazira, Emanuele Massa, Marianne . Jonker Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Federated Inference — BFI-package","text":"Jonker M.., Pazira H. Coolen .C.C. (2024). Bayesian federated inference estimating statistical models based non-shared multicenter data sets, Statistics Medicine, 43(12): 2421-2438. <https://doi.org/10.1002/sim.10072> Pazira H., Massa E., Weijers J..M., Coolen .C.C. Jonker M.. (2025b). Bayesian Federated Inference Survival Models, Journal Applied Statistics (Accepted). <https://arxiv.org/abs/2404.17464> Jonker M.., Pazira H. Coolen .C.C. (2025a). Bayesian Federated Inference regression models based non-shared medical center data, Research Synthesis Methods, 1-41. <https://doi.org/10.1017/rsm.2025.6>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian Federated Inference — bfi","title":"Bayesian Federated Inference — bfi","text":"bfi function can used (central server) combine inference results separate datasets (without combining data) approximate inferred datasets merged. function can handle linear, logistic survival regression models.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian Federated Inference — bfi","text":"","code":"bfi(theta_hats = NULL,     A_hats,     Lambda,     family = c(\"gaussian\", \"binomial\", \"survival\"),     basehaz = c(\"weibul\", \"exp\", \"gomp\", \"poly\", \"pwexp\", \"unspecified\"),     stratified = FALSE,     strat_par = NULL,     center_spec = NULL,     theta_A_polys = NULL,     treat_round = NULL,     for_ATE = NULL,     p,     q_ls,     center_zero_sample = FALSE,     which_cent_zeros,     zero_sample_covs,     refer_cats,     zero_cats,     lev_no_ref_zeros)"},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian Federated Inference — bfi","text":"theta_hats list \\(L\\) vectors maximum posteriori (MAP) estimates model parameters \\(L\\) centers. vectors must equal dimensions. See ‘Details’. A_hats list \\(L\\) minus curvature matrices \\(L\\) centers. matrices must equal dimensions. See ‘Details’. Lambda list \\(L+1\\) matrices. \\(k^{\\th}\\) matrix chosen inverse variance-covariance matrix Gaussian distribution used prior distribution center \\(k\\), \\(k=1,2,\\ldots,L\\). last matrix chosen variance-covariance matrix Gaussian prior (fictive) combined data set. stratified = FALSE, \\(L+1\\) matrices must equal dimensions. , stratified = TRUE, first \\(L\\) matrices must equal dimensions last matrix different (greater) dimention others. See ‘Details’. family character string representing family name used local centers. Can abbreviated. basehaz character string representing one available baseline hazard functions; exponential (\"exp\"), Weibull (\"weibul\", default), Gompertz (\"gomp\"), exponentiated polynomial (\"poly\"), piecewise exponential (\"pwexp\"), unspecified baseline hazard (\"unspecified\"). used family = \"survival\". Can abbreviated. basehaz = \"unspecified\", means (semi-parametric) Cox model considered, parameters (regression coefficients) estimated using partial log-likelihood. stratified logical flag performing stratified analysis. stratified = TRUE, parameter(s) selected strat_par argument allowed different across centers (deal heterogeneity across centers), except argument center_spec NULL. Default stratified = FALSE. See ‘Details’ ‘Examples’. strat_par integer vector indicating stratification parameter(s). can used deal heterogeneity due center-specific parameters. \"binomial\" \"gaussian\" families one- two-element integer vector values \\(1\\) /\\(2\\) /used indicate “intercept” /“sigma2” allowed vary, respectively. \"binomial\" family length vector one refers “intercept”, value element \\(1\\) (handel heterogeneity across outcome means). \"gaussian\" vector can \\(1\\) indicating “intercept” (handeling heterogeneity across outcome means), \\(2\\) indicating “sigma2” (handeling heterogeneity due nuisance parameter), \\(c(1, 2)\\) “intercept” “sigma2”. family = \"survival\", vector can contain combination values ranging 1 maximum number parameters baseline hazard function, .e., \\(1\\) \"exp\", \\(2\\) \"weibul\" \"gomp\", max_order + 1 \"poly\", n_intervals \"pwexp\". example, \"weibul\", strat_par \\(1\\), \\(2\\) \\(c(1, 2)\\), \\(1\\) represents \\(\\omega_1\\) \\(2\\) represents \\(\\omega_2\\). argument used stratified = TRUE center_spec = NULL. Default strat_par = NULL. See ‘Details’ ‘Examples’. center_spec vector \\(L\\) elements account heterogeneity across centers due clustering. argument used stratified = TRUE strat_par = NULL. element represents specific feature corresponding center. must one specific value attribute center. vector numeric, characteristic factor vector. Note , order centers vector center_spec must list argument theta_hats. used data type argument center_spec must categorical. Default center_spec = NULL. See also ‘Details’ ‘Examples’. theta_A_polys list \\(L\\) elements element array theta_A_ploy (output MAP.estimation function, MAP.estimation()$theta_A_ploy) corresponding center. argument, theta_A_polys, used family = \"survival\" basehaz = \"poly\". See ‘Details’ ‘Examples’. treat_round character string representing \"first\" \"second\" rounds estimating treatment effect. for_ATE list \\(L\\) vectors 4 (survival) 9 (binomial gaussian) elements calculate treatment effect. vectors must equal dimensions. treat_round = \"first\", for_ATE must NULL. treat_round = \"second\", for_ATE must list. defined using output MAP.estimation()$for_ATE obtained first round. See ‘Details’ ‘Examples’. p integer representing number covariates/coefficients. can found output MAP.estimation function, MAP.estimation()$np). argument, p, used stratified = TRUE family = \"survival\". q_ls vector \\(L\\) elements element order (minus 1) exponentiated polynomial baseline hazard function corresponding center, .e., element value q_l (output MAP.estimation function, MAP.estimation()$q_l). argument, q_ls, used family = \"survival\", family = \"survival\" basehaz = \"poly\". can also scalar represents maximum value q_l's across centers. center_zero_sample logical flag indicating whether center categorical covariate observations/individuals one categories. used address heterogeneity across centers due center-specific covariates. Default center_zero_sample = FALSE. detailes see ‘References’. which_cent_zeros integer vector representing center(s) one categorical covariate individuals one categories. used center_zero_sample = TRUE. zero_sample_covs vector element character string representing categorical covariate samples/observations one categories corresponding center. element vector can obtained output MAP.estimation function corresponding center, MAP.estimation()$zero_sample_cov. used center_zero_sample = TRUE. refer_cats vector element character string representing reference category corresponding center. element vector can obtained output MAP.estimation function corresponding center, MAP.estimation()$refer_cat. vector used center_zero_sample = TRUE. zero_cats vector element character string representing category samples/observations corresponding center. element vector can obtained output MAP.estimation function corresponding center, .e., MAP.estimation()$zero_cat. used center_zero_sample = TRUE. lev_no_ref_zeros list number elements equals length which_cent_zeros argument. element list vector containing names levels categorical covariate samples/observations one categories corresponding center. However,  name category samples name reference category excluded vector. element list can obtained output MAP.estimation function, .e., MAP.estimation()$lev_no_ref_zero. argument used center_zero_sample = TRUE.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian Federated Inference — bfi","text":"bfi returns list containing following components: theta_hat vector estimates obtained combining inference results \\(L\\) centers 'BFI' methodology. intercept fitted every center stratified = FALSE, one general “intercept” vector, stratified = TRUE strat_par = 1, \\(L\\) different intercepts model, center one; A_hat minus curvature (Hessian) matrix obtained 'BFI' method combined model. stratified = TRUE, dimension matrix always greater stratified = FALSE; sd vector (posterior) standard deviation estimates theta_hat obtained matrix A_hat, .e., vector equals sqrt(diag(solve(A_hat))) equals square root elements diagonal inverse A_hat matrix. family family object used; basehaz baseline hazard function used; stratified whether stratified analysis done ; strat_par stratification parameter(s) used; S_var sample variance treatment control arms. ATE estimates treatment effect. Two diffterent estimations (IPTW wIPTW) family gaussian binomial, one estimation family  survival. detailes see ‘References’.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian Federated Inference — bfi","text":"bfi function implements BFI approach described papers Jonker et. al. (2024a), Pazira et. al. (2024) Jonker et. al. (2024b) given references. inference results gathered different (\\(L\\)) centers combined, BFI estimates model parameters curvature matrix evaluated point returned. inference result center must obtained using MAP.estimation function separately, results (coming different centers) compiled list used input bfi(). models different centers defined exactly way; among others, exactly covariates included models. parameter vectors defined exactly , \\(L\\) vectors matrices input lists theta_hat's A_hat's defined way (e.g., covariates need included models order). Note order elements lists theta_hats, A_hats Lambda, must respect centers, every list element \\(\\ell^{\\th}\\) position center \\(\\ell\\). also case vector center_spec. locations intercept = FALSE, stratified analysis possible anymore binomial family. stratified = FALSE, strat_par center_spec must NULL (defaults), stratified = TRUE one two must NULL. stratified = FALSE \\(L+1\\) matrices Lambda equal, sufficient give (list ) one matrix . cases stratified argument (TRUE FALSE), first \\(L\\) matrices equal, argument Lambda can list two matrices, fist matrix represents chosen variance-covariance matrix local centers second one chosen matrix combined data set. last matrix list argument Lambda can built function inv.prior.cov(). data type used argument center_spec continuous categorical number categories equal number centers, one can use stratified = TRUE center_spec = NULL, set strat_par NULL (.e., \\(1\\), \\(2\\) \\((1, 2)\\)). Indeed, case, stratification parameter(s) given argument strat_par assumed different across centers. family = 'survival' basehaz = 'poly', arguments theta_hats A_hats provided. Instead, theta_A_polys q_ls arguments defined using local information, specifically MAP.estimation()$theta_A_poly MAP.estimation()$q_l, respectively. See Example 3 ‘Examples’. estimating treatment effect, first round, treat_round = \"first\", argument for_ATE must NULL (default) family must set binomial (family handled automatically.)","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian Federated Inference — bfi","text":"Jonker M.., Pazira H. Coolen .C.C. (2024a). Bayesian federated inference estimating statistical models based non-shared multicenter data sets, Statistics Medicine, 43(12): 2421-2438. <https://doi.org/10.1002/sim.10072> Pazira H., Massa E., Weijers J..M., Coolen .C.C. Jonker M.. (2025b). Bayesian Federated Inference Survival Models, Journal Applied Statistics (Accepted). <https://arxiv.org/abs/2404.17464> Jonker M.., Pazira H. Coolen .C.C. (2025a). Bayesian Federated Inference regression models based non-shared medical center data, Research Synthesis Methods, 1-41. <https://doi.org/10.1017/rsm.2025.6> van den Heuvel Z.D., Pazira H. Jonker M.. (2025c). Bayesian Federated Causal Inference observational data, arXiv. <https://arxiv.org/abs/???>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bayesian Federated Inference — bfi","text":"Hassan Pazira Marianne Jonker  Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/BFI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian Federated Inference — bfi","text":"","code":"################################################# ##  Example 1:  y ~ Binomial  (L = 2 centers)  ## #################################################  # Setting a seed for reproducibility set.seed(112358)  #------------------------------------# # Data Simulation for Local Center 1 # #------------------------------------# n1 <- 30                                           # sample size of center 1 X1 <- data.frame(x1=rnorm(n1),                     # continuous variable                  x2=sample(0:2, n1, replace=TRUE)) # categorical variable # make dummy variables X1x2_1 <- ifelse(X1$x2 == '1', 1, 0) X1x2_2 <- ifelse(X1$x2 == '2', 1, 0) X1$x2  <- as.factor(X1$x2) # regression coefficients beta <- 1:4  # beta[1] is the intercept # linear predictor: eta1   <- beta[1] + X1$x1 * beta[2] + X1x2_1 * beta[3] + X1x2_2 * beta[4] # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu1    <- binomial()$linkinv(eta1) y1     <- rbinom(n1, 1, mu1)  #------------------------------------# # Data Simulation for Local Center 2 # #------------------------------------# n2 <- 50                                           # sample size of center 2 X2 <- data.frame(x1=rnorm(n2),                     # continuous variable                  x2=sample(0:2, n2, replace=TRUE)) # categorical variable # make dummy variables: X2x2_1 <- ifelse(X2$x2 == '1', 1, 0) X2x2_2 <- ifelse(X2$x2 == '2', 1, 0) X2$x2  <- as.factor(X2$x2) # linear predictor: eta2   <- beta[1] + X2$x1 * beta[2] + X2x2_1 * beta[3] + X2x2_2 * beta[4] # inverse of the link function: mu2    <- binomial()$linkinv(eta2) y2     <- rbinom(n2, 1, mu2)  #---------------------------# # MAP Estimates at Center 1 # #---------------------------# # Assume the same inverse covariance matrix (Lambda) for both centers: Lambda     <- inv.prior.cov(X1, lambda = 0.01, family = 'binomial') fit1       <- MAP.estimation(y1, X1, family = 'binomial', Lambda) theta_hat1 <- fit1$theta_hat # intercept and coefficient estimates A_hat1     <- fit1$A_hat     # minus the curvature matrix  #---------------------------# # MAP Estimates at Center 2 # #---------------------------# fit2       <- MAP.estimation(y2, X2, family='binomial', Lambda) theta_hat2 <- fit2$theta_hat A_hat2     <- fit2$A_hat  #-----------------------# # BFI at Central Server # #-----------------------# theta_hats <- list(theta_hat1, theta_hat2) A_hats     <- list(A_hat1, A_hat2) bfi        <- bfi(theta_hats, A_hats, Lambda, family='binomial') class(bfi) #> [1] \"bfi\" summary(bfi, cur_mat=TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   1.4479  0.8145 -0.1485   3.0444 #> x1            2.4951  0.8978  0.7355   4.2547 #> x21           4.1023  1.6217  0.9239   7.2807 #> x22           2.2199  1.2637 -0.2570   4.6968 #>  #> Dispersion parameter (sigma2):  1  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      x1     x21     x22 #> (Intercept)      3.8045 -2.8450  0.7721  0.8694 #> x1              -2.8450  4.0346 -1.2184 -0.5469 #> x21              0.7721 -1.2184  0.7821  0.0000 #> x22              0.8694 -0.5469  0.0000  0.8794  ###---------------------### ### Stratified Analysis ### ###---------------------###  # By running the following line an error appears because # when stratified = TRUE, both 'strat_par' and 'center_spec' can not be NULL: Just4check1 <- try(bfi(theta_hats, A_hats, Lambda, family = 'binomial',                    stratified = TRUE), TRUE) class(Just4check1) # By default, both 'strat_par' and 'center_spec' are NULL! #> [1] \"try-error\"  # By running the following line an error appears because when stratified = TRUE, # last matrix in 'Lambda' should not have the same dim. as the other local matrices: Just4check2 <- try(bfi(theta_hats, A_hats, Lambda, stratified = TRUE,                    strat_par = 1), TRUE) class(Just4check2) # All matices in Lambda have the same dimension! #> [1] \"try-error\"  # Stratified analysis when 'intercept' varies across two centers: newLam <- inv.prior.cov(X1, lambda=c(0.1, 0.3), family = 'binomial',                         stratified = TRUE, strat_par = 1) bfi <- bfi(theta_hats, A_hats, list(Lambda, newLam), family = 'binomial',            stratified=TRUE, strat_par=1) summary(bfi, cur_mat=TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>                  Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)_loc1   2.3167  2.5315 -2.6448   7.2783 #> (Intercept)_loc2   1.1865  0.7586 -0.3003   2.6733 #> x1                 1.4500  0.7562 -0.0321   2.9322 #> x21                1.9848  1.1901 -0.3479   4.3174 #> x22                1.3621  1.0287 -0.6542   3.3784 #>  #> Dispersion parameter (sigma2):  1  #>  #> Minus the Curvature Matrix:  #>  #>                  (Intercept)_loc1 (Intercept)_loc2      x1     x21     x22 #> (Intercept)_loc1           0.1564           0.0000  0.0028  0.0082  0.0134 #> (Intercept)_loc2           0.0000           3.8380 -2.8478  0.7640  0.8561 #> x1                         0.0028          -2.8478  4.3246 -1.2184 -0.5469 #> x21                        0.0082           0.7640 -1.2184  1.0721  0.0000 #> x22                        0.0134           0.8561 -0.5469  0.0000  1.1694   ###---------------------### ###  Treatment Effect   ### ###---------------------###  set.seed(112358)  #------------------------------------# # Data Simulation for Local Center 1 # #------------------------------------# n1 <- 30                                           # sample size of center 1 X1 <- data.frame(x1=rnorm(n1),                     # continuous variable                  treatment=sample(1:2, n1, replace=TRUE)) # categorical variable X1$treatment  <- as.factor(X1$treatment)  # regression coefficients beta <- 1:3  # beta[1] is the intercept # make dummy variable X1x2_2 <- ifelse(X1$treatment == '2', 1, 0) # linear predictor: eta1   <- beta[1] + X1$x1 * beta[2] + X1x2_2 * beta[3] # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu1    <- binomial()$linkinv(eta1) y1     <- rbinom(n1, 1, mu1)  #------------------------------------# # Data Simulation for Local Center 2 # #------------------------------------# n2 <- 50                                           # sample size of center 2 X2 <- data.frame(x1=rnorm(n2),                     # continuous variable                  treatment=sample(1:2, n2, replace=TRUE)) # categorical variable X2$treatment  <- as.factor(X2$treatment) # make dummy variables: X2x2_2 <- ifelse(X2$treatment == '2', 1, 0) # linear predictor: eta2   <- beta[1] + X2$x1 * beta[2] + X2x2_2 * beta[3] # inverse of the link function: mu2    <- binomial()$linkinv(eta2) y2     <- rbinom(n2, 1, mu2)  # The algorithm works even if the order of the covariates are not the same across centers X2 <- X2[,c(\"treatment\",\"x1\")]  #-------------# # First Round # #-------------#  ## Center 1: Lambda1 <- inv.prior.cov(X1, lambda = 0.01, family = 'binomial', treatment = \"treatment\",                          treat_round=\"first\") fit1_r1 <- MAP.estimation(y1, X1, family = 'binomial', Lambda = Lambda1,                           treatment = \"treatment\", treat_round = \"first\") # In the first round, the output is without the threatment! summary(fit1_r1) #>  #> Summary of the local model: #>  #>    Formula: y ~ x1  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)  -0.7226  0.3968 -1.5003   0.0552 #> x1            0.1688  0.3960 -0.6074   0.9450 #>  #> Dispersion parameter (sigma2):  1  #>             log Lik Posterior:  -19.01  #>                   Convergence:  0   ## Center 2: Lambda2 <- inv.prior.cov(X2, lambda = 0.01, family = 'binomial', treatment = \"treatment\",                          treat_round=\"first\") fit2_r1 <- MAP.estimation(y2, X2, family = 'binomial', Lambda = Lambda2,                           treatment = \"treatment\", treat_round = \"first\") fit2_r1 #> $theta_hat #> (Intercept)          x1  #>  -0.2509259  -0.1262514  #>  #> $A_hat #>             (Intercept)        x1 #> (Intercept)   12.292006 -1.054369 #> x1            -1.054369  9.822675 #>  #> $sd #> (Intercept)          x1  #>   0.2865479   0.3205485  #>  #> $Lambda #>             (Intercept)   x1 #> (Intercept)        0.01 0.00 #> x1                 0.00 0.01 #>  #> $formula #> [1] y ~ x1 #>  #> $names #> [1] \"(Intercept)\" \"x1\"          #>  #> $n #> [1] 50 #>  #> $np #> [1] 2 #>  #> $treatment #> [1] \"treatment\" #>  #> $refer_treat #> NULL #>  #> $gamma_bfi #> NULL #>  #> $RCT_propens #> NULL #>  #> $propensity #> NULL #>  #> $for_ATE #> NULL #>  #> $zero_sample_cov #> NULL #>  #> $refer_cat #> NULL #>  #> $zero_cat #> NULL #>  #> $value #> [1] 34.21872 #>  #> $family #> [1] \"binomial\" #>  #> $basehaz #> NULL #>  #> $intercept #> [1] TRUE #>  #> $convergence #> [1] 0 #>  #> $control #> $control$maxit #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"bfi\"  ## Centeral Server: theta_hats_r1 <- list(fit1_r1$theta_hat, fit2_r1$theta_hat) A_hats_r1 <- list(fit1_r1$A_hat, fit2_r1$A_hat) fitbfi_r1 <- bfi(theta_hats_r1, A_hats_r1, Lambda1, family = 'binomial',                  treat_round = \"first\") summary(fitbfi_r1, cur_mat = TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)  -0.3964  0.2299 -0.8470   0.0543 #> x1           -0.0437  0.2464 -0.5266   0.4392 #>  #> Dispersion parameter (sigma2):  1  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      x1 #> (Intercept)     18.9205  0.3314 #> x1               0.3314 16.4782  #--------------# # Second Round # #--------------#  ## Center 1: Lambda11 <- inv.prior.cov(X1, lambda = 0.01, family = 'binomial', treatment = \"treatment\",                          treat_round=\"second\") fit1_r2 <- MAP.estimation(y1, X1, family = 'binomial', Lambda = Lambda11,                           treatment = \"treatment\", treat_round = \"second\",                           gamma_bfi = fitbfi_r1$theta_hat) # In the second round, the output is only with the threatment! summary(fit1_r2) #>  #> Summary of the local model: #>  #>    Formula: y ~ x1  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)  -0.2078  0.8768 -1.9262   1.5106 #> treatment     0.8105  0.6168 -0.3984   2.0194 #>  #> Dispersion parameter (sigma2):  1  #>             log Lik Posterior:  -34.09  #>                   Convergence:  0   ## Center 2: Lambda22 <- inv.prior.cov(X2, lambda = 0.01, family = 'binomial', treatment = \"treatment\",                          treat_round=\"second\") fit2_r2 <- MAP.estimation(y2, X2, family = 'binomial', Lambda = Lambda22,                           treatment = \"treatment\", treat_round = \"second\",                           gamma_bfi = fitbfi_r1$theta_hat) fit2_r2 #> $theta_hat #> (Intercept)   treatment  #>   -4.175237    5.266223  #>  #> $A_hat #>             (Intercept) treatment #> (Intercept)    8.927176  9.011428 #> treatment      9.011428  9.209932 #>  #> $sd #> (Intercept)   treatment  #>    3.015475    2.968824  #>  #> $Lambda #>             (Intercept) treatment #> (Intercept)        0.01      0.00 #> treatment          0.00      0.01 #>  #> $formula #> [1] y ~ x1 #>  #> $names #> [1] \"(Intercept)\" \"treatment\"   #>  #> $n #> [1] 50 #>  #> $np #> [1] 2 #>  #> $treatment #> [1] \"treatment\" #>  #> $refer_treat #> [1] \"1\" #>  #> $gamma_bfi #>   (Intercept)          x1 #> 1  -0.3963759 -0.04370602 #>  #> $RCT_propens #> NULL #>  #> $propensity #>  [1] 0.4011608 0.4046425 0.4016316 0.4065235 0.4013848 0.3921165 0.4006005 #>  [8] 0.4171208 0.3974666 0.3818413 0.4161945 0.4135265 0.4065453 0.4080270 #> [15] 0.4035998 0.4049694 0.3868497 0.4058360 0.4051789 0.4120526 0.4130087 #> [22] 0.3800897 0.4107172 0.4150832 0.3942670 0.4036748 0.4111251 0.4017086 #> [29] 0.4014951 0.3879404 0.3867900 0.4146683 0.4038661 0.3964183 0.4211174 #> [36] 0.4029404 0.4135190 0.4144179 0.3932297 0.4003255 0.4077919 0.3905918 #> [43] 0.4088652 0.4097657 0.3931901 0.3913643 0.3953093 0.4043939 0.4066814 #> [50] 0.4074400 #>  #> $for_ATE #> [1] 22.00000 28.00000 22.00000 22.00000 54.53770 54.53770 46.87703 34.95445 #> [9] 21.00000 #>  #> $zero_sample_cov #> NULL #>  #> $refer_cat #> NULL #>  #> $zero_cat #> NULL #>  #> $value #> [1] 26.903 #>  #> $family #> [1] \"binomial\" #>  #> $basehaz #> NULL #>  #> $intercept #> [1] TRUE #>  #> $convergence #> [1] 0 #>  #> $control #> $control$maxit #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"bfi\"  ## Centeral Server: theta_hats_r2 <- list(fit1_r2$theta_hat, fit2_r2$theta_hat) A_hats_r2 <- list(fit1_r2$A_hat, fit2_r2$A_hat) for_ATEs <- list(fit1_r2$for_ATE, fit2_r2$for_ATE) fitbfi_r2 <- bfi(theta_hats_r2, A_hats_r2, Lambda11, family = 'binomial',                  treat_round = \"second\", for_ATE = for_ATEs) fitbfi_r2$S_var #> $treatment #> [1] 0.06048387 #>  #> $control #> [1] 0.2393617 #>  fitbfi_r2$ATE #> $IPTW #> [1] 0.2269916 #>  #> $wIPTW #> [1] 0.234374 #>  summary(fitbfi_r2) #>  #> Summary of the BFI model: #>  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.1581  0.6978 -1.2096   1.5258 #> treatment     0.6975  0.5533 -0.3869   1.7819 #>  #> Dispersion parameter (sigma2):  1  #>  #> Average Treatment Effect (ATE):   #>  #>          IPTW:  0.227  #>         wIPTW:  0.2344  #>  #> Sample Variance:   #>  #>     Treatment:  0.06048  #>       Control:  0.2394    ################################################# ##  Example 2:  y ~ Gaussian  (L = 3 centers)  ## #################################################  # Setting a seed for reproducibility set.seed(112358)  p     <- 3                     # number of coefficients without 'intercept' theta <- c(1, rep(2, p), 1.5)  # reg. coef.s (theta[1] is 'intercept') & 'sigma2' = 1.5  #------------------------------------# # Data Simulation for Local Center 1 # #------------------------------------# n1   <- 30                                       # sample size of center 1 X1   <- data.frame(matrix(rnorm(n1 * p), n1, p)) # continuous variables # linear predictor: eta1 <- theta[1] + as.matrix(X1)  # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu1  <- gaussian()$linkinv(eta1) y1   <- rnorm(n1, mu1, sd = sqrt(theta[5]))  #------------------------------------# # Data Simulation for Local Center 2 # #------------------------------------# n2   <- 40                                       # sample size of center 2 X2   <- data.frame(matrix(rnorm(n2 * p), n2, p)) # continuous variables # linear predictor: eta2 <- theta[1] + as.matrix(X2)  # inverse of the link function: mu2  <- gaussian()$linkinv(eta2) y2   <- rnorm(n2, mu2, sd = sqrt(theta[5]))  #------------------------------------# # Data Simulation for Local Center 3 # #------------------------------------# n3   <- 50                                       # sample size of center 3 X3   <- data.frame(matrix(rnorm(n3 * p), n3, p)) # continuous variables # linear predictor: eta3 <- theta[1] + as.matrix(X3)  # inverse of the link function: mu3  <- gaussian()$linkinv(eta3) y3   <- rnorm(n3, mu3, sd = sqrt(theta[5]))  #---------------------------# # Inverse Covariance Matrix # #---------------------------# # Creating the inverse covariance matrix for the Gaussian prior distribution: # the same for both centers Lambda <- inv.prior.cov(X1, lambda = 0.05, family='gaussian')  #---------------------------# # MAP Estimates at Center 1 # #---------------------------# fit1       <- MAP.estimation(y1, X1, family = 'gaussian', Lambda) theta_hat1 <- fit1$theta_hat # intercept and coefficient estimates A_hat1     <- fit1$A_hat     # minus the curvature matrix  #---------------------------# # MAP Estimates at Center 2 # #---------------------------# fit2       <- MAP.estimation(y2, X2, family = 'gaussian', Lambda) theta_hat2 <- fit2$theta_hat A_hat2     <- fit2$A_hat  #---------------------------# # MAP Estimates at Center 3 # #---------------------------# fit3       <- MAP.estimation(y3, X3, family = 'gaussian', Lambda) theta_hat3 <- fit3$theta_hat A_hat3     <- fit3$A_hat  #-----------------------# # BFI at Central Server # #-----------------------# A_hats     <- list(A_hat1, A_hat2, A_hat3) theta_hats <- list(theta_hat1, theta_hat2, theta_hat3) bfi        <- bfi(theta_hats, A_hats, Lambda, family = 'gaussian') summary(bfi, cur_mat=TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.8666  0.1008  0.6691   1.0641 #> X1            0.9385  0.1010  0.7405   1.1364 #> X2           -0.0077  0.0969 -0.1976   0.1823 #> X3            0.0199  0.1001 -0.1762   0.2161 #>  #> Dispersion parameter (sigma2):  1.177  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      X1       X2       X3   sigma2 #> (Intercept)    103.1370 -1.6100  17.4702 -13.8002  -0.2532 #> X1              -1.6100 98.6784   7.0582  -2.9109  -0.2822 #> X2              17.4702  7.0582 109.9666  -1.7587   0.0094 #> X3             -13.8002 -2.9109  -1.7587 101.7764  -0.0120 #> sigma2          -0.2532 -0.2822   0.0094  -0.0120 240.6151  ###---------------------### ### Stratified Analysis ### ###---------------------###  # Stratified analysis when 'intercept' varies across two centers: newLam1 <- inv.prior.cov(X1, lambda = c(0.1,0.3), family = 'gaussian',                          stratified = TRUE, strat_par = 1, L = 3) # 'newLam1' is used as the prior for combined data and # 'Lambda' is used as the prior for locals list_newLam1 <- list(Lambda, newLam1) bfi1 <- bfi(theta_hats, A_hats, list_newLam1, family = 'gaussian',             stratified = TRUE, strat_par = 1) summary(bfi1, cur_mat = TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>                  Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)_loc1   0.7067  0.2132  0.2888   1.1246 #> (Intercept)_loc2   0.9419  0.1681  0.6125   1.2713 #> (Intercept)_loc3   0.8819  0.1539  0.5802   1.1835 #> X1                 0.9492  0.1022  0.7490   1.1495 #> X2                -0.0141  0.0973 -0.2048   0.1765 #> X3                 0.0276  0.1016 -0.1715   0.2267 #>  #> Dispersion parameter (sigma2):  1.176  #>  #> Minus the Curvature Matrix:  #>  #>                  (Intercept)_loc1 (Intercept)_loc2 (Intercept)_loc3      X1 #> (Intercept)_loc1          22.1366           0.0000           0.0000  3.3627 #> (Intercept)_loc2           0.0000          38.6215           0.0000 -7.1785 #> (Intercept)_loc3           0.0000           0.0000          42.6288  2.2058 #> X1                         3.3627          -7.1785           2.2058 98.7284 #> X2                         1.1877           9.8374           6.4452  7.0582 #> X3                        -1.3802         -13.1667           0.7467 -2.9109 #> sigma2                    -0.0723          -0.0929          -0.0880 -0.2822 #>                        X2       X3   sigma2 #> (Intercept)_loc1   1.1877  -1.3802  -0.0723 #> (Intercept)_loc2   9.8374 -13.1667  -0.0929 #> (Intercept)_loc3   6.4452   0.7467  -0.0880 #> X1                 7.0582  -2.9109  -0.2822 #> X2               110.0166  -1.7587   0.0094 #> X3                -1.7587 101.8264  -0.0120 #> sigma2             0.0094  -0.0120 240.8651  # Stratified analysis when 'sigma2' varies across two centers: newLam2 <- inv.prior.cov(X1, lambda = c(0.1,0.3), family = 'gaussian',                          stratified = TRUE, strat_par = 2, L = 3) # 'newLam2' is used as the prior for combined data and 'Lambda' is used as # the prior for locals list_newLam2 <- list(Lambda, newLam2) bfi2 <- bfi(theta_hats, A_hats, list_newLam2, family = 'gaussian',             stratified = TRUE, strat_par=2) summary(bfi2, cur_mat = TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.8661  0.1007  0.6687   1.0636 #> X1            0.9380  0.1010  0.7401   1.1359 #> X2           -0.0076  0.0969 -0.1975   0.1823 #> X3            0.0199  0.1001 -0.1763   0.2160 #> sigma2_loc1   1.3559  0.1285  1.1040   1.6079 #> sigma2_loc2   1.0350  0.1115  0.8165   1.2535 #> sigma2_loc3   1.1728  0.0998  0.9772   1.3683 #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      X1       X2       X3 sigma2_loc1 sigma2_loc2 #> (Intercept)    103.1870 -1.6100  17.4702 -13.8002     -0.0723     -0.0929 #> X1              -1.6100 98.7284   7.0582  -2.9109     -0.0915     -0.0989 #> X2              17.4702  7.0582 110.0166  -1.7587      0.0081      0.0027 #> X3             -13.8002 -2.9109  -1.7587 101.8264     -0.0110      0.0018 #> sigma2_loc1     -0.0723 -0.0915   0.0081  -0.0110     60.5223      0.0000 #> sigma2_loc2     -0.0929 -0.0989   0.0027   0.0018      0.0000     80.4576 #> sigma2_loc3     -0.0880 -0.0918  -0.0015  -0.0029      0.0000      0.0000 #>             sigma2_loc3 #> (Intercept)     -0.0880 #> X1              -0.0918 #> X2              -0.0015 #> X3              -0.0029 #> sigma2_loc1      0.0000 #> sigma2_loc2      0.0000 #> sigma2_loc3    100.4852  # Stratified analysis when 'intercept' and 'sigma2' vary across 2 centers: newLam3 <- inv.prior.cov(X1, lambda = c(0.1,0.2,0.3), family = 'gaussian',                          stratified = TRUE, strat_par = c(1, 2), L = 3) # 'newLam3' is used as the prior for combined data and 'Lambda' is used as # the prior for locals list_newLam3 <- list(Lambda, newLam3) bfi3 <- bfi(theta_hats, A_hats, list_newLam3, family = 'gaussian',             stratified = TRUE, strat_par = 1:2) summary(bfi3, cur_mat = TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>                  Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)_loc1   0.7075  0.2130  0.2899   1.1250 #> (Intercept)_loc2   0.9413  0.1596  0.6284   1.2542 #> (Intercept)_loc3   0.8819  0.1533  0.5814   1.1824 #> X1                 0.9482  0.1018  0.7486   1.1478 #> X2                -0.0140  0.0941 -0.1985   0.1704 #> X3                 0.0275  0.0992 -0.1669   0.2218 #> sigma2_loc1        1.3558  0.1285  1.1038   1.6077 #> sigma2_loc2        1.0351  0.1115  0.8166   1.2536 #> sigma2_loc3        1.1728  0.0998  0.9773   1.3683 #>  #> Minus the Curvature Matrix:  #>  #>                  (Intercept)_loc1 (Intercept)_loc2 (Intercept)_loc3      X1 #> (Intercept)_loc1          22.1366           0.0000           0.0000  3.3627 #> (Intercept)_loc2           0.0000          38.6215           0.0000 -7.1785 #> (Intercept)_loc3           0.0000           0.0000          42.6288  2.2058 #> X1                         3.3627          -7.1785           2.2058 98.8284 #> X2                         1.1877           9.8374           6.4452  7.0582 #> X3                        -1.3802         -13.1667           0.7467 -2.9109 #> sigma2_loc1               -0.0723           0.0000           0.0000  1.1877 #> sigma2_loc2                0.0000          -0.0929           0.0000  9.8374 #> sigma2_loc3                0.0000           0.0000          -0.0880  6.4452 #>                        X2       X3 sigma2_loc1 sigma2_loc2 sigma2_loc3 #> (Intercept)_loc1  -1.3802   0.0081     -0.0723      0.0000      0.0000 #> (Intercept)_loc2 -13.1667   0.0027      0.0000     -0.0929      0.0000 #> (Intercept)_loc3   0.7467  -0.0015      0.0000      0.0000     -0.0880 #> X1                 7.0582  -2.9109     -0.0915     -0.0989     -0.0918 #> X2               110.1166  -1.7587      0.0081      0.0027     -0.0015 #> X3                -1.7587 101.9264     -0.0110      0.0018     -0.0029 #> sigma2_loc1       -0.0915  -0.0110     60.5223      0.0000      0.0000 #> sigma2_loc2       -0.0989   0.0018      0.0000     80.4576      0.0000 #> sigma2_loc3       -0.0918  -0.0029      0.0000      0.0000    100.4852  ###----------------------------### ### Center Specific Covariates ### ###----------------------------###  # Assume the first and third centers have the same center-specific covariate value # of 'High', while this value for the second center is 'Low', i.e., # center_spec = c('High','Low','High') newLam4 <- inv.prior.cov(X1, lambda=c(0.1, 0.2, 0.3), family='gaussian',                          stratified = TRUE, center_spec = c('High','Low','High'), L = 3) # 'newLam4' is used as the prior for combined data and 'Lambda' is used as # the prior for locals l_newLam4 <- list(Lambda, newLam4) bfi4 <- bfi(theta_hats, A_hats, l_newLam4, family = 'gaussian',             stratified = TRUE, center_spec = c('High','Low','High')) summary(bfi4, cur_mat = TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>                  Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)_High   0.8233  0.1251  0.5781   1.0686 #> (Intercept)_Low    0.9412  0.1681  0.6117   1.2706 #> X1                 0.9454  0.1020  0.7455   1.1454 #> X2                -0.0116  0.0971 -0.2020   0.1788 #> X3                 0.0294  0.1015 -0.1695   0.2283 #>  #> Dispersion parameter (sigma2):  1.176  #>  #> Minus the Curvature Matrix:  #>  #>                  (Intercept)_High (Intercept)_Low      X1       X2       X3 #> (Intercept)_High          64.6654          0.0000  5.5685   7.6329  -0.6335 #> (Intercept)_Low            0.0000         38.6215 -7.1785   9.8374 -13.1667 #> X1                         5.5685         -7.1785 98.8284   7.0582  -2.9109 #> X2                         7.6329          9.8374  7.0582 110.1166  -1.7587 #> X3                        -0.6335        -13.1667 -2.9109  -1.7587 101.9264 #> sigma2                    -0.1603         -0.0929 -0.2822   0.0094  -0.0120 #>                    sigma2 #> (Intercept)_High  -0.1603 #> (Intercept)_Low   -0.0929 #> X1                -0.2822 #> X2                 0.0094 #> X3                -0.0120 #> sigma2           240.8651   ###---------------------### ###  Treatment Effect   ### ###---------------------###  #-----------------------------# # New Data for Local Center 1 # #-----------------------------# # Generating new data with 'treatment' variable # We cansider the first variable (X1$X1) to be the treatment X1$X1 <- sample(0:1, n1, replace=TRUE) # categorical variable #X1$X1 <- as.factor(X1$X1)  # linear predictor: #X1x2_2 <- ifelse(X1$treatment == '2', 1, 0) #eta1   <- beta[1] + X1$x1 * beta[2] + X1x2_2 * beta[3] eta1 <- theta[1] + as.matrix(X1)  mu1    <- gaussian()$linkinv(eta1) y1     <- rnorm(n1, mu1, sd = sqrt(theta[5]))  #-----------------------------# # New Data for Local Center 2 # #-----------------------------# # We cansider the first variable (X2$X1) to be the treatment! X2$X1 <- sample(0:1, n2, replace=TRUE) # categorical variable # linear predictor: eta2 <- theta[1] + as.matrix(X2)  # inverse of the link function: mu2  <- gaussian()$linkinv(eta2) y2   <- rnorm(n2, mu2, sd = sqrt(theta[5]))  #-----------------------------# # New Data for Local Center 3 # #-----------------------------# # We cansider the first variable (X3$X1) to be the treatment! X3$X1 <- sample(0:1, n3, replace=TRUE) # categorical variable # linear predictor: eta3 <- theta[1] + as.matrix(X3)  # inverse of the link function: mu3  <- gaussian()$linkinv(eta3) y3   <- rnorm(n3, mu3, sd = sqrt(theta[5]))  #-------------# # First Round # #-------------#  ## Center 1: Lambda1 <- inv.prior.cov(X1, lambda = 0.01, family = 'binomial', # same results with 'gaussian'                          treatment = \"X1\", treat_round=\"first\") # When treat_round = \"first\", the family will automatically set to 'binomial', # even if family = 'gaussian' or family = 'survival'. fit1_r1 <- MAP.estimation(y1, X1, family = 'gaussian', # same results with 'binomial'                           Lambda = Lambda1, treatment = \"X1\", treat_round = \"first\") # The output without the threatment (X1) in the first round! summary(fit1_r1) #>  #> Summary of the local model: #>  #>    Formula: y ~ X2 + X3  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.0223  0.3766 -0.7158   0.7603 #> X2            0.2602  0.4041 -0.5318   1.0522 #> X3            0.4581  0.4304 -0.3854   1.3016 #>  #> Dispersion parameter (sigma2):  1  #>             log Lik Posterior:  -20.02  #>                   Convergence:  0   ## Center 2: Lambda2 <- inv.prior.cov(X2, lambda = 0.01, family = 'gaussian',                          treatment = \"X1\", treat_round=\"first\") fit2_r1 <- MAP.estimation(y2, X2, family = 'gaussian', Lambda = Lambda2,                           treatment = \"X1\", treat_round = \"first\") fit2_r1 #> $theta_hat #> (Intercept)          X2          X3  #> -0.52120058  0.29742357 -0.08886829  #>  #> $A_hat #>             (Intercept)        X2        X3 #> (Intercept)    9.354493  2.945393 -3.248575 #> X2             2.945393 11.750351 -1.184030 #> X3            -3.248575 -1.184030  9.977399 #>  #> $sd #> (Intercept)          X2          X3  #>   0.3596205   0.3040087   0.3362061  #>  #> $Lambda #>             (Intercept)   X2   X3 #> (Intercept)        0.01 0.00 0.00 #> X2                 0.00 0.01 0.00 #> X3                 0.00 0.00 0.01 #>  #> $formula #> [1] y ~ X2 + X3 #>  #> $names #> [1] \"(Intercept)\" \"X2\"          \"X3\"          #>  #> $n #> [1] 40 #>  #> $np #> [1] 3 #>  #> $treatment #> [1] \"X1\" #>  #> $refer_treat #> NULL #>  #> $gamma_bfi #> NULL #>  #> $RCT_propens #> NULL #>  #> $propensity #> NULL #>  #> $for_ATE #> NULL #>  #> $zero_sample_cov #> NULL #>  #> $refer_cat #> NULL #>  #> $zero_cat #> NULL #>  #> $value #> [1] 26.38388 #>  #> $family #> [1] \"binomial\" #>  #> $basehaz #> NULL #>  #> $intercept #> [1] TRUE #>  #> $convergence #> [1] 0 #>  #> $control #> $control$maxit #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"bfi\"  ## Centeral Server: theta_hats_r1 <- list(fit1_r1$theta_hat, fit2_r1$theta_hat) A_hats_r1 <- list(fit1_r1$A_hat, fit2_r1$A_hat) fitbfi_r1 <- bfi(theta_hats_r1, A_hats_r1, Lambda1, family = 'gaussian',                  treat_round = \"first\") # same results with 'binomial' # The output without the threatment (X1) in the first round! summary(fitbfi_r1, cur_mat = TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘binomial’  #>       Link: ‘Logit’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)  -0.2424  0.2574 -0.7470   0.2622 #> X2            0.2451  0.2406 -0.2265   0.7168 #> X3            0.1488  0.2626 -0.3659   0.6635 #>  #> Dispersion parameter (sigma2):  1  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      X2      X3 #> (Intercept)     16.4799  3.1477 -3.9190 #> X2               3.1477 17.9615 -1.9104 #> X3              -3.9190 -1.9104 15.5098  #--------------# # Second Round # #--------------#  ## Center 1: Lambda11 <- inv.prior.cov(X1, lambda = 0.01, family = 'gaussian', treatment = \"X1\",                           treat_round=\"second\") fit1_r2 <- MAP.estimation(y1, X1, family = 'gaussian', Lambda = Lambda11,                           treatment = \"X1\", treat_round = \"second\",                           gamma_bfi = fitbfi_r1$theta_hat) # The output with only the threatment (X1) in the second round! summary(fit1_r2) #>  #> Summary of the local model: #>  #>    Formula: y ~ X2 + X3  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   1.0285  0.3868  0.2704   1.7865 #> X1            1.2372  0.5159  0.2261   2.2484 #>  #> Dispersion parameter (sigma2):  3.969  #>             log Lik Posterior:  -71.46  #>                   Convergence:  0   ## Center 2: Lambda22 <- inv.prior.cov(X2, lambda = 0.01, family = 'gaussian', treatment = \"X1\",                           treat_round=\"second\") fit2_r2 <- MAP.estimation(y2, X2, family = 'gaussian', Lambda = Lambda22,                           treatment = \"X1\", treat_round = \"second\",                           gamma_bfi = fitbfi_r1$theta_hat) fit2_r2 #> $theta_hat #> (Intercept)          X1      sigma2  #>   1.1927959   0.7520922   3.5989485  #>  #> $A_hat #>             (Intercept)          X1      sigma2 #> (Intercept) 22.14307019 10.10269136 -0.02386092 #> X1          10.10269136 10.11269136 -0.01503365 #> sigma2      -0.02386092 -0.01503365 80.14388436 #>  #> $sd #> (Intercept)          X1      sigma2  #>   0.2880712   0.4262706   0.1117030  #>  #> $Lambda #>             (Intercept)   X1 sigma2 #> (Intercept)        0.01 0.00   0.00 #> X1                 0.00 0.01   0.00 #> sigma2             0.00 0.00   0.01 #>  #> $formula #> [1] y ~ X2 + X3 #>  #> $names #> [1] \"(Intercept)\" \"X1\"          \"sigma2\"      #>  #> $n #> [1] 40 #>  #> $np #> [1] 2 #>  #> $treatment #> [1] \"X1\" #>  #> $refer_treat #> [1] \"0\" #>  #> $gamma_bfi #>   (Intercept)      X2        X3 #> 1  -0.2424109 0.24512 0.1487866 #>  #> $RCT_propens #> NULL #>  #> $propensity #>  [1] 0.4228957 0.2872530 0.5435048 0.6162998 0.4389738 0.4533253 0.5423924 #>  [8] 0.4295079 0.3948974 0.5279462 0.3830530 0.3982273 0.3216490 0.4675986 #> [15] 0.5106539 0.3565694 0.3786060 0.4616242 0.4758353 0.4287259 0.4189701 #> [22] 0.4281438 0.3818497 0.5980655 0.5318969 0.3729389 0.4134376 0.4051359 #> [29] 0.4820874 0.3853137 0.4671696 0.4610488 0.5546443 0.4229997 0.4534592 #> [36] 0.5209616 0.4055026 0.3859785 0.3263390 0.4925895 #>  #> $for_ATE #> [1] 16.00000 24.00000 31.18591 90.44691 36.35907 70.74137 43.29671 51.66003 #> [9] 28.72066 #>  #> $zero_sample_cov #> NULL #>  #> $refer_cat #> NULL #>  #> $zero_cat #> NULL #>  #> $value #> [1] 91.3175 #>  #> $family #> [1] \"gaussian\" #>  #> $basehaz #> NULL #>  #> $intercept #> [1] TRUE #>  #> $convergence #> [1] 0 #>  #> $control #> $control$maxit #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"bfi\"  ## Centeral Server: theta_hats_r2 <- list(fit1_r2$theta_hat, fit2_r2$theta_hat) A_hats_r2 <- list(fit1_r2$A_hat, fit2_r2$A_hat) for_ATEs <- list(fit1_r2$for_ATE, fit2_r2$for_ATE) fitbfi_r2 <- bfi(theta_hats_r2, A_hats_r2, Lambda11, family = 'gaussian',                  treat_round = \"second\", for_ATE = for_ATEs) fitbfi_r2$ATE #> $IPTW #> [1] 0.9823843 #>  #> $wIPTW #> [1] 0.9702013 #>  fitbfi_r2$S_var #> $treatment #> [1] 1.935765 #>  #> $control #> [1] 2.289511 #>  summary(fitbfi_r2) #>  #> Summary of the BFI model: #>  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   1.1344  0.2312  0.6813   1.5874 #> X1            0.9579  0.3271  0.3169   1.5990 #>  #> Dispersion parameter (sigma2):  3.758  #>  #> Average Treatment Effect (ATE):   #>  #>          IPTW:  0.9824  #>         wIPTW:  0.9702  #>  #> Sample Variance:   #>  #>     Treatment:  1.936  #>       Control:  2.29    #################################################### ##  Example 3:  Survival family  (L = 2 centers)  ## ####################################################  # Setting a seed for reproducibility set.seed(112358)  p <- 3 theta <- c(1:4, 5, 6)  # regression coefficients (1:4) & omega's (5:6)  #---------------------------------------------# # Simulating Survival data for Local Center 1 # #---------------------------------------------# n1 <- 30 X1 <- data.frame(matrix(rnorm(n1 * p), n1, p)) # continuous (normal) variables # Simulating survival data ('time' and 'status') from 'Weibull' with # a predefined censoring rate of 0.3: y1 <- surv.simulate(Z = list(X1), beta = theta[1:p], a = theta[5], b = theta[6],                    u1 = 0.1, cen_rate = 0.3, gen_data_from = \"weibul\")$D[[1]][, 1:2] Lambda <- inv.prior.cov(X1, lambda = c(0.1, 1), family = \"survival\", basehaz =\"poly\") fit1 <- MAP.estimation(y1, X1, family = 'survival', Lambda = Lambda, basehaz = \"poly\") theta_hat1 <- fit1$theta_hat  # coefficient estimates A_hat1     <- fit1$A_hat      # minus the curvature matrix summary(fit1, cur_mat=TRUE) #>  #> Summary of the local model: #>  #>    Formula: Survival(time, status) ~ X1 + X2 + X3  #>     Family: ‘survival’  #>   Baseline: ‘poly’ #>  #> Coefficients: #>  #>         Estimate Std.Dev CI 2.5% CI 97.5% #> X1        0.6589  0.2443  0.1801   1.1378 #> X2        0.8425  0.2128  0.4255   1.2595 #> X3        1.4327  0.2359  0.9704   1.8951 #> omega_0  -1.5158  0.2166 -1.9403  -1.0913 #> omega_1   1.8742  0.3310  1.2255   2.5228 #> omega_2   1.7874  0.5340  0.7408   2.8340 #>  #> log Lik Posterior:  -1.275  #>       Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>              X1      X2      X3 omega_0 omega_1 omega_2 #> X1      19.9169 -7.9165 -1.8776  2.0008  0.4276 -0.1580 #> X2      -7.9165 26.1009  1.3864  4.1509  0.4604  0.3718 #> X3      -1.8776  1.3864 23.3546  3.4463 -3.3272 -4.4365 #> omega_0  2.0008  4.1509  3.4463 33.5158  9.5086  7.3123 #> omega_1  0.4276  0.4604 -3.3272  9.5086 15.3123  6.5539 #> omega_2 -0.1580  0.3718 -4.4365  7.3123  6.5539  7.3698 fit1$theta_A_poly # Only when family = \"survival\" and basehaz =\"poly\" #> , , 1 #>  #>         [,1] [,2]       [,3] [,4] [,5] [,6] #> X1        NA   NA  0.6589476   NA   NA   NA #> X2        NA   NA  0.8424763   NA   NA   NA #> X3        NA   NA  1.4327460   NA   NA   NA #> omega_0   NA   NA -1.5157831   NA   NA   NA #> omega_1   NA   NA  1.8741816   NA   NA   NA #> omega_2   NA   NA  1.7874313   NA   NA   NA #>  #> , , 2 #>  #>         [,1] [,2] [,3] [,4] [,5] [,6] #> X1        NA   NA   NA   NA   NA   NA #> X2        NA   NA   NA   NA   NA   NA #> X3        NA   NA   NA   NA   NA   NA #> omega_0   NA   NA   NA   NA   NA   NA #> omega_1   NA   NA   NA   NA   NA   NA #> omega_2   NA   NA   NA   NA   NA   NA #>  #> , , 3 #>  #>         [,1] [,2] [,3] [,4] [,5] [,6] #> X1        NA   NA   NA   NA   NA   NA #> X2        NA   NA   NA   NA   NA   NA #> X3        NA   NA   NA   NA   NA   NA #> omega_0   NA   NA   NA   NA   NA   NA #> omega_1   NA   NA   NA   NA   NA   NA #> omega_2   NA   NA   NA   NA   NA   NA #>  #> , , 4 #>  #>               [,1]       [,2]      [,3]      [,4]       [,5]       [,6] #> X1      19.9168965 -7.9165022 -1.877557  2.000794  0.4276326 -0.1580233 #> X2      -7.9165022 26.1009020  1.386382  4.150947  0.4603776  0.3717607 #> X3      -1.8775567  1.3863818 23.354639  3.446257 -3.3271931 -4.4364945 #> omega_0  2.0007944  4.1509475  3.446257 33.515762  9.5086145  7.3122662 #> omega_1  0.4276326  0.4603776 -3.327193  9.508614 15.3122662  6.5539443 #> omega_2 -0.1580233  0.3717607 -4.436494  7.312266  6.5539443  7.3698101 #>   #---------------------------------------------# # Simulating Survival data for Local Center 2 # #---------------------------------------------# n2 <- 30 X2 <- data.frame(matrix(rnorm(n2 * p), n2, p)) # continuous (normal) variables # Survival simulated data from 'Weibull' with a predefined censoring rate of 0.3: y2 <- surv.simulate(Z = list(X2), beta = theta[1:p], a = theta[5], b = theta[6], u1 = 0.1,                     cen_rate = 0.3, gen_data_from = \"weibul\")$D[[1]][, 1:2] fit2 <- MAP.estimation(y2, X2, family = 'survival', Lambda = Lambda, basehaz = \"poly\") theta_hat2 <- fit2$theta_hat A_hat2 <- fit2$A_hat summary(fit2, cur_mat=TRUE) #>  #> Summary of the local model: #>  #>    Formula: Survival(time, status) ~ X1 + X2 + X3  #>     Family: ‘survival’  #>   Baseline: ‘poly’ #>  #> Coefficients: #>  #>         Estimate Std.Dev CI 2.5% CI 97.5% #> X1        0.5961  0.2320  0.1414   1.0509 #> X2        0.4218  0.1837  0.0618   0.7817 #> X3        1.2563  0.2362  0.7934   1.7192 #> omega_0  -1.0431  0.2075 -1.4497  -0.6365 #> omega_1   2.0875  0.3292  1.4422   2.7328 #> omega_2  -0.1028  0.2806 -0.6528   0.4473 #>  #> log Lik Posterior:  -6.197  #>       Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>              X1      X2      X3 omega_0 omega_1 omega_2 #> X1      20.3039  1.7314  2.0927  0.5517 -3.0791 -6.2397 #> X2       1.7314 31.2288  4.3588  1.2219 -3.6742 -4.7424 #> X3       2.0927  4.3588 24.5192  7.9651 -2.9422 -8.3513 #> omega_0  0.5517  1.2219  7.9651 33.0430  8.5748  8.9323 #> omega_1 -3.0791 -3.6742 -2.9422  8.5748 16.9323 13.7961 #> omega_2 -6.2397 -4.7424 -8.3513  8.9323 13.7961 26.8460  #-----------------------# # BFI at Central Server # #-----------------------# # When family = 'survival' and basehaz = \"poly\", only 'theta_A_polys' # should be defined instead of 'theta_hats' and 'A_hats': theta_A_hats <- list(fit1$theta_A_poly, fit2$theta_A_poly) qls <- c(fit1$q_l, fit2$q_l) bfi <- bfi(Lambda = Lambda, family = 'survival', theta_A_polys = theta_A_hats,            basehaz = \"poly\", q_ls = qls) summary(bfi, cur_mat=TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘survival’  #>   Baseline: ‘poly’ #>  #> Coefficients: #>  #>         Estimate Std.Dev CI 2.5% CI 97.5% #> X1        0.6009  0.1647  0.2781   0.9237 #> X2        0.6306  0.1361  0.3638   0.8974 #> X3        1.2684  0.1645  0.9460   1.5908 #> omega_0  -1.2108  0.1483 -1.5015  -0.9201 #> omega_1   2.2308  0.2386  1.7632   2.6985 #> omega_2   0.1755  0.2470 -0.3087   0.6597 #>  #> Minus the Curvature Matrix:  #>  #>              X1      X2       X3 omega_0 omega_1  omega_2 #> X1      40.1208 -6.1851   0.2152  2.5525 -2.6515  -6.3977 #> X2      -6.1851 57.2297   5.7451  5.3728 -3.2138  -4.3706 #> X3       0.2152  5.7451  47.7738 11.4113 -6.2694 -12.7878 #> omega_0  2.5525  5.3728  11.4113 65.5588 18.0834  16.2445 #> omega_1 -2.6515 -3.2138  -6.2694 18.0834 31.2445  20.3501 #> omega_2 -6.3977 -4.3706 -12.7878 16.2445 20.3501  33.2158   ###---------------------### ### Stratified Analysis ### ###---------------------###  # Stratified analysis when first parameter ('omega_0') varies across two centers: (newLam0 <- inv.prior.cov(X1, lambda = c(rep(1, 3), 0.3, 0.7, rep(2,2)),                           family = 'survival', stratified = TRUE,                           basehaz = c(\"poly\"), strat_par = 1, L = 2)) #>              X1 X2 X3 omega_0_loc1 omega_0_loc2 omega_1 omega_2 #> X1            1  0  0          0.0          0.0       0       0 #> X2            0  1  0          0.0          0.0       0       0 #> X3            0  0  1          0.0          0.0       0       0 #> omega_0_loc1  0  0  0          0.3          0.0       0       0 #> omega_0_loc2  0  0  0          0.0          0.7       0       0 #> omega_1       0  0  0          0.0          0.0       2       0 #> omega_2       0  0  0          0.0          0.0       0       2 # 'newLam0' is used as the prior for combined data and 'Lambda' is used as for locals: list_newLam0 <- list(Lambda, newLam0) bfi0 <- bfi(Lambda = list_newLam0, family = 'survival', theta_A_polys = theta_A_hats,             stratified = TRUE, basehaz = c(\"poly\"), p = 3, q_ls = qls, strat_par = 1) summary(bfi0, cur_mat = TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘survival’  #>   Baseline: ‘poly’ #>  #> Coefficients: #>  #>              Estimate Std.Dev CI 2.5% CI 97.5% #> X1             0.5812  0.1625  0.2627   0.8996 #> X2             0.6168  0.1351  0.3520   0.8816 #> X3             1.2269  0.1628  0.9078   1.5460 #> omega_0_loc1  -1.2097  0.1904 -1.5829  -0.8365 #> omega_0_loc2  -1.1427  0.1958 -1.5264  -0.7590 #> omega_1        2.1174  0.2307  1.6652   2.5696 #> omega_2        0.1988  0.2386 -0.2687   0.6664 #>  #> Minus the Curvature Matrix:  #>  #>                   X1      X2       X3 omega_0_loc1 omega_0_loc2 omega_1 #> X1           41.0208 -6.1851   0.2152       2.0008       0.5517 -2.6515 #> X2           -6.1851 58.1297   5.7451       4.1509       1.2219 -3.2138 #> X3            0.2152  5.7451  48.6738       3.4463       7.9651 -6.2694 #> omega_0_loc1  2.0008  4.1509   3.4463      32.8158       0.0000  9.5086 #> omega_0_loc2  0.5517  1.2219   7.9651       0.0000      32.7430  8.5748 #> omega_1      -2.6515 -3.2138  -6.2694       9.5086       8.5748 32.2445 #> omega_2      -6.3977 -4.3706 -12.7878       7.3123       8.9323 20.3501 #>               omega_2 #> X1            -6.3977 #> X2            -4.3706 #> X3           -12.7878 #> omega_0_loc1   7.3123 #> omega_0_loc2   8.9323 #> omega_1       20.3501 #> omega_2       34.2158   # Stratified analysis when the first and second parameters ('omega_0' and 'omega_1') # vary across two centers: newLam1 <- inv.prior.cov(X1, lambda = c(rep(1, 3), 0.3, 0.7, 0.5, 0.8, 2),                          family = 'survival', stratified = TRUE, basehaz = c(\"poly\"),                          strat_par = c(1, 2), L = 2) # 'newLam1' is used as the prior for combined data: list_newLam1 <- list(Lambda, newLam1) bfi1 <- bfi(Lambda = list_newLam1, family = 'survival', theta_A_polys = theta_A_hats,             stratified = TRUE, basehaz = c(\"poly\"), p = 3, q_ls = qls, strat_par = c(1, 2)) summary(bfi1, cur_mat = TRUE) #>  #> Summary of the BFI model: #>  #>     Family: ‘survival’  #>   Baseline: ‘poly’ #>  #> Coefficients: #>  #>              Estimate Std.Dev CI 2.5% CI 97.5% #> X1             0.5704  0.1594  0.2579   0.8829 #> X2             0.6066  0.1307  0.3505   0.8627 #> X3             1.2503  0.1471  0.9620   1.5386 #> omega_0_loc1  -1.3203  0.1855 -1.6839  -0.9567 #> omega_0_loc2  -1.1006  0.1792 -1.4518  -0.7493 #> omega_1_loc1   2.4654  0.3023  1.8729   3.0579 #> omega_1_loc2   1.8937  0.3117  1.2828   2.5045 #> omega_2        0.2404  0.2224 -0.1955   0.6764 #>  #> Minus the Curvature Matrix:  #>  #>                   X1      X2       X3 omega_0_loc1 omega_0_loc2 omega_1_loc1 #> X1           41.0208 -6.1851   0.2152       2.0008       0.5517       0.4276 #> X2           -6.1851 58.1297   5.7451       4.1509       1.2219       0.4604 #> X3            0.2152  5.7451  48.6738       3.4463       7.9651      -3.3272 #> omega_0_loc1  2.0008  3.4463   0.4276      32.8158       0.0000       9.5086 #> omega_0_loc2  0.5517  7.9651  -3.0791       0.0000      32.7430       0.0000 #> omega_1_loc1  4.1509  7.3123   0.4604       9.5086       0.0000      14.8123 #> omega_1_loc2  1.2219  8.9323  -3.6742       0.0000       8.5748       0.0000 #> omega_2      -6.3977 -4.3706 -12.7878       7.3123       8.9323       6.5539 #>              omega_1_loc2  omega_2 #> X1                -3.0791  -6.3977 #> X2                -3.6742  -4.3706 #> X3                -2.9422 -12.7878 #> omega_0_loc1       0.0000  -3.3272 #> omega_0_loc2       8.5748  -2.9422 #> omega_1_loc1       0.0000   6.5539 #> omega_1_loc2      16.7323  13.7961 #> omega_2           13.7961  34.2158   ###---------------------### ###  Treatment Effect   ### ###---------------------###  set.seed(112358)  #------------------------------------# # Data Simulation for Local Center 1 # #------------------------------------#"},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum A Posteriori estimation — MAP.estimation","title":"Maximum A Posteriori estimation — MAP.estimation","text":"MAP.estimation function used (local centers) compute Maximum Posterior (MAP) estimators parameters Generalized Linear Models (GLM) Survival models.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum A Posteriori estimation — MAP.estimation","text":"","code":"MAP.estimation(y,                X,                family = c(\"gaussian\", \"binomial\", \"survival\"),                Lambda,                intercept = TRUE,                basehaz = c(\"weibul\", \"exp\", \"gomp\", \"poly\", \"pwexp\", \"unspecified\"),                treatment = NULL,                treat_round = NULL,                refer_treat,                gamma_bfi = NULL,                RCT_propens = NULL,                initial = NULL,                alpha = 0.1,                max_order = 2,                n_intervals = 4,                min_max_times,                center_zero_sample = FALSE,                zero_sample_cov,                refer_cat,                zero_cat,                control = list())"},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum A Posteriori estimation — MAP.estimation","text":"y response vector. “binomial” family used, argument vector entries 0 (failure) 1 (success). Alternatively, family, response can matrix first column number “successes” second column number “failures”. “survival” family, response matrix first column survival time, named “time”, second column censoring indicator, named “status”, 0 indicating censoring time 1 indicating event time. X design matrix dimension \\(n_{\\ell} \\times p\\), \\(p\\) number covariates predictors \\(n_{\\ell}\\) number indeviduals local center. categorical covariate, function factor() used encode covariate factor. Note order covariates must across centers; otherwise, output estimates bfi() incorrect. family description error distribution. character string naming family model. current version package, family model can “gaussian” (identity link function), dQuotebinomial (logit link function), “survival”. Can abbreviated. default “gaussian” family used. case linear regression model, family = \"gaussian\", extra model parameter variance measurement error. case survival model, family = \"survival\", number model parameters depend choice baseline hazard functions, see ‘Details’ information. Lambda inverse variance-covariance matrix Gaussian distribution used prior distribution model parameters. dimension matrix depends number columns X, type covariates (continuous / dichotomous categorical), family, whether intercept included (applicable). However, Lambda can easily created inv.prior.cov(). See inv.prior.cov information. intercept logical flag fitting intercept. intercept=TRUE (default), intercept fitted, .e., included model, intercept = FALSE set zero, .e., model. argument used family = \"survival\". basehaz character string representing one available baseline hazard functions; exponential (“exp”), Weibull (“weibul”, default), Gompertz (“gomp”), exponentiated polynomial (“poly”), piecewise constant exponential (“pwexp”), unspecified baseline hazard (“unspecified”). Can abbreviated. used family = \"survival\". local sample size large shape baseline hazard function completely unknown, “exponentiated polynomial” “piecewise exponential” hazard functions preferred lower dimensional alternatives. However, local samples size low, one careful using “piecewise exponential” hazard function many intervals. basehaz = \"unspecified\", means (semi-parametric) Cox model considered, parameters (regression coefficients) estimated using partial log-likelihood. treatment NULL, basehaz must set \"unspecified\", regression coefficients estimated using weighted partial log-likelihood. treatment character string representing name place binary covariate, respectively. covariate indicates whether patient got new treatment (\\(z_{\\ell }=1\\)) placebo/standard treatment (\\(z_{\\ell }=0\\)). treatment effect estimated argument 'NULL'. set 'NULL' (default), treatment effect estimated. first second rounds, 'NULL'. See ‘Details’. treat_round character string representing 'first' 'second' round estimating treatment effects. first round, treat_round = 'first', local estimates coefficients (\\(\\gamma_{\\ell}\\)) estimated. second round, treat_round = 'second', propensity scores statistical summaries (for_ATE) calculated sent central server estimating average treatment effects. refer_treat character string representing reference category treatment variable. reference category considered \\(z_{\\ell }=0\\). argument used treatment 'NULL'. Default refer_treat = levels(X$treatment)[1]. gamma_bfi vector specifying BFI estimates coefficients received central server first round. length gamma_bfi equals number regression coefficients, including intercept intercept=TRUE, excluding \\(\\zeta\\), represents treatment effect, well nuisance parameter \\(\\sigma\\) gaussian family parameters baseline hazard (\\(\\boldsymbol{\\omega}\\)) survival. argument used argument treatment 'NULL'. treatment 'NULL' gamma_bfi = NULL, argument RCT_propens must 'NULL', indicating RCT study. See ‘Details’. RCT_propens vector specifying propensity scores, represent probability receiving treatment given covariates, known randomized studies (RCTs). example, 1:1 randomized trial, propensity scores , definition, equal 1/2 (0.5), whereas unbalanced randomized trial, e.g., 2:1 trial, propensity scores now 2/3 1/3 two arms, respectively. length RCT_propens equals number individuals local center denoted \\(n_{\\ell}\\). argument used study randomized control trial, .e., propensity scores known local center. case, ‘one’ round, argument treatment must 'NULL', whereas gamma_bfi = NULL. Indeed, 'treatment' 'NULL', one arguments 'RCT_propens' 'gamma_bfi' 'NULL'. See ‘Details’. initial vector specifying initial values parameters optimized . length initial equal number model parameters thus, equal number rows columns Lambda. Since 'L-BFGS-B' method used algorithm, values always finite. Default vector zeros, except survival family poly function, vector first \\(p\\) elements zeros coefficients (\\(\\boldsymbol{\\beta}\\)) -0.5 remaining parameters (\\(\\boldsymbol{\\omega}\\)). gaussian family, last element initial vector also considered negative, Gaussian prior applied \\(log(\\sigma^2)\\). alpha significance level used chi-squared distribution (one degree freedom 1-\\(\\alpha\\) representing upper quantile) conduct likelihood ratio test obtaining order exponentiated polynomial baseline hazard function. used family = \"survival\" basehaz = \"poly\". Default 0.1. See ‘Details’. max_order integer representing maximum value q_l, order/degree minus 1 exponentiated polynomial baseline hazard function. argument used family = \"survival\" basehaz = \"poly\". Default 2. n_intervals integer representing number intervals piecewise exponential baseline hazard function. argument used family = \"survival\" basehaz = \"pwexp\". Default 4. min_max_times scalar representing minimum maximum event times observed centers. value argument defined central server (access maximum event times centers) used family = \"survival\" basehaz = \"pwexp\". center_zero_sample logical flag indicating whether center categorical covariate observations/individuals one categories. Default center_zero_sample = FALSE. zero_sample_cov either character string integer representing categorical covariate samples/observations one categories. covariate least two categories, one reference. used center_zero_sample = TRUE. refer_cat character string representing reference category. category observations (argument zero_cat) used reference argument refer_cat. used center_zero_sample = TRUE. zero_cat character string representing category samples/observations. used center_zero_sample = TRUE. control list control parameters. See ‘Details’.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum A Posteriori estimation — MAP.estimation","text":"MAP.estimation returns list containing following components: theta_hat vector corresponding maximum posteriori (MAP) estimates parameters. gaussian family, last element vector \\(\\sigma^2\\); A_hat minus curvature (Hessian) matrix around point theta_hat. dimension matrix argument Lambda; sd vector (posterior) standard deviation MAP estimates theta_hat, sqrt(diag(solve(A_hat))); Lambda inverse variance-covariance matrix Gaussian distribution used prior distribution parameters. exactly argument Lambda; formula formula applied; names names model parameters; n sample size, \\(n_{\\ell}\\); np number coefficients; q_l order/degree minus 1 exponentiated polynomial baseline hazard function determined current center likelihood ratio test. output argument, q_l, shown family = \"survival\" basehaz = \"poly\", used function bfi(); theta_A_poly array first component matrix columns representing MAP estimates parameters different q_l's, .e., q_l, q_l+1, ..., max_order. components minus curvature matrices different q_l's, .e., q_l, q_l+1, ..., max_order. Therefore, first non-NA curvature matrix equal output argument A_hat. output argument, theta_A_poly, shown family = \"survival\" basehaz = \"poly\", used function bfi(); lev_no_ref_zer vector containing names levels categorical covariate samples/observations one categories. name category samples name reference category excluded vector. argument shown family = \"survival\" basehaz = \"poly\", used function bfi(); treatment character string representing name place binary covariate, respectively. set 'NULL', treatment effect estimated; refer_treat reference category treatment. shown treatment 'NULL', can used function bfi(); gamma_bfi vector specifying BFI estimates coefficients received central server first round. treatment = NULL, gamma_bfi must also 'NULL'; RCT_propens vector specifying propensity scores, represent probability receiving treatment given covariates, known randomized studies (RCTs). treatment = NULL, RCT_propens must also 'NULL'; propensity vector specifying propensity scores (probability patient gets treatment given characteristics measured baseline) calculated \\(Pr(Z_\\ell = 1 | X_\\ell)\\); for_ATE vector used central server calculate average treatment effect (ATE). family binomial gaussian, elements : first \\(m_{\\ell 1}\\), number patients treatment group, \\(n_{\\ell} = m_{\\ell 1} + m_{\\ell 2}\\), second \\(m_{\\ell 2}\\), number patients reference group, \\(m_{\\ell 2} = n_{\\ell} - m_{\\ell 1}\\), third \\(\\sum_{=1}^{n_{\\ell}} z_{\\ell } y_{\\ell }\\), fourth \\(\\sum_{=1}^{n_{\\ell}} (z_{\\ell } y_{\\ell })^{2} \\), fifth \\(\\sum_{=1}^{n_{\\ell}} z_{\\ell } / e_{\\ell }\\), sixth \\(\\sum_{=1}^{n_{\\ell}} z_{\\ell } y_{\\ell } /  e_{\\ell }\\), seventh \\(\\sum_{=1}^{n_{\\ell}} (1 - z_{\\ell }) / (1 - e_{\\ell })\\), eighth \\(\\sum_{=1}^{n_{\\ell}} (1 - z_{\\ell }) y_{\\ell } / (1 - e_{\\ell })\\), ninth \\(\\sum_{=1}^{n_{\\ell}} (1 - z_{\\ell }) y_{\\ell }\\), survival, elements : first \\(\\hat \\zeta_\\ell\\), weighted MAP estimates treatment effect \\( \\zeta_\\ell\\) center \\(\\ell\\), second \\(\\hat{\\bold{}}_\\ell\\), minus curvature (1\\(\\times\\)1)-dimensional matrix estimates (variance) around \\( \\zeta_\\ell\\) center \\(\\ell\\), third standard deviation \\( \\zeta_\\ell\\) center \\(\\ell\\), .e., , sqrt(solve(for_ATE[2])) fourth integer value used encode warnings errors related algorithm used maximaze weighted partial log likelihood; zero_sample_cov categorical covariate samples/observations one categories. shown center_zero_sample = TRUE, can used function bfi(); refer_cat reference category. shown center_zero_sample = TRUE, can used function bfi(); zero_cat category samples/observations. shown center_zero_sample = TRUE, can used function bfi(); value value minus log-likelihood posterior density evaluated theta_hat; family family used; basehaz baseline hazard function used; intercept logical flag used fit intercept TRUE, set zero FALSE; convergence integer value used encode warnings errors related algorithm used fit model. values returned : 0 algorithm converged, 1 maximum number iterations ('maxit') reached, 2 Warning 'L-BFGS-B' method. See message value; control list control parameters used compute MAP estimates.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maximum A Posteriori estimation — MAP.estimation","text":"MAP.estimation function finds Maximum Posteriori (MAP) estimates model parameters maximizing log-posterior density respect parameters, .e., estimates equal values log-posterior density maximal (posterior mode). words, MAP.estimation() optimizes log-posterior density respect parameter vector obtain MAP estimates. addition model parameters (.e., coefficients (\\(\\boldsymbol{\\beta}\\)) variance error (\\(\\sigma^2_e\\)) gaussian parameters baseline hazard (\\(\\boldsymbol{\\omega}\\)) survival), curvature matrix (Hessian log-posterior) estimated around mode. MAP.estimation function returns object class `bfi`. Therefore, summary() can used object returned MAP.estimation(). case family = \"survival\" basehaz = \"poly\", assume centers \\(q_\\ell\\)'s equal. However, order estimated polynomials may vary across centers center can different number parameters, say \\(q_\\ell\\)+1.  obtaining estimates within local centers (using MAP.estimation()) estimates central server, choose order polynomial approximation combined data maximum orders local polynomial functions, .e., \\(\\max \\{q_1, \\ldots, q_L \\}\\), approximate global baseline hazard (exponentiated polynomial) function accurately. higher-order polynomial approximation can capture complex features details combined data. Using higher-order approximation ensures account higher-order moments features present data maintaining accuracy. result, potential cases stored theta_A_poly argument used bfi() central server. information survival family, refer 'References' section. three arguments treatment, gamma_bfi, RCT_propens related estimation treatment effect. observational non-randomized studies, treatment effect estimated two rounds; first round, \\(\\hat{\\boldsymbol{\\beta}}_{\\ell}\\) (\\(\\hat{\\boldsymbol{\\gamma}}_{\\ell}\\)) estimated locally central server \\(\\hat{\\boldsymbol{\\beta}}_{BFI}\\) (\\(\\hat{\\boldsymbol{\\gamma}}_{BFI}\\)) estimated sent centers second round. first round, argument treatment 'NULL', gamma_bfi = NULL RCT_propens = NULL. Moreover, first round, family must set binomial, handled automatically. second round, propensity scores estimated, summary statistics sent central server estimate average treatment estimate, ATE (case treatment gamma_bfi 'NULL', RCT_propens = NULL). contrast, randomized control trial (RCT), treatment effect can estimated one round propensity scores known (case treatment RCT_propens 'NULL', gamma_bfi = NULL). NOTE: argument gamma_bfi include estimates nuisance parameter \\(\\sigma\\) gaussian family parameters baseline hazard (\\(\\boldsymbol{\\omega}\\)) survival. Check : identical(names(gamma_bfi), X[, -(colnames(X) == treatment)]) TRUE. solve unconstrained bound-constrained optimization problems, MAP.estimation function utilizes optimization algorithm called Limited-memory Broyden-Fletcher-Goldfarb-Shanno Bound Constraints (L-BFGS-B), Byrd et. al. (1995). L-BFGS-B algorithm limited-memory “quasi-Newton” method iteratively updates parameter estimates approximating inverse Hessian matrix using gradient information history previous iterations. approach allows algorithm approximate curvature posterior distribution efficiently search optimal solution, makes computationally efficient problems large number variables. default, algorithm uses relative change objective function convergence criterion. change objective function iterations falls certain threshold (`factr`) algorithm considered converged. convergence can checked argument convergence output. See ‘Value’. case convergence issue, may necessary investigate adjust optimization parameters facilitate convergence. can done using initial control arguments. argument initial initial points interative optimization algorithm can changed, argument control list can supply following components: maxit: maximum number iterations. Default 150; factr: controls convergence 'L-BFGS-B' method. Convergence occurs reduction objective within factor machine tolerance. Default factr 1e7, gives tolerance 1e-9. exact tolerance can checked multiplying value .Machine$double.eps; pgtol: helps control convergence 'L-BFGS-B' method. tolerance projected gradient current search direction, .e., iteration stop maximum component projected gradient less equal pgtol, pgtol\\(\\geq 0\\). Default zero, check suppressed; trace: non-negative integer. positive, tracing information progress optimization produced. Higher values may produce tracing information: method 'L-BFGS-B' six levels tracing. understand exactly see source code optim function stats package; REPORT: frequency reports 'L-BFGS-B' method 'control$trace' positive. Default every 10 iterations; lmm: integer giving number BFGS updates retained 'L-BFGS-B' method. Default 5.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Maximum A Posteriori estimation — MAP.estimation","text":"Jonker M.., Pazira H. Coolen .C.C. (2024). Bayesian federated inference estimating statistical models based non-shared multicenter data sets, Statistics Medicine, 43(12): 2421-2438. <https://doi.org/10.1002/sim.10072> Pazira H., Massa E., Weijers J..M., Coolen .C.C. Jonker M.. (2025b). Bayesian Federated Inference Survival Models, Journal Applied Statistics (Accepted). <https://arxiv.org/abs/2404.17464> Jonker M.., Pazira H. Coolen .C.C. (2025a). Bayesian Federated Inference regression models based non-shared medical center data, Research Synthesis Methods, 1-41. <https://doi.org/10.1017/rsm.2025.6> van den Heuvel Z.D., Pazira H. Jonker M.. (2025c). Bayesian Federated Causal Inference observational data, arXiv. <https://arxiv.org/abs/???> Byrd R.H., Lu P., Nocedal J. Zhu C. (1995). limited memory algorithm bound constrained optimization. SIAM Journal Scientific Computing, 16, 1190-1208. <https://doi.org/10.1137/0916069>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Maximum A Posteriori estimation — MAP.estimation","text":"Hassan Pazira Marianne Jonker  Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/MAP.estimation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum A Posteriori estimation — MAP.estimation","text":"","code":"###--------------### ### y ~ Gaussian ### ###--------------###  # Setting a seed for reproducibility set.seed(11235)  # model parameters: coefficients and sigma2 = 1.5 theta <- c(1, 2, 2, 2, 1.5)  #---------------- # Data Simulation #---------------- n   <- 30   # sample size p   <- 3    # number of coefficients without intercept X   <- data.frame(matrix(rnorm(n * p), n, p)) # continuous variables # linear predictor: eta <- theta[1] + theta[2] * X$X1 + theta[3] * X$X2 + theta[4] * X$X3 # inverse of the link function ( g^{-1}(\\eta) = \\mu ): mu  <- gaussian()$linkinv(eta) y   <- rnorm(n, mu, sd = sqrt(theta[5]))  # Load the BFI package library(BFI)  #----------------------------------------------- # MAP estimations for theta and curvature matrix #----------------------------------------------- # MAP estimates with 'intercept' Lambda <- inv.prior.cov(X, lambda = c(0.1, 1), family = \"gaussian\") (fit <- MAP.estimation(y, X, family = \"gaussian\", Lambda)) #> $theta_hat #> (Intercept)          X1          X2          X3      sigma2  #>    1.341258    2.236391    2.071001    2.164002    1.054571  #>  #> $A_hat #>             (Intercept)         X1         X2         X3     sigma2 #> (Intercept)  28.5475747  1.9315730 -7.7385763  6.2804549 -0.2682462 #> X1            1.9315730 20.4369223 -2.2127254  4.5673270 -0.4472059 #> X2           -7.7385763 -2.2127254 49.3206700  3.1359341 -0.4141474 #> X3            6.2804549  4.5673270  3.1359341 24.3657850 -0.4327445 #> sigma2       -0.2682462 -0.4472059 -0.4141474 -0.4327445 64.2183745 #>  #> $sd #> (Intercept)          X1          X2          X3      sigma2  #>   0.1982976   0.2269483   0.1476575   0.2153269   0.1248065  #>  #> $Lambda #>             (Intercept)  X1  X2  X3 sigma2 #> (Intercept)         0.1 0.0 0.0 0.0      0 #> X1                  0.0 0.1 0.0 0.0      0 #> X2                  0.0 0.0 0.1 0.0      0 #> X3                  0.0 0.0 0.0 0.1      0 #> sigma2              0.0 0.0 0.0 0.0      1 #>  #> $formula #> [1] y ~ X1 + X2 + X3 #>  #> $names #> [1] \"(Intercept)\" \"X1\"          \"X2\"          \"X3\"          \"sigma2\"      #>  #> $n #> [1] 30 #>  #> $np #> [1] 4 #>  #> $treatment #> NULL #>  #> $zero_sample_cov #> NULL #>  #> $refer_cat #> NULL #>  #> $zero_cat #> NULL #>  #> $value #> [1] 35.28046 #>  #> $family #> [1] \"gaussian\" #>  #> $basehaz #> [1] \"weibul\"      \"exp\"         \"gomp\"        \"poly\"        \"pwexp\"       #> [6] \"unspecified\" #>  #> $intercept #> [1] TRUE #>  #> $convergence #> [1] 0 #>  #> $control #> $control$maxit #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"bfi\" class(fit) #> [1] \"bfi\" summary(fit, cur_mat = TRUE) #>  #> Summary of the local model: #>  #>    Formula: y ~ X1 + X2 + X3  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   1.3413  0.1983  0.9526   1.7299 #> X1            2.2364  0.2269  1.7916   2.6812 #> X2            2.0710  0.1477  1.7816   2.3604 #> X3            2.1640  0.2153  1.7420   2.5860 #>  #> Dispersion parameter (sigma2):  1.055  #>             log Lik Posterior:  -35.28  #>                   Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      X1      X2      X3  sigma2 #> (Intercept)     28.5476  1.9316 -7.7386  6.2805 -0.2682 #> X1               1.9316 20.4369 -2.2127  4.5673 -0.4472 #> X2              -7.7386 -2.2127 49.3207  3.1359 -0.4141 #> X3               6.2805  4.5673  3.1359 24.3658 -0.4327 #> sigma2          -0.2682 -0.4472 -0.4141 -0.4327 64.2184  # MAP estimates without 'intercept' Lambda <- inv.prior.cov(X, lambda = c(0.1, 1), family = 'gaussian', intercept = FALSE) (fit1 <- MAP.estimation(y, X, family = 'gaussian', Lambda, intercept = FALSE)) #> $theta_hat #>       X1       X2       X3   sigma2  #> 2.241637 1.832740 2.525235 2.496099  #>  #> $A_hat #>                X1         X2         X3     sigma2 #> X1      8.6921038 -0.9348497  1.9296405 -0.4483243 #> X2     -0.9348497 20.8951379  1.3248942 -0.3665339 #> X3      1.9296405  1.3248942 10.3520007 -0.5050368 #> sigma2 -0.4483243 -0.3665339 -0.5050368 69.9843284 #>  #> $sd #>        X1        X2        X3    sigma2  #> 0.3478802 0.2205610 0.3192969 0.1195753  #>  #> $Lambda #>         X1  X2  X3 sigma2 #> X1     0.1 0.0 0.0      0 #> X2     0.0 0.1 0.0      0 #> X3     0.0 0.0 0.1      0 #> sigma2 0.0 0.0 0.0      1 #>  #> $formula #> [1] y ~ X1 + X2 + X3 #>  #> $names #> [1] \"X1\"     \"X2\"     \"X3\"     \"sigma2\" #>  #> $n #> [1] 30 #>  #> $np #> [1] 3 #>  #> $treatment #> NULL #>  #> $zero_sample_cov #> NULL #>  #> $refer_cat #> NULL #>  #> $zero_cat #> NULL #>  #> $value #> [1] 63.9101 #>  #> $family #> [1] \"gaussian\" #>  #> $basehaz #> [1] \"weibul\"      \"exp\"         \"gomp\"        \"poly\"        \"pwexp\"       #> [6] \"unspecified\" #>  #> $intercept #> [1] FALSE #>  #> $convergence #> [1] 0 #>  #> $control #> $control$maxit #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"bfi\" summary(fit1, cur_mat = TRUE) #>  #> Summary of the local model: #>  #>    Formula: y ~ X1 + X2 + X3  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>    Estimate Std.Dev CI 2.5% CI 97.5% #> X1   2.2416  0.3479  1.5598   2.9235 #> X2   1.8327  0.2206  1.4004   2.2650 #> X3   2.5252  0.3193  1.8994   3.1510 #>  #> Dispersion parameter (sigma2):  2.496  #>             log Lik Posterior:  -63.91  #>                   Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>             X1      X2      X3  sigma2 #> X1      8.6921 -0.9348  1.9296 -0.4483 #> X2     -0.9348 20.8951  1.3249 -0.3665 #> X3      1.9296  1.3249 10.3520 -0.5050 #> sigma2 -0.4483 -0.3665 -0.5050 69.9843    ###-----------------### ### Survival family ### ###-----------------###  # Setting a seed for reproducibility set.seed(112358)  #------------------------- # Simulating Survival data #------------------------- n    <- 100 beta <- 1:4 p    <- length(beta) X    <- data.frame(matrix(rnorm(n * p), n, p)) # continuous (normal) variables  ## Simulating survival data from Weibull with a predefined censoring rate of 0.3 y <- surv.simulate(Z = list(X), beta = beta, a = 5, b = exp(1.8), u1 = 0.1,                    cen_rate = 0.3, gen_data_from = \"weibul\")$D[[1]][, 1:2]  #--------------------------------------- # MAP estimations with \"weibul\" function #--------------------------------------- Lambda <- inv.prior.cov(X, lambda = c(0.1, 1), family = 'survival', basehaz = \"weibul\") fit2 <- MAP.estimation(y, X, family = 'survival', Lambda = Lambda, basehaz = \"weibul\") fit2 #> $theta_hat #>       X1       X2       X3       X4  omega_1  omega_2  #> 1.216502 2.433061 3.305429 4.895585 1.411903 1.905060  #>  #> $A_hat #>                 X1          X2          X3          X4     omega_1   omega_2 #> X1       54.813643    8.232601   -3.813501   -5.643886    7.220449  -49.8473 #> X2        8.232601   85.409611   -5.039660  -16.200600   15.679748 -130.8181 #> X3       -3.813501   -5.039660   57.371520    4.560337   -2.868448 -186.1929 #> X4       -5.643886  -16.200600    4.560337   56.028421   23.120562 -262.4108 #> omega_1   7.220449   15.679748   -2.868448   23.120562   77.588076 -229.2848 #> omega_2 -49.847299 -130.818053 -186.192918 -262.410849 -229.284799 2656.6802 #>  #> $sd #>         X1         X2         X3         X4    omega_1    omega_2  #> 0.15896950 0.19980633 0.26038338 0.36632933 0.14912596 0.06994841  #>  #> $Lambda #>          X1  X2  X3  X4 omega_1 omega_2 #> X1      0.1 0.0 0.0 0.0       0       0 #> X2      0.0 0.1 0.0 0.0       0       0 #> X3      0.0 0.0 0.1 0.0       0       0 #> X4      0.0 0.0 0.0 0.1       0       0 #> omega_1 0.0 0.0 0.0 0.0       1       0 #> omega_2 0.0 0.0 0.0 0.0       0       1 #>  #> $formula #> [1] \"Survival(time, status) ~ X1 + X2 + X3 + X4\" #>  #> $names #> [1] \"X1\"      \"X2\"      \"X3\"      \"X4\"      \"omega_1\" \"omega_2\" #>  #> $n #> [1] 100 #>  #> $np #> [1] 4 #>  #> $treatment #> NULL #>  #> $zero_sample_cov #> NULL #>  #> $refer_cat #> NULL #>  #> $zero_cat #> NULL #>  #> $value #> [1] -61.88167 #>  #> $family #> [1] \"survival\" #>  #> $basehaz #> [1] \"weibul\" #>  #> $intercept #> [1] FALSE #>  #> $convergence #> [1] 0 #>  #> $control #> $control$maxit #> [1] 100 #>  #>  #> attr(,\"class\") #> [1] \"bfi\" summary(fit2, cur_mat = TRUE) #>  #> Summary of the local model: #>  #>    Formula: Survival(time, status) ~ X1 + X2 + X3 + X4  #>     Family: ‘survival’  #>   Baseline: ‘weibul’ #>  #> Coefficients: #>  #>         Estimate Std.Dev CI 2.5% CI 97.5% #> X1        1.2165  0.1590  0.9049   1.5281 #> X2        2.4331  0.1998  2.0414   2.8247 #> X3        3.3054  0.2604  2.7951   3.8158 #> X4        4.8956  0.3663  4.1776   5.6136 #> omega_1   1.4119  0.1491  1.1196   1.7042 #> omega_2   1.9051  0.0699  1.7680   2.0422 #>  #> log Lik Posterior:  61.88  #>       Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>               X1        X2        X3        X4   omega_1   omega_2 #> X1       54.8136    8.2326   -3.8135   -5.6439    7.2204  -49.8473 #> X2        8.2326   85.4096   -5.0397  -16.2006   15.6797 -130.8181 #> X3       -3.8135   -5.0397   57.3715    4.5603   -2.8684 -186.1929 #> X4       -5.6439  -16.2006    4.5603   56.0284   23.1206 -262.4108 #> omega_1   7.2204   15.6797   -2.8684   23.1206   77.5881 -229.2848 #> omega_2 -49.8473 -130.8181 -186.1929 -262.4108 -229.2848 2656.6802  #------------------------------------- # MAP estimations with \"poly\" function #------------------------------------- Lambda <- inv.prior.cov(X, lambda = c(0.1, 1), family = 'survival', basehaz = 'poly') fit3 <- MAP.estimation(y, X, family = \"survival\", Lambda = Lambda, basehaz = \"poly\") # Degree of the exponentiated polynomial baseline hazard fit3$q_l + 1 #> [1] 3 # theta_hat for (beta_1, ..., beta_p, omega_0, ..., omega_{q_l}) fit3$theta_A_poly[,,1][,fit3$q_l+1] # equal to fit3$theta_hat #>         X1         X2         X3         X4    omega_0    omega_1    omega_2  #>  0.4587444  0.9065738  1.2387261  1.8013492 -2.0743547  4.7662933 -1.0941826  # A_hat fit3$theta_A_poly[,,fit3$q_l+2] # equal to fit3$A_hat #>               [,1]      [,2]       [,3]       [,4]      [,5]       [,6] #> X1      67.2578299  3.698096  -6.328249  -0.830014  7.296302   1.005843 #> X2       3.6980959 85.034720   3.130474  -6.311998 15.832762  -1.055534 #> X3      -6.3282486  3.130474  73.449859  11.351621 -2.661869 -25.299425 #> X4      -0.8300140 -6.311998  11.351621  68.043358 23.430052  -8.113705 #> omega_0  7.2963020 15.832762  -2.661869  23.430052 90.074528  43.191997 #> omega_1  1.0058432 -1.055534 -25.299425  -8.113705 43.191997  57.713003 #> omega_2 -0.7626327 -7.194974 -42.325003 -19.174732 48.713003  71.822389 #>                [,7] #> X1       -0.7626327 #> X2       -7.1949742 #> X3      -42.3250033 #> X4      -19.1747319 #> omega_0  48.7130029 #> omega_1  71.8223891 #> omega_2 122.9402820 summary(fit3, cur_mat = TRUE) #>  #> Summary of the local model: #>  #>    Formula: Survival(time, status) ~ X1 + X2 + X3 + X4  #>     Family: ‘survival’  #>   Baseline: ‘poly’ #>  #> Coefficients: #>  #>         Estimate Std.Dev CI 2.5% CI 97.5% #> X1        0.4587  0.1242  0.2153   0.7022 #> X2        0.9066  0.1159  0.6793   1.1338 #> X3        1.2387  0.1364  0.9713   1.5061 #> X4        1.8013  0.1460  1.5153   2.0874 #> omega_0  -2.0744  0.1647 -2.3971  -1.7516 #> omega_1   4.7663  0.2867  4.2044   5.3282 #> omega_2  -1.0942  0.1826 -1.4520  -0.7364 #>  #> log Lik Posterior:  -1.084  #>       Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>              X1      X2       X3       X4 omega_0  omega_1  omega_2 #> X1      67.2578  3.6981  -6.3282  -0.8300  7.2963   1.0058  -0.7626 #> X2       3.6981 85.0347   3.1305  -6.3120 15.8328  -1.0555  -7.1950 #> X3      -6.3282  3.1305  73.4499  11.3516 -2.6619 -25.2994 -42.3250 #> X4      -0.8300 -6.3120  11.3516  68.0434 23.4301  -8.1137 -19.1747 #> omega_0  7.2963 15.8328  -2.6619  23.4301 90.0745  43.1920  48.7130 #> omega_1  1.0058 -1.0555 -25.2994  -8.1137 43.1920  57.7130  71.8224 #> omega_2 -0.7626 -7.1950 -42.3250 -19.1747 48.7130  71.8224 122.9403  #------------------------------------------------------ # MAP estimations with \"pwexp\" function with 3 intervals #------------------------------------------------------- # Assume we have 4 centers Lambda <- inv.prior.cov(X, lambda = c(0.1, 1), family = 'survival',                         basehaz = 'pwexp', n_intervals = 3) # For this baseline hazard (\"pwexp\"), we need to know # maximum survival times of the 3 other centers: max_times <- c(max(rexp(30)), max(rexp(50)), max(rexp(70))) # Minimum of the maximum values of the survival times of all 4 centers is: min_max_times <- min(max(y$time), max_times) fit4 <- MAP.estimation(y, X, family = \"survival\", Lambda = Lambda, basehaz = \"pwexp\",                        n_intervals = 3, min_max_times=max(y$time)) #>  #>  No. observations in the intervals :  73 18 9  #>   summary(fit4, cur_mat = TRUE) #>  #> Summary of the local model: #>  #>    Formula: Survival(time, status) ~ X1 + X2 + X3 + X4  #>     Family: ‘survival’  #>   Baseline: ‘pwexp’ #>  #> Coefficients: #>  #>         Estimate Std.Dev CI 2.5% CI 97.5% #> X1        0.3310  0.1353  0.0658   0.5961 #> X2        0.6246  0.1242  0.3812   0.8680 #> X3        0.7795  0.1377  0.5097   1.0493 #> X4        1.1811  0.1588  0.8699   1.4924 #> omega_1  -0.3968  0.1787 -0.7471  -0.0465 #> omega_2   1.4806  0.2910  0.9104   2.0509 #> omega_3   1.4282  0.6395  0.1747   2.6817 #>  #> log Lik Posterior:  -27.06  #>       Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>              X1      X2       X3      X4 omega_1  omega_2 omega_3 #> X1      58.2386  2.0588  -8.1905 -0.7741  7.5573  -0.4890  0.2409 #> X2       2.0588 74.7939   1.2829 -3.3496 16.9213  -0.5449 -0.5155 #> X3      -8.1905  1.2829  65.1478  9.3205  9.5898 -10.3783 -1.8274 #> X4      -0.7741 -3.3496   9.3205 64.3901 31.2096  -6.2708 -1.4469 #> omega_1  7.5573 16.9213   9.5898 31.2096 54.3965   0.0000  0.0000 #> omega_2 -0.4890 -0.5449 -10.3783 -6.2708  0.0000  14.5194  0.0000 #> omega_3  0.2409 -0.5155  -1.8274 -1.4469  0.0000   0.0000  2.5716   #-------------------------- # Semi-parametric Cox model #-------------------------- Lambda <- inv.prior.cov(X, lambda = c(0.1), family = 'survival', basehaz = \"unspecified\") fit5 <- MAP.estimation(y, X, family = 'survival', Lambda = Lambda, basehaz = \"unspecified\") #>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 summary(fit5, cur_mat = TRUE) #>  #> Summary of the local model: #>  #>    Formula: Survival(time, status) ~ X1 + X2 + X3 + X4  #>     Family: ‘survival’  #>   Baseline: ‘unspecified’ #>  #> Coefficients: #>  #>    Estimate Std.Dev CI 2.5% CI 97.5% #> X1   1.3040  0.1912  0.9293   1.6787 #> X2   2.4894  0.2755  1.9494   3.0293 #> X3   3.2086  0.3354  2.5512   3.8660 #> X4   5.0264  0.5126  4.0218   6.0311 #>  #> log Lik Posterior:  -143.5  #>       Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>          X1       X2       X3       X4 #> X1  51.8496   3.0205  -6.6147 -10.8334 #> X2   3.0205  57.7207 -11.4154 -21.3849 #> X3  -6.6147 -11.4154  35.0165 -12.4757 #> X4 -10.8334 -21.3849 -12.4757  23.4777"},{"path":"https://hassanpazira.github.io/BFI/reference/Nurses.html","id":null,"dir":"Reference","previous_headings":"","what":"Nurses' stress in different hospitals — Nurses","title":"Nurses' stress in different hospitals — Nurses","text":"dataset comprises three-level simulated data extracted hypothetical study investigating stress levels within hospital settings. dataset focuses nurses working specific wards within various hospitals. includes several variables, nurse age (measured years), nurse experience (measured years), nurse gender (0 male, 1 female), ward type (0 general care, 1 special care), hospital size (0 small, 1 medium, 2 large). dataset package obtained original dataset leaving unused columns.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/Nurses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nurses' stress in different hospitals — Nurses","text":"","code":"data(Nurses)"},{"path":"https://hassanpazira.github.io/BFI/reference/Nurses.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Nurses' stress in different hospitals — Nurses","text":"https://multilevel-analysis.sites.uu.nl/datasets/","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/Nurses.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Nurses' stress in different hospitals — Nurses","text":"Hox, J., Moerbeek, M., van de Schoot, R. (2010). Multilevel Analysis: Techniques Applications, Second Edition (2nd ed.). Routledge. <https://doi.org/10.4324/9780203852279>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/b.diag.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Block Diagonal Matrix — b.diag","title":"Create a Block Diagonal Matrix — b.diag","text":"Construct block diagonal matrix using multiple given block matrices.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/b.diag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Block Diagonal Matrix — b.diag","text":"","code":"b.diag(..., fill = 0)"},{"path":"https://hassanpazira.github.io/BFI/reference/b.diag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Block Diagonal Matrix — b.diag","text":"... individual matrices one list matrices. fill non-block-diagonal elements. Default \\(0\\).","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/b.diag.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Block Diagonal Matrix — b.diag","text":"Avoid combining matrices lists ... argument. b.diag() covers arguments type \"character\". sparse matrix needed, run following: library(Matrix); Matrix(b_diag, sparse = TRUE) b_diag matrix returned b.diag().","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/b.diag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Block Diagonal Matrix — b.diag","text":"b.diag() returns block diagonal matrix obtained combining arguments.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/b.diag.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a Block Diagonal Matrix — b.diag","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/b.diag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Block Diagonal Matrix — b.diag","text":"","code":"b.diag(1, matrix(1:3, 3,4), diag(3:2)) #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] #> [1,]    1    0    0    0    0    0    0 #> [2,]    0    1    1    1    1    0    0 #> [3,]    0    2    2    2    2    0    0 #> [4,]    0    3    3    3    3    0    0 #> [5,]    0    0    0    0    0    3    0 #> [6,]    0    0    0    0    0    0    2  b.diag(matrix(1:6, 2), as.character(2)) #>      [,1] [,2] [,3] [,4] #> [1,]    1    3    5    0 #> [2,]    2    4    6    0 #> [3,]    0    0    0    2  lists <- list(1, 2:3, diag(4:6), 7, cbind(8,9:12), 13:15) b.diag(lists) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] #>  [1,]    1    0    0    0    0    0    0    0    0 #>  [2,]    0    2    0    0    0    0    0    0    0 #>  [3,]    0    3    0    0    0    0    0    0    0 #>  [4,]    0    0    4    0    0    0    0    0    0 #>  [5,]    0    0    0    5    0    0    0    0    0 #>  [6,]    0    0    0    0    6    0    0    0    0 #>  [7,]    0    0    0    0    0    7    0    0    0 #>  [8,]    0    0    0    0    0    0    8    9    0 #>  [9,]    0    0    0    0    0    0    8   10    0 #> [10,]    0    0    0    0    0    0    8   11    0 #> [11,]    0    0    0    0    0    0    8   12    0 #> [12,]    0    0    0    0    0    0    0    0   13 #> [13,]    0    0    0    0    0    0    0    0   14 #> [14,]    0    0    0    0    0    0    0    0   15 identical(b.diag(lists), b.diag(lapply(lists, as.matrix))) #> [1] TRUE  b.diag(replicate(3, matrix(round(rnorm(9)), 3, 3), simplify=FALSE)) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] #>  [1,]    1    1    0    0    0    0    0    0    0 #>  [2,]    1   -1   -1    0    0    0    0    0    0 #>  [3,]    0   -1    0    0    0    0    0    0    0 #>  [4,]    0    0    0   -1    1    0    0    0    0 #>  [5,]    0    0    0    0    0    2    0    0    0 #>  [6,]    0    0    0    0   -2    0    0    0    0 #>  [7,]    0    0    0    0    0    0    0    2    0 #>  [8,]    0    0    0    0    0    0    1    1    0 #>  [9,]    0    0    0    0    0    0    0   -1    1"},{"path":"https://hassanpazira.github.io/BFI/reference/hazards.fun.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","title":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","text":"given vector times, hazards.fun computes estimated baseline hazard, cumulative baseline hazard, hazard, baseline survival, survival functions. can used prediction new sample.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/hazards.fun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","text":"","code":"hazards.fun(time,             z = NULL,             p,             theta_hat,             basehaz = c(\"weibul\", \"exp\", \"gomp\", \"poly\", \"pwexp\"),             q_max,             timax)"},{"path":"https://hassanpazira.github.io/BFI/reference/hazards.fun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","text":"time vector containing time values hazard rate computed. argument z NULL, length argument time number columns z, \\(p\\). z new observation vector length \\(p\\). z = NULL (default), relative risk (\\(\\boldsymbol{z}^{\\top} \\boldsymbol{\\beta}\\)) considered vector 1 length \\(n\\). p number coefficients. taken equal number elements argument z, z NULL. theta_hat vector contains values estimated parameters. first \\(p\\) values represent coefficient parameters (\\(\\boldsymbol{\\beta}\\)), remaining values pertain parameters baseline hazard function  (\\(\\boldsymbol{\\omega}\\)). basehaz character string representing one available baseline hazard functions; exponential (\"exp\"), Weibull (\"weibul\", default), Gompertz (\"gomp\"), exponentiated polynomial (\"poly\"), piecewise exponential (\"pwexp\"). Can abbreviated. q_max value represents order exponentiated polynomial baseline hazard function. argument used basehaz = \"poly\". case multiple centers, maximum value orders used. ql.LRT() can used obtaining order center. timax value represents minimum (maximum) value maximum times observed different centers. argument used basehaz = \"pwexp\".","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/hazards.fun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","text":"hazards.fun computes estimated baseline hazard, cumulative baseline hazard, hazard, baseline survival, survival functions different time points specified argument time. function hazards.fun() can used prediction purposes new sample. arguments time z provided new data.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/hazards.fun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","text":"hazards.fun returns list containing following components: bhazard vector estimates baseline hazard function time points given argument time; cbhazard vector estimates cumulative baseline hazard function time points specified argument time; bsurvival vector estimates baseline survival function time points given argument time; hazard vector estimates hazard function time points given argument time; chazard vector estimates cumulative hazard function time points specified argument time; survival vector estimates survival function time points given argument time.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/hazards.fun.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","text":"Pazira H., Massa E., Weijers J..M., Coolen .C.C. Jonker M.. (2025b). Bayesian Federated Inference Survival Models, Journal Applied Statistics (Accepted). <https://arxiv.org/abs/2404.17464>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/hazards.fun.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/hazards.fun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the estimated (baseline/cumulative) hazard and (baseline) survival functions — hazards.fun","text":"","code":"# Setting a seed for reproducibility set.seed(1123)  ##------------------------- ## Simulating Survival data ##-------------------------  n <- 40 p <- 7 Original_data <- data.frame(matrix(rnorm((n+1) * p), (n+1), p)) X <- Original_data[1:n,] X_new <- Original_data[(n+1),] # Simulating survival data from Exponential distribution # with a predefined censoring rate of 0.2: Orig_y <- surv.simulate(Z = Original_data, beta = rep(1,p), a = exp(1),                         cen_rate = 0.2, gen_data_from = \"exp\")$D[[1]][,1:2] y <- Orig_y[1:n,] y_new <- Orig_y[(n+1),] time_points <- seq(0, max(y$time), length.out=20)  #------------------------ # Weibull baseline hazard #------------------------  Lambda <- inv.prior.cov(X, lambda = c(0.5, 1), family = 'survival', basehaz = 'weibul') fit_weib <- MAP.estimation(y, X, family = 'survival', Lambda = Lambda,                            basehaz = \"weibul\") # reltive risk is 1: hazards.fun(time = time_points, p = p, theta_hat = fit_weib$theta_hat,             basehaz = \"weibul\") #> $bhazard #>  [1]      Inf 2.978474 2.838078 2.759040 2.704300 2.662590 2.628988 2.600909 #>  [9] 2.576829 2.555773 2.537084 2.520296 2.505066 2.491138 2.478311 2.466429 #> [17] 2.455365 2.445018 2.435302 2.426148 #>  #> $cbhazard #>  [1]  0.000000  1.139229  2.171059  3.165896  4.137445  5.092038  6.033332 #>  [8]  6.963708  7.884839  8.797963  9.704032 10.603800 11.497880 12.386779 #> [15] 13.270923 14.150674 15.026347 15.898213 16.766511 17.631454 #>  #> $bsurvival #>  [1] 1.000000e+00 3.200656e-01 1.140567e-01 4.217634e-02 1.596358e-02 #>  [6] 6.145483e-03 2.397493e-03 9.455839e-04 3.764071e-04 1.510404e-04 #> [11] 6.103691e-05 2.482151e-05 1.015159e-05 4.173402e-06 1.723898e-06 #> [16] 7.152208e-07 2.979480e-07 1.245931e-07 5.228735e-08 2.201693e-08 #>  #> $hazard #>  [1]      Inf 2.978474 2.838078 2.759040 2.704300 2.662590 2.628988 2.600909 #>  [9] 2.576829 2.555773 2.537084 2.520296 2.505066 2.491138 2.478311 2.466429 #> [17] 2.455365 2.445018 2.435302 2.426148 #>  #> $chazard #>  [1]  0.000000  1.139229  2.171059  3.165896  4.137445  5.092038  6.033332 #>  [8]  6.963708  7.884839  8.797963  9.704032 10.603800 11.497880 12.386779 #> [15] 13.270923 14.150674 15.026347 15.898213 16.766511 17.631454 #>  #> $survival #>  [1] 1.000000e+00 3.200656e-01 1.140567e-01 4.217634e-02 1.596358e-02 #>  [6] 6.145483e-03 2.397493e-03 9.455839e-04 3.764071e-04 1.510404e-04 #> [11] 6.103691e-05 2.482151e-05 1.015159e-05 4.173402e-06 1.723898e-06 #> [16] 7.152208e-07 2.979480e-07 1.245931e-07 5.228735e-08 2.201693e-08 #>   #------------------------- # Gompertz baseline hazard #------------------------- fit_gomp <- MAP.estimation(y, X, family = 'survival', Lambda = Lambda,                            basehaz = \"gomp\") # different time points hazards.fun(time=1:max(y*2), p = p, theta_hat = fit_gomp$theta_hat,             basehaz = \"gomp\") #> $bhazard #>  [1]  3.689346  4.847121  6.368226  8.366677 10.992274 14.441825 18.973901 #>  [8] 24.928215 32.751088 43.028903 56.532061 74.272726 97.580696 #>  #> $cbhazard #>  [1]   3.228712   7.470645  13.043764  20.365818  29.985649  42.624337 #>  [7]  59.229248  81.045045 109.706988 147.363508 196.837246 261.836634 #> [13] 347.233871 #>  #> $bsurvival #>  [1]  3.960849e-02  5.695610e-04  2.163541e-06  1.429676e-09  9.492883e-14 #>  [6]  3.079539e-19  1.892625e-26  6.347231e-36  2.263917e-48  1.001940e-64 #> [11]  3.270923e-86 1.931055e-114 1.578505e-151 #>  #> $hazard #>  [1]  3.689346  4.847121  6.368226  8.366677 10.992274 14.441825 18.973901 #>  [8] 24.928215 32.751088 43.028903 56.532061 74.272726 97.580696 #>  #> $chazard #>  [1]   3.228712   7.470645  13.043764  20.365818  29.985649  42.624337 #>  [7]  59.229248  81.045045 109.706988 147.363508 196.837246 261.836634 #> [13] 347.233871 #>  #> $survival #>  [1]  3.960849e-02  5.695610e-04  2.163541e-06  1.429676e-09  9.492883e-14 #>  [6]  3.079539e-19  1.892625e-26  6.347231e-36  2.263917e-48  1.001940e-64 #> [11]  3.270923e-86 1.931055e-114 1.578505e-151 #>    ##---------------------------- ## Prediction for a new sample ##----------------------------  ## Exponentiated polynomial (poly) baseline hazard: Lambda <- inv.prior.cov(X, lambda = c(0.5, 1), family = 'survival', basehaz = \"poly\") fit_poly <- MAP.estimation(y, X, family = 'survival', Lambda = Lambda,                            basehaz = \"poly\") hazards.fun(time = y_new$time, z = X_new, theta_hat = fit_poly$theta_hat,             basehaz = \"poly\", q_max = fit_poly$q_l) #> $bhazard #> [1] 3.18832 #>  #> $cbhazard #> [1] 0.3483998 #>  #> $bsurvival #> [1] 0.7058166 #>  #> $hazard #> [1] 67.42799 #>  #> $chazard #> [1] 7.368112 #>  #> $survival #> [1] 0.0006310584 #>   ## Piecewise Exponential (pwexp) baseline hazard: Lambda <- inv.prior.cov(X, lambda = c(0.5, 1), family = 'survival', basehaz = \"pwexp\") fit_pw <- MAP.estimation(y, X, family='survival', Lambda=Lambda, basehaz=\"pwexp\",                          min_max_times = max(y)) #>  #>  No. observations in the intervals :  36 1 0 3  #>   hazards.fun(time = y_new$time, z = X_new, theta_hat = fit_pw$theta_hat,             basehaz = \"pwexp\", timax = max(y)) #> $bhazard #> [1] 3.305502 #>  #> $cbhazard #> [1] 0.3612048 #>  #> $bsurvival #> [1] 0.6968363 #>  #> $hazard #> [1] 63.9545 #>  #> $chazard #> [1] 6.988551 #>  #> $survival #> [1] 0.000922382 #>"},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"inv.prior.cov constructs diagonal inverse covariance matrix Gaussian prior distribution based design matrix covariates. construction accounts number regression parameters, especially dealing categorical covariates. linear model, also includes additional row column represent variance measurement error. case survival model, considers parameters baseline hazard function well.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"","code":"inv.prior.cov(X,               lambda = 1,               L = 2,               family = c(\"gaussian\", \"binomial\", \"survival\"),               treatment = NULL,               treat_round = NULL,               intercept = TRUE,               stratified = FALSE,               strat_par = NULL,               center_spec = NULL,               basehaz = c(\"weibul\", \"exp\", \"gomp\", \"poly\", \"pwexp\", \"unspecified\"),               max_order = 2,               n_intervals = 4)"},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"X design matrix dimension \\(n \\times p\\), \\(n\\) number samples observed, \\(p\\) number predictors/variables excluding intercept. lambda vector used diagonal (inverse covariance) matrix created inv.prior.cov(). length vector depends number columns X, type covariates (continuous/dichotomous categorical), family, whether intercept included model, whether stratified analysis desired. stratified = FALSE, lambda single positive number (values vector equal), vector two elements (first used regression parameters including “intercept” second “sigma2” gaussian family baseline hazard parameters survival case), vector length equal number model parameters. However, length lambda different stratified = TRUE, see ‘Details’ information. Default lambda = 1. L number centers. argument used stratified = TRUE. Default L = 2. See ‘Details’ ‘Examples’. family description error distribution. character string naming family model. current version package, family model can \"gaussian\" (identity link function), \"binomial\" (logit link function), \"survival\". Can abbreviated. default gaussian family used. case linear regression model, family = \"gaussian\", extra model parameter variance measurement error. case survival model, family = \"survival\", number model parameters depend choice baseline hazard functions, see ‘Details’ information. treatment character string representing name place binary covariate, respectively. covariate indicates whether patient got new treatment (\\(z_{\\ell }=1\\)) placebo/standard treatment (\\(z_{\\ell }=0\\)). first second rounds, 'NULL'. See ‘Details’. treat_round character string representing 'first' 'second' round estimating treatment effects. first round, treat_round = 'first', local estimates coefficients (\\(\\gamma_{\\ell}\\)) estimated. second round, treat_round = 'second', propensity scores statistical summaries (for_ATE) calculated. intercept logical flag intercept. used family = \"survival\". changing intercept dimension inverse covariance matrix changes. intercept = TRUE (default), output matrix created inv.prior.cov() one row one column related intercept, intercept = FALSE, resulting matrix row column called intercept. stratified logical flag performing stratified analysis. stratified = TRUE, parameter(s) selected strat_par argument allowed different across centers deal heterogeneity across centers. argument used designing inverse covariance matrix (fictive) combined data, .e., last matrix Lambda argument bfi(). inv.prior.cov() used analysis local centers (build \\(L\\) first matrices Lambda argument bfi()), argument FALSE, even BFI analysis stratified. Default stratified = FALSE. See ‘Details’ ‘Examples’. strat_par integer vector indicating stratification parameter(s). can used deal heterogeneity due center-specific parameters. \"binomial\" \"gaussian\" families one- two-element integer vector values \\(1\\) /\\(2\\) /used indicate “intercept” /“sigma2” allowed vary, respectively. \"binomial\" family length vector one refers “intercept”, value element \\(1\\) (handel heterogeneity across outcome means). \"gaussian\" vector can \\(1\\) indicating “intercept” (handeling heterogeneity across outcome means), \\(2\\) indicating “sigma2” (handeling heterogeneity due nuisance parameter), c(\\(1\\), \\(2\\)) “intercept” “sigma2”. family = \"survival\", vector can contain combination 1 maximum number parameters baseline function, .e., \\(1\\) \"exp\", \\(2\\) \"weibul\" \"gomp\", max_order + 1 \"poly\", n_intervals \"pwexp\". argument used stratified = TRUE. Default strat_par = NULL. stratified = TRUE, strat_par can NULL except center_spec NULL handeling heterogeneity due clustering missing covariates. See ‘Details’ ‘Examples’. center_spec vector \\(L\\) elements representing center specific variable. argument used stratified = TRUE strat_par = NULL. element represents specific feature corresponding center. must one specific value attribute center. vector numeric, characteristic factor vector. Note , order centers vector center_spec must list argument theta_hats function bfi(). used data type argument center_spec must categorical. Default center_spec = NULL. See also ‘Details’ ‘Examples’. basehaz character string representing one available baseline hazard functions; exponential (\"exp\"), Weibull (\"weibul\", default), Gompertz (\"gomp\"), exponentiated polynomial (\"poly\"), piecewise constant exponential (\"pwexp\"), unspecified baseline hazard (\"unspecified\"). Can abbreviated. used family = \"survival\". max_order integer representing maximum value q_l, order/degree minus 1 exponentiated polynomial baseline hazard function. argument used family = \"survival\" basehaz = \"poly\". Default 2. n_intervals integer representing number intervals piecewise exponential baseline hazard function. argument used family = \"survival\" basehaz = \"pwexp\". Default 4.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"inv.prior.cov creates diagonal matrix vector lambda diagonal. argument stratified = TRUE used construct matrix prior density case stratification fictive combined data. Never used construction matrix analysis centers. stratified = FALSE, length vector lambda depends covariate matrix X, family, basehaz, whether “intercept” included model. example, design matrix X p columns continuous dichotomous covariates, family = gaussian, intercept = TRUE, lambda \\(p+2\\) elements. case, X categorical covariate \\(q>2\\) categories, length lambda increases \\(q-2\\). values lambda non-negative represent inverse variance Gaussian prior. argument considered inverse variance prior distribution : \\((\\beta_0, \\boldsymbol{\\beta})\\) family = \"binomial\" intercept = TRUE; \\((\\beta_0, \\boldsymbol{\\beta},\\sigma^2)\\) family = \"gaussian\" intercept = TRUE; \\(( \\boldsymbol{\\beta},\\boldsymbol{\\omega})\\) family = \"survival\". values vector lambda equal, one value enough given entry. lambda scalar, function inv.prior.cov sets value diagonal equal lambda.  lambda two dimensional: family = \"binomial\", first second values used inverse variance prior distribution intercept (\\(\\beta_0\\)) regression parameters (\\(\\boldsymbol{\\beta}\\)), respectively; family = \"gaussian\", first second values used inverse variance prior distribution regression parameters including intercept (\\(\\beta_0, \\boldsymbol{\\beta}\\)) variance measurement error (\\( \\sigma^2\\)), respectively; family = \"survival\", first second values used inverse variance prior distribution regression parameters (\\(\\boldsymbol{\\beta}\\)) baseline hazard parameters (\\( \\omega\\)), respectively. stratified = TRUE length vector lambda must equal number parameters combined model. intercept = FALSE, binomial family stratified analysis possible therefore stratified can TRUE. stratified = FALSE, strat_par center_spec must NULL (defaults), stratified = TRUE one two must NULL. stratified = TRUE family = \"survival\", strat_par = 1 refers \\(\\omega_0\\) basehaz = \"poly\", \\(\\omega_1\\) baseline hazards. output inv.prior.cov() can used main functions MAP.estimation() bfi().","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"inv.prior.cov returns diagonal matrix. dimension matrix depends number columns X, type covariates (continuous/dichotomous categorical), intercept, family, basehaz.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"Jonker M.., Pazira H. Coolen .C.C. (2024). Bayesian federated inference estimating statistical models based non-shared multicenter data sets, Statistics Medicine, 43(12): 2421-2438. <https://doi.org/10.1002/sim.10072> Pazira H., Massa E., Weijers J..M., Coolen .C.C. Jonker M.. (2025b). Bayesian Federated Inference Survival Models, Journal Applied Statistics (Accepted). <https://arxiv.org/abs/2404.17464> Jonker M.., Pazira H. Coolen .C.C. (2025a). Bayesian Federated Inference regression models based non-shared medical center data, Research Synthesis Methods, 1-41. <https://doi.org/10.1017/rsm.2025.6>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"Hassan Pazira Marianne Jonker  Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/inv.prior.cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates an inverse covariance matrix for a Gaussian prior — inv.prior.cov","text":"","code":"#---------------- # Data Simulation #---------------- X <- data.frame(x1=rnorm(50),                     # standard normal variable                 x2=sample(0:2, 50, replace=TRUE), # categorical variable                 x3=sample(0:1, 50, replace=TRUE)) # dichotomous variable X$x2 <- as.factor(X$x2) X$x3 <- as.factor(X$x3)  # The (inverse) variance value (lambda=0.05) is assumed to be # the same for Gaussian prior of all parameters (for non-stratified)  #------------------------------------------------- # Inverse Covariance Matrix for the Gaussian prior #------------------------------------------------- # y ~ Binomial with 'intercept' inv.prior.cov(X, lambda = 0.05, family = 'binomial') #>             (Intercept)   x1  x21  x22  x31 #> (Intercept)        0.05 0.00 0.00 0.00 0.00 #> x1                 0.00 0.05 0.00 0.00 0.00 #> x21                0.00 0.00 0.05 0.00 0.00 #> x22                0.00 0.00 0.00 0.05 0.00 #> x31                0.00 0.00 0.00 0.00 0.05 # returns a 5-by-5 matrix  # y ~ Binomial without 'intercept' inv.prior.cov(X, lambda = 0.05, family = \"binomial\", intercept = FALSE) #>       x1  x21  x22  x31 #> x1  0.05 0.00 0.00 0.00 #> x21 0.00 0.05 0.00 0.00 #> x22 0.00 0.00 0.05 0.00 #> x31 0.00 0.00 0.00 0.05 # a 4-by-4 matrix  # y ~ Gaussian with 'intercept' inv.prior.cov(X, lambda = 0.05, family = 'gaussian') #>             (Intercept)   x1  x21  x22  x31 sigma2 #> (Intercept)        0.05 0.00 0.00 0.00 0.00   0.00 #> x1                 0.00 0.05 0.00 0.00 0.00   0.00 #> x21                0.00 0.00 0.05 0.00 0.00   0.00 #> x22                0.00 0.00 0.00 0.05 0.00   0.00 #> x31                0.00 0.00 0.00 0.00 0.05   0.00 #> sigma2             0.00 0.00 0.00 0.00 0.00   0.05 # returns a 6-by-6 matrix  # Survival family with 'weibul' baseline hazard inv.prior.cov(X, lambda = c(0.05, 0.1), family = 'survival') #>           x1  x21  x22  x31 omega_1 omega_2 #> x1      0.05 0.00 0.00 0.00     0.0     0.0 #> x21     0.00 0.05 0.00 0.00     0.0     0.0 #> x22     0.00 0.00 0.05 0.00     0.0     0.0 #> x31     0.00 0.00 0.00 0.05     0.0     0.0 #> omega_1 0.00 0.00 0.00 0.00     0.1     0.0 #> omega_2 0.00 0.00 0.00 0.00     0.0     0.1 # returns a 6-by-6 matrix  # Survival family with 'pwexp' baseline hazard (4 intervals) inv.prior.cov(X, lambda = 0.05, family = 'survival', basehaz = \"pwexp\") #>           x1  x21  x22  x31 omega_1 omega_2 omega_3 omega_4 #> x1      0.05 0.00 0.00 0.00    0.00    0.00    0.00    0.00 #> x21     0.00 0.05 0.00 0.00    0.00    0.00    0.00    0.00 #> x22     0.00 0.00 0.05 0.00    0.00    0.00    0.00    0.00 #> x31     0.00 0.00 0.00 0.05    0.00    0.00    0.00    0.00 #> omega_1 0.00 0.00 0.00 0.00    0.05    0.00    0.00    0.00 #> omega_2 0.00 0.00 0.00 0.00    0.00    0.05    0.00    0.00 #> omega_3 0.00 0.00 0.00 0.00    0.00    0.00    0.05    0.00 #> omega_4 0.00 0.00 0.00 0.00    0.00    0.00    0.00    0.05 # returns a 8-by-8 matrix  # Survival family with 'poly' baseline hazard inv.prior.cov(X, lambda = c(0.05, 0.1), family = 'survival', basehaz = \"poly\") #>           x1  x21  x22  x31 omega_0 omega_1 omega_2 #> x1      0.05 0.00 0.00 0.00     0.0     0.0     0.0 #> x21     0.00 0.05 0.00 0.00     0.0     0.0     0.0 #> x22     0.00 0.00 0.05 0.00     0.0     0.0     0.0 #> x31     0.00 0.00 0.00 0.05     0.0     0.0     0.0 #> omega_0 0.00 0.00 0.00 0.00     0.1     0.0     0.0 #> omega_1 0.00 0.00 0.00 0.00     0.0     0.1     0.0 #> omega_2 0.00 0.00 0.00 0.00     0.0     0.0     0.1 # returns a 7-by-7 matrix  #-------------------- # Stratified analysis #-------------------- # y ~ Binomial when 'intercept' varies across 3 centers: inv.prior.cov(X, lambda = c(.2, 1), family = 'binomial', stratified = TRUE,               strat_par = 1, L = 3) #>                  (Intercept)_loc1 (Intercept)_loc2 (Intercept)_loc3 x1 x21 x22 #> (Intercept)_loc1              0.2              0.0              0.0  0   0   0 #> (Intercept)_loc2              0.0              0.2              0.0  0   0   0 #> (Intercept)_loc3              0.0              0.0              0.2  0   0   0 #> x1                            0.0              0.0              0.0  1   0   0 #> x21                           0.0              0.0              0.0  0   1   0 #> x22                           0.0              0.0              0.0  0   0   1 #> x31                           0.0              0.0              0.0  0   0   0 #>                  x31 #> (Intercept)_loc1   0 #> (Intercept)_loc2   0 #> (Intercept)_loc3   0 #> x1                 0 #> x21                0 #> x22                0 #> x31                1  # y ~ Gaussian when 'intercept' and 'sigma2' vary across 2 centers; y ~ Gaussian inv.prior.cov(X, lambda = c(1, 2, 3), family = \"gaussian\", stratified = TRUE,               strat_par = c(1, 2)) #>                  (Intercept)_loc1 (Intercept)_loc2 x1 x21 x22 x31 sigma2_loc1 #> (Intercept)_loc1                1                0  0   0   0   0           0 #> (Intercept)_loc2                0                1  0   0   0   0           0 #> x1                              0                0  2   0   0   0           0 #> x21                             0                0  0   2   0   0           0 #> x22                             0                0  0   0   2   0           0 #> x31                             0                0  0   0   0   2           0 #> sigma2_loc1                     0                0  0   0   0   0           3 #> sigma2_loc2                     0                0  0   0   0   0           0 #>                  sigma2_loc2 #> (Intercept)_loc1           0 #> (Intercept)_loc2           0 #> x1                         0 #> x21                        0 #> x22                        0 #> x31                        0 #> sigma2_loc1                0 #> sigma2_loc2                3  # y ~ Gaussian when 'sigma2' varies across 2 centers (with 'intercept') inv.prior.cov(X, lambda = c(1, 2, 3), family='gaussian', stratified = TRUE,               strat_par = 2) #>             (Intercept) x1 x21 x22 x31 sigma2_loc1 sigma2_loc2 #> (Intercept)           1  0   0   0   0           0           0 #> x1                    0  2   0   0   0           0           0 #> x21                   0  0   2   0   0           0           0 #> x22                   0  0   0   2   0           0           0 #> x31                   0  0   0   0   2           0           0 #> sigma2_loc1           0  0   0   0   0           3           0 #> sigma2_loc2           0  0   0   0   0           0           3  # y ~ Gaussian when 'sigma2' varies across 2 centers (without 'intercept') inv.prior.cov(X, lambda = c(2, 3), family = \"gaussian\", intercept = FALSE,               stratified=TRUE, strat_par = 2) #>             x1 x21 x22 x31 sigma2_loc1 sigma2_loc2 #> x1           2   0   0   0           0           0 #> x21          0   2   0   0           0           0 #> x22          0   0   2   0           0           0 #> x31          0   0   0   2           0           0 #> sigma2_loc1  0   0   0   0           3           0 #> sigma2_loc2  0   0   0   0           0           3  #-------------------------- # Center specific covariate #-------------------------- # center specific covariate has K = 2 categories across 4 centers; y ~ Binomial inv.prior.cov(X, lambda = c(0.1:2), family = 'binomial', stratified = TRUE,               center_spec = c(\"Iran\",\"Netherlands\",\"Netherlands\",\"Iran\"), L=4) #>                         (Intercept)_Iran (Intercept)_Netherlands  x1 x21 x22 #> (Intercept)_Iran                     0.1                     0.0 0.0 0.0 0.0 #> (Intercept)_Netherlands              0.0                     0.1 0.0 0.0 0.0 #> x1                                   0.0                     0.0 1.1 0.0 0.0 #> x21                                  0.0                     0.0 0.0 1.1 0.0 #> x22                                  0.0                     0.0 0.0 0.0 1.1 #> x31                                  0.0                     0.0 0.0 0.0 0.0 #>                         x31 #> (Intercept)_Iran        0.0 #> (Intercept)_Netherlands 0.0 #> x1                      0.0 #> x21                     0.0 #> x22                     0.0 #> x31                     1.1  # center specific covariate has K = 3 categories across 5 centers; y ~ Gaussian inv.prior.cov(X, lambda = c(0.5:3), family = 'gaussian', stratified = TRUE,               center_spec = c(\"Medium\",\"Big\",\"Small\",\"Big\",\"Small\"), L = 5) #>                    (Intercept)_Big (Intercept)_Medium (Intercept)_Small  x1 x21 #> (Intercept)_Big                0.5                0.0               0.0 0.0 0.0 #> (Intercept)_Medium             0.0                0.5               0.0 0.0 0.0 #> (Intercept)_Small              0.0                0.0               0.5 0.0 0.0 #> x1                             0.0                0.0               0.0 1.5 0.0 #> x21                            0.0                0.0               0.0 0.0 1.5 #> x22                            0.0                0.0               0.0 0.0 0.0 #> x31                            0.0                0.0               0.0 0.0 0.0 #> sigma2                         0.0                0.0               0.0 0.0 0.0 #>                    x22 x31 sigma2 #> (Intercept)_Big    0.0 0.0    0.0 #> (Intercept)_Medium 0.0 0.0    0.0 #> (Intercept)_Small  0.0 0.0    0.0 #> x1                 0.0 0.0    0.0 #> x21                0.0 0.0    0.0 #> x22                1.5 0.0    0.0 #> x31                0.0 1.5    0.0 #> sigma2             0.0 0.0    2.5  # center specific covariate has K = 4 categories across 5 centers; y ~ Gaussian inv.prior.cov(X, lambda = 1, family = 'gaussian', stratified = TRUE,               center_spec = c(3,1:4), L=5) #>               (Intercept)_1 (Intercept)_2 (Intercept)_3 (Intercept)_4 x1 x21 #> (Intercept)_1             1             0             0             0  0   0 #> (Intercept)_2             0             1             0             0  0   0 #> (Intercept)_3             0             0             1             0  0   0 #> (Intercept)_4             0             0             0             1  0   0 #> x1                        0             0             0             0  1   0 #> x21                       0             0             0             0  0   1 #> x22                       0             0             0             0  0   0 #> x31                       0             0             0             0  0   0 #> sigma2                    0             0             0             0  0   0 #>               x22 x31 sigma2 #> (Intercept)_1   0   0      0 #> (Intercept)_2   0   0      0 #> (Intercept)_3   0   0      0 #> (Intercept)_4   0   0      0 #> x1              0   0      0 #> x21             0   0      0 #> x22             1   0      0 #> x31             0   1      0 #> sigma2          0   0      1"},{"path":"https://hassanpazira.github.io/BFI/reference/n.par.html","id":null,"dir":"Reference","previous_headings":"","what":"The Number of Predictors, Coefficients, and Observations — n.par","title":"The Number of Predictors, Coefficients, and Observations — n.par","text":"n.par returns number regression parameters, covariates observations present X based selected family.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/n.par.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Number of Predictors, Coefficients, and Observations — n.par","text":"","code":"n.par(X, family = c(\"gaussian\", \"binomial\", \"survival\"))"},{"path":"https://hassanpazira.github.io/BFI/reference/n.par.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Number of Predictors, Coefficients, and Observations — n.par","text":"X design matrix dimension \\(n \\times p\\), \\(n\\) number samples observed, \\(p\\) number predictors/covariables. matrix list matrices. family description error distribution used specify model. character string, either “gaussian”, “binomial”, “survival”. Can abbreviated. default gaussian family used.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/n.par.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Number of Predictors, Coefficients, and Observations — n.par","text":"orig.names covar.names covariates X continuous. However, least one categorical variable X two categories, different.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/n.par.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Number of Predictors, Coefficients, and Observations — n.par","text":"n.par returns list containing following components: n.reg.par number regression parameters; n.covar number covariates; n.sample number samples/observations; orig.names original variable names excluding dummy variable names; covar.names variables names, including dummy variable names (applicable).","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/n.par.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"The Number of Predictors, Coefficients, and Observations — n.par","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/n.par.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Number of Predictors, Coefficients, and Observations — n.par","text":"","code":"#-------------------- # family = \"gaussian\" #--------------------  X0 <- data.frame(x1 = rnorm(50),                     # standard normal variable                  x2 = sample(0:2, 50, replace=TRUE), # categorical variable                  x3 = sample(0:1, 50, replace=TRUE)) # dichotomous variable n.par(X0) # without dummy variables #> $n.reg.par #> [1] 3 #>  #> $n.covar #> [1] 3 #>  #> $n.sample #> [1] 50 #>  #> $orig.names #> [1] \"x1\" \"x2\" \"x3\" #>  #> $covar.names #> [1] \"x1\" \"x2\" \"x3\" #>  X0$x2 <- as.factor(X0$x2) X0$x3 <- as.factor(X0$x3) n.par(X0)  # with dummy variables #> $n.reg.par #> [1] 4 #>  #> $n.covar #> [1] 3 #>  #> $n.sample #> [1] 50 #>  #> $orig.names #> [1] \"x1\" \"x2\" \"x3\" #>  #> $covar.names #> [1] \"x1\"  \"x21\" \"x22\" \"x31\" #>   X1 <- data.frame(Intercept = rep(1,30),                  x1 = rnorm(30),                     # continuous variable                  x2 = sample(0:2, 30, replace=TRUE)) # categorical variable n.par(X1) # without dummy variables #> $n.reg.par #> [1] 2 #>  #> $n.covar #> [1] 2 #>  #> $n.sample #> [1] 30 #>  #> $orig.names #> [1] \"x1\" \"x2\" #>  #> $covar.names #> [1] \"x1\" \"x2\" #>  X1$x2  <- as.factor(X1$x2) n.par(X1) # without dummy variables #> $n.reg.par #> [1] 3 #>  #> $n.covar #> [1] 2 #>  #> $n.sample #> [1] 30 #>  #> $orig.names #> [1] \"x1\" \"x2\" #>  #> $covar.names #> [1] \"x1\"  \"x21\" \"x22\" #>   # a list of two data sets: X01 <- list(X0, X1) n.par(X01) #> $n.reg.par #> [1] 4 3 #>  #> $n.covar #> [1] 3 2 #>  #> $n.sample #> [1] 50 30 #>  #> $orig.names #> $orig.names[[1]] #> [1] \"x1\" \"x2\" \"x3\" #>  #> $orig.names[[2]] #> [1] \"x1\" \"x2\" #>  #>  #> $covar.names #> $covar.names[[1]] #> [1] \"x1\"  \"x21\" \"x22\" \"x31\" #>  #> $covar.names[[2]] #> [1] \"x1\"  \"x21\" \"x22\" #>  #>"},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing BFI Fits — summary.bfi","title":"Summarizing BFI Fits — summary.bfi","text":"Summary method object class 'bfi' created MAP.estimation bfi functions.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing BFI Fits — summary.bfi","text":"","code":"# S3 method for class 'bfi' summary(object,         cur_mat = FALSE,         digits = max(3, getOption(\"digits\") - 3),         ...)"},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing BFI Fits — summary.bfi","text":"object fitted bfi object. cur_mat logical; TRUE, minus curvature matrix around estimated parameters returned printed. Default FALSE. digits significant digits printout. ... additional arguments affecting summary produced.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarizing BFI Fits — summary.bfi","text":"summary.bfi() gives information MAP estimates parameters model. can used bfi objects built MAP.estimation bfi functions. output summary method shows details model, .e. formula, family link function used specify generalized linear model, followed information estimates, standard deviations credible intervals. Information log-likelihood posterior convergence status also provided. default, summary.bfi function return (minus) curvature matrix, user can use cur_mat = TRUE print .","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing BFI Fits — summary.bfi","text":"summary.bfi returns object class summary.bfi, list following components: theta_hat component object. last element vector estimate dispersion parameter (sigma2) family = \"gaussian\". See MAP.estimation bfi functions. A_hat component object. See MAP.estimation bfi functions. sd component object. family = \"gaussian\", last element vector square root estimated dispersion. See MAP.estimation bfi functions. Lambda component object. See MAP.estimation function. formula component object. See MAP.estimation function. n component object. See MAP.estimation function. np component object. See MAP.estimation function. family component object. See MAP.estimation function. intercept component object. See MAP.estimation function. convergence component object. See MAP.estimation function. control component object. See MAP.estimation function. stratified component object. See bfi function. estimate estimated regression coefficients, .e., without estimate sigma2. logLikPost value log-likelihood posterior density evaluated estimates (theta_hat). link link function GLMs, survival family. default gaussian family identity link function binomial family logit link function used. dispersion estimated variance random error, .e., sigma2. dispersion taken 1 binomial family. CI 95% credible interval MAP estimates parameters.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarizing BFI Fits — summary.bfi","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/summary.bfi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing BFI Fits — summary.bfi","text":"","code":"#------------- # y ~ Gaussian #------------- # model assumption: theta <- c(1, 2, 3, 4, 1.5)  # coefficients and sigma2 = 1.5  #---------------- # Data Simulation #---------------- n      <- 40 X      <- data.frame(x1=rnorm(n),                     # continuous variable                      x2=sample(1:3, n, replace=TRUE)) # categorical variable Xx2_1  <- ifelse(X$x2 == '2', 1, 0) Xx2_2  <- ifelse(X$x2 == '3', 1, 0) X$x2   <- as.factor(X$x2) eta    <- theta[1] + theta[2] * X$x1 + theta[3] * Xx2_1 + theta[4] * Xx2_2 mu     <- gaussian()$linkinv(eta) y      <- rnorm(n, mu, sd = sqrt(theta[5]))  #---------------- # MAP estimations #---------------- Lambda <- inv.prior.cov(X, lambda = c(0.1, 0.5), family = \"gaussian\") fit    <- MAP.estimation(y, X, family = \"gaussian\", Lambda) class(fit) #> [1] \"bfi\"  #------------------------- # Summary of MAP estimates #------------------------- summary(fit) #>  #> Summary of the local model: #>  #>    Formula: y ~ x1 + x2  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.5077  0.3072 -0.0945   1.1099 #> x1            1.7133  0.1977  1.3259   2.1007 #> x22           3.9905  0.4676  3.0741   4.9070 #> x23           4.6274  0.4377  3.7695   5.4853 #>  #> Dispersion parameter (sigma2):  1.421  #>             log Lik Posterior:  -59.53  #>                   Convergence:  0  sumfit <- summary(fit, cur_mat = TRUE) #>  #> Summary of the local model: #>  #>    Formula: y ~ x1 + x2  #>     Family: ‘gaussian’  #>       Link: ‘identity’ #>  #> Coefficients: #>  #>             Estimate Std.Dev CI 2.5% CI 97.5% #> (Intercept)   0.5077  0.3072 -0.0945   1.1099 #> x1            1.7133  0.1977  1.3259   2.1007 #> x22           3.9905  0.4676  3.0741   4.9070 #> x23           4.6274  0.4377  3.7695   5.4853 #>  #> Dispersion parameter (sigma2):  1.421  #>             log Lik Posterior:  -59.53  #>                   Convergence:  0  #>  #> Minus the Curvature Matrix:  #>  #>             (Intercept)      x1     x22     x23  sigma2 #> (Intercept)     28.2460  6.0093  7.7402  9.8511 -0.1010 #> x1               6.0093 27.0031  0.8318  2.7736 -0.3427 #> x22              7.7402  0.8318  7.8402  0.0000 -0.7980 #> x23              9.8511  2.7736  0.0000  9.9511 -0.9253 #> sigma2          -0.1010 -0.3427 -0.7980 -0.9253 82.8423 sumfit$estimate #> [1] 0.507736 1.713305 3.990528 4.627400 sumfit$logLikPost #> [1] -59.53309 sumfit$dispersion #>   sigma2  #> 1.421159  sumfit$CI #>                   2.5 %   97.5 % #> (Intercept) -0.09445457 1.109927 #> x1           1.32586120 2.100748 #> x22          3.07407378 4.906981 #> x23          3.76947073 5.485330 class(sumfit) #> [1] \"summary.bfi\""},{"path":"https://hassanpazira.github.io/BFI/reference/surv.simulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","title":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","text":"surv.simulate simulates one multiple (right-censored) survival datasets proportional hazards models simultaneously incorporating baseline hazard function three different survival distributions (exponential, Weibull Gompertz), random censoring time generated uniform distribution known/unknown upper limit, set baseline covariates. upper limit uniform censoring time distribution unknown, surv.simulate can used separately obtain upper limit predefined censoring rate.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/surv.simulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","text":"","code":"surv.simulate(L = 1, Z, beta, a, b, u1 = 0, u2, cen_rate,               gen_data_from = c(\"exp\", \"weibul\", \"gomp\"),               only_u2 = FALSE, n.rep = 100, Trace = FALSE)"},{"path":"https://hassanpazira.github.io/BFI/reference/surv.simulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","text":"L number datasets generated. Default L = 1. Z list L design matrices dimension \\(n_\\ell \\times p\\), \\(n_\\ell\\) number samples observed \\(\\ell^{\\text{th}}\\) dataset \\(p\\) number covariables. L = 1, Z can matrix. beta vector (true) coefficients values, length \\(p\\) (number covariates). scale parameter, non-negative. See ‘Details’ form cumulative hazard can used. b shape/location parameter, non-negative. used gen_data_from = “exp”. See ‘Details’ form cumulative hazard can used. u1 known non-negative lower limit uniform distribution generating random censoring time. Default u1 = 0. cen_rate equal 0, u1 need defined. u2 non-negative upper limit uniform random censoring time distribution. upper limit can unknown (u2 = NULL, default), predefined. argument assumed unknown, u2 = NULL, calculated algorithm within surv.simulate(). However, argument u2 known, censoring rate predefined (meaning control ) calculated based generated dataset. See ‘Details’ ‘References’. cen_rate value representing proportion observations simulated survival data censored. range argument 0 1. upper limit known, cen_rate can predefined. censoring (cen_rate = 0), lower (u1) upper (u2) limits uniform distribution need specified. gen_data_from description distribution time event generated. character string can exponential (“exp”), Weibull (“weibul”), Gompertz (“gomp”). Can abbreviated. default, exponential distribution used. only_u2 logical flag calculating upper limit uniform censoring time distribution. only_u2 = TRUE, dataset(s) generated. only_u2 = TRUE, arguments Z u2 need specified, cen_rate set \\(0\\). Default only_u2 = FALSE. n.rep scalar specifying number iterations. argument exclusively used case Gompertz distribution. Default 100. Trace logical flag indicating whether output desired u2 censoring proportion different datasets produced iteration. works gen_data_from = “gomp”.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/surv.simulate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","text":"surv.simulate function generates \\(L\\) simulated right-censored survival datasets exponential, Weibull, Gompertz distributions, incorporating covariates, Z, distributed according multivariate normal distribution, censoring time generated uniform distribution Uniform(u1, u2), u1 known u2 can either known unknown. surv.simulate() can also used calculate unknown upper limit uniform distribution, u2, predefined censoring rate. , set u2 = NULL only_u2 = TRUE. case, datasets generated; u2 . surv.simulate() uses root-finding algorithm select censoring parameter achieves predefined censoring rates simulated survival data. gen_data_from = “exp”: cumulative baseline hazard function considered \\(\\Lambda_0=t\\), event time \\(\\ell^{\\text{th}}\\) dataset, \\(T_\\ell\\), computed \\( - log(u) \\ exp(- Z_\\ell \\boldsymbol{\\beta}) / \\), \\(u\\) follows standard uniform distribution; gen_data_from = “weibul”: cumulative hazard function \\(\\Lambda_0=t ^ b\\), event time computed \\(T_\\ell= (- log(u) \\ exp(- Z_\\ell \\boldsymbol{\\beta}) / )^{1/b}\\), \\(u\\) follows standard uniform distribution; gen_data_from = “gomp”: cumulative hazard function \\(\\Lambda_0=(exp(b t) - 1) / b\\), event time computed \\(T_\\ell= \\log(1- log(u) \\ exp(- Z_\\ell \\boldsymbol{\\beta}) b / ) / b\\), \\(u\\) follows standard uniform distribution; Finally survival time obtained \\(\\tilde{T}_\\ell=\\min\\{T_\\ell , C_\\ell \\}\\). function updated gen_data_from = “gomp”.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/surv.simulate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","text":"surv.simulate returns list containing following components: D list \\(L\\) data frames, dimension \\(n_\\ell \\times (p+2)\\). first second columns, named time status, contain simulated survival time censoring indicator, respectively, \\(0\\) means censored \\(1\\) means uncensored; censor_propor vector censoring proportions simulated datasets D, containing \\(L\\) elements; u1 lower limit uniform distribution used generate random censoring times predefined censoring rate. Sometimes output less value entered user, adjusted achieve desired amount censoring rate; u2 upper limit uniform distribution used generate random censoring times. u2 = NULL, output estimated upper limit necessary achieve desired censoring rate across \\(L\\) datasets.","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/surv.simulate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","text":"Pazira H., Massa E., Weijers J..M., Coolen .C.C. Jonker M.. (2025b). Bayesian Federated Inference Survival Models, Journal Applied Statistics (Accepted). <https://arxiv.org/abs/2404.17464>","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/surv.simulate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","text":"Hassan Pazira Maintainer: Hassan Pazira hassan.pazira@radboudumc.nl","code":""},{"path":[]},{"path":"https://hassanpazira.github.io/BFI/reference/surv.simulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate survival data with predefined censoring rates for proportional hazards models — surv.simulate","text":"","code":"# Setting a seed for reproducibility set.seed(1123)  #------------------------- # Simulating Survival data #------------------------- N    <- c(7, 10, 13) # the sample sizes of 3 datasets beta <- 1:4 p    <- length(beta) L    <- 3  # Define a function to generate multivariate normal samples mvrnorm_new <- function(n, mu, Sigma) {     pp <- length(mu)     e <- matrix(rnorm(n * pp), nrow = n)     return(crossprod(t(e), chol(Sigma)) + matrix(mu, n, pp, byrow = TRUE)) } Z <- list() for (z in seq_len(L)) {     Z[[z]] <- mvrnorm_new(n = N[z], mu = rep(0, p),                           Sigma = diag(rep(1, p),p))     colnames(Z[[z]]) <- paste0(\"Z_\",seq_len(ncol(Z[[z]]))) }  # One simulated dataset from exponential distribution with no censoring: surv_data <- surv.simulate(Z = Z[[1]], beta = beta, a = exp(-.9),                            cen_rate = 0, gen_data_from = \"exp\") surv_data #> $D #> $D[[1]] #>           time status       Z.Z_1       Z.Z_2      Z.Z_3      Z.Z_4 #> 1  0.075564227      1  0.70473619  0.94551438 -0.6930954  0.6174432 #> 2  0.732609577      1  1.10710882  0.37164284 -0.1714535 -0.2798152 #> 3 15.148291300      1  0.94005308 -1.14369244 -1.1564422  0.9669025 #> 4  0.003073544      1 -0.91096743  0.31234925  1.9137865  0.3402063 #> 5  2.022124176      1  1.38294723 -0.17384622 -1.2173467  0.3753887 #> 6  0.055636648      1  0.19442801  0.05596198 -0.8097336  1.6147903 #> 7  0.328196224      1 -0.03972739  0.79823340 -0.3073386  0.6104483 #>  #>  #> $censor_propor #> [1] 0 #>  #> $u1 #> NULL #>  #> $u2 #> NULL #>  surv_data$D[[1]][,1:2] # The simulated survival data #>           time status #> 1  0.075564227      1 #> 2  0.732609577      1 #> 3 15.148291300      1 #> 4  0.003073544      1 #> 5  2.022124176      1 #> 6  0.055636648      1 #> 7  0.328196224      1  # Calculate only 'u2' with a predefined censoring rate of 0.4: u2_new <- surv.simulate(Z = Z[1:2], beta = beta, a = exp(-.9),                         b = exp(1.8), u1 = 0.1, only_u2 = TRUE,                         cen_rate = 0.4, gen_data_from = \"weibul\")$u2 u2_new #> [1] 3.252022  # Two simulated datasets with a known 'u2': # Using 'u2_new' to help control over censoring rate (was chosen 0.4) surv.simulate(Z = Z[1:2], beta = beta, a = exp(-.9), b = exp(1.8),               u1 = 0.05, u2 = u2_new, gen_data_from = \"weibul\") #> $D #> $D[[1]] #>        time status       Z.Z_1       Z.Z_2      Z.Z_3      Z.Z_4 #> 1 0.7399626      1  0.70473619  0.94551438 -0.6930954  0.6174432 #> 2 1.1207633      0  1.10710882  0.37164284 -0.1714535 -0.2798152 #> 3 1.7127411      1  0.94005308 -1.14369244 -1.1564422  0.9669025 #> 4 0.3660419      1 -0.91096743  0.31234925  1.9137865  0.3402063 #> 5 0.8653180      1  1.38294723 -0.17384622 -1.2173467  0.3753887 #> 6 0.3775353      1  0.19442801  0.05596198 -0.8097336  1.6147903 #> 7 0.7019206      1 -0.03972739  0.79823340 -0.3073386  0.6104483 #>  #> $D[[2]] #>         time status       Z.Z_1      Z.Z_2      Z.Z_3       Z.Z_4 #> 1  3.1926945      0 -0.23027404 -1.2690632 -0.2673166 -1.55025861 #> 2  0.3414662      1 -0.32916907  1.6265643  0.2278069  0.91480231 #> 3  1.1314558      1  0.49944094 -0.7696502  0.3879469 -0.02710971 #> 4  1.1982244      1 -0.92867906  0.2380289 -1.2894161  0.70696930 #> 5  1.4326297      1 -0.96832355  0.2955621 -0.4037798  0.42578390 #> 6  0.9277940      1 -0.05840795  0.9128333 -0.4899637  0.34036840 #> 7  0.3113212      0  1.07646211 -0.8527642  0.2666801  1.41542485 #> 8  0.1139205      0  1.68615000 -0.5295145  1.3293412  0.59569653 #> 9  0.6654312      1  1.93659046  1.7751477 -1.2878720  0.26822334 #> 10 1.0432595      0  0.51202240 -1.6117240  0.9368176 -0.75419444 #>  #>  #> $censor_propor #> [1] 0.1428571 0.4000000 #>  #> $u1 #> [1] 0.05 #>  #> $u2 #> [1] 3.252022 #>   # Three simulated datasets from 'weibul' with an unknown 'u2': surv.simulate(Z = Z, beta = beta, a = exp(-1), b = exp(1),                u1 = 0.01, cen_rate = 0.3, gen_data_from = \"weibul\") #> $D #> $D[[1]] #>        time status       Z.Z_1       Z.Z_2      Z.Z_3      Z.Z_4 #> 1 0.2823065      1  0.70473619  0.94551438 -0.6930954  0.6174432 #> 2 0.9975437      1  1.10710882  0.37164284 -0.1714535 -0.2798152 #> 3 0.8144260      0  0.94005308 -1.14369244 -1.1564422  0.9669025 #> 4 0.1386992      1 -0.91096743  0.31234925  1.9137865  0.3402063 #> 5 1.6849989      1  1.38294723 -0.17384622 -1.2173467  0.3753887 #> 6 0.1502737      0  0.19442801  0.05596198 -0.8097336  1.6147903 #> 7 0.3864806      1 -0.03972739  0.79823340 -0.3073386  0.6104483 #>  #> $D[[2]] #>          time status       Z.Z_1      Z.Z_2      Z.Z_3       Z.Z_4 #> 1  7.75069014      0 -0.23027404 -1.2690632 -0.2673166 -1.55025861 #> 2  0.07093456      1 -0.32916907  1.6265643  0.2278069  0.91480231 #> 3  1.34441157      1  0.49944094 -0.7696502  0.3879469 -0.02710971 #> 4  1.85809906      1 -0.92867906  0.2380289 -1.2894161  0.70696930 #> 5  0.88334276      1 -0.96832355  0.2955621 -0.4037798  0.42578390 #> 6  0.72544536      0 -0.05840795  0.9128333 -0.4899637  0.34036840 #> 7  0.10815548      1  1.07646211 -0.8527642  0.2666801  1.41542485 #> 8  0.10718719      1  1.68615000 -0.5295145  1.3293412  0.59569653 #> 9  0.33155256      1  1.93659046  1.7751477 -1.2878720  0.26822334 #> 10 1.31690683      1  0.51202240 -1.6117240  0.9368176 -0.75419444 #>  #> $D[[3]] #>          time status       Z.Z_1       Z.Z_2       Z.Z_3      Z.Z_4 #> 1  1.54786085      1 -1.44153951  0.84543041  1.63435118 -1.3325912 #> 2  0.28011636      1  0.42547690  0.91067540 -0.02140968  0.3038766 #> 3  0.07408815      1  0.63158367  0.08532232  0.64390401  1.2853559 #> 4  0.98235600      0 -0.15201586 -0.91096893  0.32015202 -0.1719336 #> 5  0.09308440      0 -1.48957048  0.09515951  1.29546216 -0.1569018 #> 6  0.20262018      1  0.50347542  0.65439581 -0.57036674  1.1085850 #> 7  0.78550533      0  0.95250295 -0.71764421  0.51880688 -1.5608051 #> 8  0.04926487      1  0.04937487  1.07616067  1.37303835  0.3469306 #> 9  0.38080909      1  0.37153942 -0.04582918 -0.45533515  1.2241016 #> 10 3.21427845      0 -0.90718225 -2.49706485  1.40629078 -0.8608085 #> 11 0.11008080      1  2.53099268 -0.03519585  0.12720354  1.4766462 #> 12 0.15020603      1  1.13004355  1.34211808  0.83315557 -0.4462548 #> 13 6.77948385      1 -0.73382185  0.15624687 -1.35326133  0.2320178 #>  #>  #> $censor_propor #> [1] 0.2857143 0.2000000 0.3076923 #>  #> $u1 #> [1] 0.01 #>  #> $u2 #> [1] 9.967712 #>   # Two simulated datasets from 'gomp' with unknown 'u2' and censoring rate of 0.3: surv.simulate(Z = Z[2:3], beta = beta, a = exp(1), b = exp(2), u1 = 0.1,               cen_rate = 0.3, gen_data_from = \"gomp\", Trace = TRUE) #> censoring proportion for silos are:  0.01 0.01   with u2 = 20  #> censoring proportion for silos are:  0.01 0.01   with u2 = 14.19  #> censoring proportion for silos are:  0.02 0.02   with u2 = 10.10383  #> censoring proportion for silos are:  0.03 0.02   with u2 = 7.28991  #> censoring proportion for silos are:  0.04 0.03   with u2 = 5.275091  #> censoring proportion for silos are:  0.05 0.04   with u2 = 3.895249  #> censoring proportion for silos are:  0.07 0.07   with u2 = 2.896867  #> censoring proportion for silos are:  0.09 0.06   with u2 = 2.225017  #> censoring proportion for silos are:  0.12 0.09   with u2 = 1.72242  #> censoring proportion for silos are:  0.15 0.12   with u2 = 1.39092  #> censoring proportion for silos are:  0.17 0.15   with u2 = 1.162114  #> censoring proportion for silos are:  0.17 0.18   with u2 = 0.9992837  #> censoring proportion for silos are:  0.18 0.2   with u2 = 0.8723362  #> censoring proportion for silos are:  0.2 0.21   with u2 = 0.7788285  #> censoring proportion for silos are:  0.21 0.24   with u2 = 0.7064274  #> censoring proportion for silos are:  0.22 0.24   with u2 = 0.6536355  #> censoring proportion for silos are:  0.23 0.25   with u2 = 0.6087609  #> censoring proportion for silos are:  0.24 0.25   with u2 = 0.5731016  #> censoring proportion for silos are:  0.26 0.26   with u2 = 0.5429697  #> censoring proportion for silos are:  0.26 0.27   with u2 = 0.5212091  #> censoring proportion for silos are:  0.26 0.28   with u2 = 0.5016437  #> censoring proportion for silos are:  0.26 0.27   with u2 = 0.4858998  #> censoring proportion for silos are:  0.27 0.28   with u2 = 0.4684635  #> censoring proportion for silos are:  0.29 0.29   with u2 = 0.4560853  #> censoring proportion for silos are:  0.28 0.28   with u2 = 0.4499632  #> censoring proportion for silos are:  0.27 0.28   with u2 = 0.4408082  #> censoring proportion for silos are:  0.28 0.3   with u2 = 0.4296693  #>  #>  Desired u2 is: 0.4296693 ( with u1 = 0.1 )  #>   #> $D #> $D[[1]] #>            time status       Z.Z_1      Z.Z_2      Z.Z_3       Z.Z_4 #> 1  3.491216e-01      0 -0.23027404 -1.2690632 -0.2673166 -1.55025861 #> 2  8.252691e-04      1 -0.32916907  1.6265643  0.2278069  0.91480231 #> 3  8.251961e-06      1  0.49944094 -0.7696502  0.3879469 -0.02710971 #> 4  3.457653e-01      1 -0.92867906  0.2380289 -1.2894161  0.70696930 #> 5  1.383742e-01      1 -0.96832355  0.2955621 -0.4037798  0.42578390 #> 6  3.500657e-02      1 -0.05840795  0.9128333 -0.4899637  0.34036840 #> 7  3.473370e-04      1  1.07646211 -0.8527642  0.2666801  1.41542485 #> 8  3.788401e-04      1  1.68615000 -0.5295145  1.3293412  0.59569653 #> 9  1.746997e-02      1  1.93659046  1.7751477 -1.2878720  0.26822334 #> 10 1.887190e-01      0  0.51202240 -1.6117240  0.9368176 -0.75419444 #>  #> $D[[2]] #>            time status       Z.Z_1       Z.Z_2       Z.Z_3      Z.Z_4 #> 1  1.908368e-01      1 -1.44153951  0.84543041  1.63435118 -1.3325912 #> 2  5.553927e-03      1  0.42547690  0.91067540 -0.02140968  0.3038766 #> 3  2.554467e-05      1  0.63158367  0.08532232  0.64390401  1.2853559 #> 4  2.509140e-01      1 -0.15201586 -0.91096893  0.32015202 -0.1719336 #> 5  7.807589e-02      1 -1.48957048  0.09515951  1.29546216 -0.1569018 #> 6  8.807375e-03      1  0.50347542  0.65439581 -0.57036674  1.1085850 #> 7  2.237849e-01      0  0.95250295 -0.71764421  0.51880688 -1.5608051 #> 8  2.597067e-04      1  0.04937487  1.07616067  1.37303835  0.3469306 #> 9  7.799071e-03      1  0.37153942 -0.04582918 -0.45533515  1.2241016 #> 10 2.913660e-01      0 -0.90718225 -2.49706485  1.40629078 -0.8608085 #> 11 2.111413e-05      1  2.53099268 -0.03519585  0.12720354  1.4766462 #> 12 5.090627e-03      1  1.13004355  1.34211808  0.83315557 -0.4462548 #> 13 4.275830e-01      0 -0.73382185  0.15624687 -1.35326133  0.2320178 #>  #>  #> $censor_propor #> [1] 0.2000000 0.2307692 #>  #> $u1 #> [1] 0.1 #>  #> $u2 #> [1] 0.4296693 #>"},{"path":"https://hassanpazira.github.io/BFI/reference/trauma.html","id":null,"dir":"Reference","previous_headings":"","what":"Trauma patients from different hospitals — trauma","title":"Trauma patients from different hospitals — trauma","text":"data set consists data 371 trauma patients three hospitals. binary variable mortality used outcome, variables age, sex, Injury Severity Score (ISS, ranging 1 (low) 75 (high)) Glasgow Coma Scale (GCS, expresses level consciousness, ranging 3 (low) 15 (high)) used covariates. three types hospitals: peripheral hospital without neuro-surgical unit (Status = 1), peripheral hospital neuro-surgical unit (Status = 2), academic medical center (Status = 3). Originally, data come multi center study collected different aim. educational purposes minor changes made, see references .","code":""},{"path":"https://hassanpazira.github.io/BFI/reference/trauma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trauma patients from different hospitals — trauma","text":"","code":"data(trauma)"},{"path":"https://hassanpazira.github.io/BFI/reference/trauma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Trauma patients from different hospitals — trauma","text":"Jonker M.., Pazira H. Coolen .C.C. (2024). Bayesian federated inference estimating statistical models based non-shared multicenter data sets, Statistics Medicine, 43(12): 2421-2438. <https://doi.org/10.1002/sim.10072> Draaisma J.M.Th, de Haan .F.J., Goris R.J.. (1989). Preventable Trauma Deaths Netherlands - prospective Multicentre Study, journal Trauma, Vol. 29(11), 1552-1557.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v300-latest","dir":"Changelog","previous_headings":"","what":"BFI v3.0.0 (Latest)","title":"BFI v3.0.0 (Latest)","text":"release, package updated support observational studies estimating treatment effects (Bayesian Federated Causal Inference).","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v210","dir":"Changelog","previous_headings":"","what":"BFI v2.1.0","title":"BFI v2.1.0","text":"release, package updated support (semi-parametric) Cox model ‘unspecified’ baseline hazard, maximizing partial log-likelihood. documentation examples updated.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v201","dir":"Changelog","previous_headings":"","what":"BFI v2.0.1","title":"BFI v2.0.1","text":"CRAN release: 2024-07-04 bugfix release resolve minor bug optim function entries related gaussian family.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v200","dir":"Changelog","previous_headings":"","what":"BFI v2.0.0","title":"BFI v2.0.0","text":"package now supports survival data analysis, adding comprehensive tools time--event modeling alongside existing GLM functionalities. documentation examples updated.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v114","dir":"Changelog","previous_headings":"","what":"BFI v1.1.4","title":"BFI v1.1.4","text":"CRAN release: 2024-04-27 package updated address NOTEs identified CRAN submission.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v111","dir":"Changelog","previous_headings":"","what":"BFI v1.1.1","title":"BFI v1.1.1","text":"package prepared submission CRAN minor modifications.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v110","dir":"Changelog","previous_headings":"","what":"BFI v1.1.0","title":"BFI v1.1.0","text":"functions inv.prior.cov() bfi() adapted center specific variable. function summary() updated used case stratification. manual pdf updated case center specific variable. Henceforth BFI package can called Python. vignette also added package calling BFI Python.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v100","dir":"Changelog","previous_headings":"","what":"BFI v1.0.0","title":"BFI v1.0.0","text":"release, package website built using pkgdown package. functions adapted extra arguments case stratification. manual pdf also updated.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v064","dir":"Changelog","previous_headings":"","what":"BFI v0.6.4","title":"BFI v0.6.4","text":"manual pdf updated. also bugfix release resolve one minor bug.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v063","dir":"Changelog","previous_headings":"","what":"BFI v0.6.3","title":"BFI v0.6.3","text":"release, package updated outputs inv.prior.cov() MAP.estimation() (different centers) dimensions intercept=FALSE used bfi(). Moreover, one argument bfi(), .e., const_var, added package handle constant variables. bugfix release resolve one minor bug well.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v052","dir":"Changelog","previous_headings":"","what":"BFI v0.5.2","title":"BFI v0.5.2","text":"release, summary function (S3 method class bfi) added package. package pdf manual created package.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v042","dir":"Changelog","previous_headings":"","what":"BFI v0.4.2","title":"BFI v0.4.2","text":"release, package updated several arguments, e.g., intercept fitted . vignette added package well.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v032","dir":"Changelog","previous_headings":"","what":"BFI v0.3.2","title":"BFI v0.3.2","text":"release, package can carry stratified analysis.","code":""},{"path":"https://hassanpazira.github.io/BFI/news/index.html","id":"bfi-v022","dir":"Changelog","previous_headings":"","what":"BFI v0.2.2","title":"BFI v0.2.2","text":"bugfix release resolve one minor bug, add two functions related building Gamma matrix. Moreover, package now handles categorical covariates two levels.","code":""}]
